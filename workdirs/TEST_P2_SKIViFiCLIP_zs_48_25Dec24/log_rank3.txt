[2024-12-24 21:35:50 ViT-B/16] (CL_main_v2.py 442): INFO working dir: ./workdirs/TEST_P2_SKIViFiCLIP_zs_48_25Dec24/
[2024-12-24 21:36:25 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 261): INFO Loading CLIP (backbone: ViT-B/16)
[2024-12-24 21:36:29 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 265): INFO Building Model
[2024-12-24 21:36:29 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 282): INFO Turning on gradients for COMPLETE SKI_VLM model
[2024-12-24 21:36:29 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 315): INFO Parameters to be updated: {'hyperformer_model.l1.residual.conv.bias', 'clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l7.vit1.attn.outer', 'image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'text_encoder.transformer.resblocks.8.ln_2.bias', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'hyperformer_model.l8.tcn1.branches.1.0.weight', 'hyperformer_model.l5.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'hyperformer_model.l3.vit1.attn.rpe', 'hyperformer_model.l5.tcn1.branches.2.4.bias', 'hyperformer_model.l10.vit1.norm1.bias', 'image_encoder.transformer.resblocks.2.ln_1.bias', 'text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'hyperformer_model.l2.vit1.norm1.weight', 'text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l10.vit1.attn.rpe', 'hyperformer_model.l6.tcn1.branches.1.1.weight', 'image_encoder.ln_post.bias', 'text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l4.tcn1.branches.3.1.bias', 'hyperformer_model.l2.tcn1.branches.2.0.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'hyperformer_model.l2.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'hyperformer_model.l8.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'hyperformer_model.l9.vit1.attn.w1', 'hyperformer_model.l8.tcn1.branches.2.0.bias', 'hyperformer_model.l2.vit1.pe_proj.weight', 'image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l6.vit1.attn.kv.weight', 'hyperformer_model.l6.tcn1.branches.1.1.bias', 'image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'hyperformer_model.l1.tcn1.branches.1.1.bias', 'hyperformer_model.l3.tcn1.branches.2.1.bias', 'text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'hyperformer_model.l4.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.5.ln_1.bias', 'hyperformer_model.l6.tcn1.branches.2.0.weight', 'text_encoder.transformer.resblocks.2.ln_2.weight', 'text_encoder.transformer.resblocks.8.ln_2.weight', 'hyperformer_model.l3.tcn1.branches.0.1.weight', 'hyperformer_model.l3.vit1.attn.alpha', 'hyperformer_model.l10.vit1.attn.w1', 'text_encoder.transformer.resblocks.2.ln_1.weight', 'hyperformer_model.l9.tcn1.branches.0.0.weight', 'hyperformer_model.l3.tcn1.branches.1.1.bias', 'hyperformer_model.l7.vit1.attn.proj.weight', 'hyperformer_model.l1.tcn1.branches.2.0.weight', 'hyperformer_model.l2.vit1.attn.proj.weight', 'image_encoder.transformer.resblocks.6.ln_2.weight', 'clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'hyperformer_model.l4.vit1.norm1.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'text_encoder.transformer.resblocks.1.ln_2.bias', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l1.vit1.attn.proj.weight', 'hyperformer_model.l8.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l10.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'hyperformer_model.l2.tcn1.branches.1.0.weight', 'hyperformer_model.l8.tcn1.branches.1.1.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l5.vit1.attn.rpe', 'hyperformer_model.l4.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l3.vit1.pe_proj.weight', 'hyperformer_model.l9.vit1.pe_proj.weight', 'hyperformer_model.l1.vit1.attn.alpha', 'image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.6.ln_2.bias', 'image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.1.ln_1.bias', 'hyperformer_model.l10.tcn1.branches.2.1.weight', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l10.tcn1.branches.2.0.weight', 'clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'hyperformer_model.l9.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l10.tcn1.branches.3.0.weight', 'hyperformer_model.l3.vit1.attn.q.weight', 'text_encoder.transformer.resblocks.3.ln_1.bias', 'image_encoder.transformer.resblocks.4.ln_1.weight', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'hyperformer_model.l7.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'hyperformer_model.l7.vit1.attn.rpe', 'hyperformer_model.l9.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'image_encoder.transformer.resblocks.3.ln_1.weight', 'hyperformer_model.l6.tcn1.branches.2.4.weight', 'hyperformer_model.l7.vit1.attn.q.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'hyperformer_model.l9.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'hyperformer_model.l10.tcn1.branches.0.0.bias', 'image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'text_encoder.transformer.resblocks.7.ln_1.bias', 'clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'hyperformer_model.l4.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'image_encoder.ln_post.weight', 'hyperformer_model.l2.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l9.tcn1.branches.0.0.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l2.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'hyperformer_model.l8.tcn1.branches.0.1.weight', 'image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l6.tcn1.branches.1.3.conv.weight', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.0.ln_1.weight', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.1.0.weight', 'hyperformer_model.l8.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.2.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.2.4.bias', 'hyperformer_model.l5.tcn1.branches.2.4.weight', 'hyperformer_model.l4.tcn1.branches.1.1.weight', 'hyperformer_model.l8.residual.conv.weight', 'hyperformer_model.l5.tcn1.branches.0.1.weight', 'hyperformer_model.l8.tcn1.branches.2.4.bias', 'hyperformer_model.l9.tcn1.branches.3.0.weight', 'hyperformer_model.l1.tcn1.branches.3.0.bias', 'hyperformer_model.l10.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.10.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'hyperformer_model.l1.tcn1.branches.3.1.bias', 'text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'hyperformer_model.l6.vit1.pe_proj.weight', 'hyperformer_model.l9.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.4.ln_1.bias', 'text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l5.residual.conv.weight', 'text_encoder.transformer.resblocks.5.ln_1.weight', 'text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'hyperformer_model.l6.tcn1.branches.1.0.weight', 'hyperformer_model.l5.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l1.vit1.attn.proj.bias', 'hyperformer_model.l4.vit1.attn.proj.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l6.vit1.attn.w1', 'hyperformer_model.l4.vit1.attn.outer', 'hyperformer_model.l7.vit1.norm1.weight', 'image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'hyperformer_model.l1.tcn1.branches.2.1.weight', 'hyperformer_model.l10.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l8.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l4.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l10.vit1.attn.outer', 'text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.7.ln_1.weight', 'hyperformer_model.l2.vit1.attn.outer', 'hyperformer_model.l2.tcn1.branches.1.0.bias', 'hyperformer_model.l5.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l2.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.l4.tcn1.branches.0.1.bias', 'hyperformer_model.l7.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'hyperformer_model.l7.vit1.attn.kv.weight', 'hyperformer_model.l7.tcn1.branches.2.0.bias', 'image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'hyperformer_model.l7.tcn1.branches.1.1.weight', 'hyperformer_model.l8.vit1.attn.outer', 'clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'hyperformer_model.l3.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l10.vit1.attn.alpha', 'image_encoder.transformer.resblocks.10.ln_2.weight', 'image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'hyperformer_model.l7.vit1.attn.proj.bias', 'hyperformer_model.l10.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l3.tcn1.branches.0.0.weight', 'hyperformer_model.l4.tcn1.branches.3.1.weight', 'hyperformer_model.l9.tcn1.branches.1.1.weight', 'hyperformer_model.l4.vit1.attn.w1', 'clip_text_encoder.ln_final.weight', 'hyperformer_model.l7.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'hyperformer_model.l7.tcn1.branches.2.4.bias', 'hyperformer_model.l6.tcn1.branches.0.3.bn.weight', 'image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'hyperformer_model.l5.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.4.ln_2.weight', 'text_encoder.transformer.resblocks.4.ln_1.weight', 'hyperformer_model.l7.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l10.tcn1.branches.0.1.weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'hyperformer_model.l3.vit1.attn.proj.weight', 'hyperformer_model.l10.tcn1.branches.0.3.bn.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'hyperformer_model.l1.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l9.tcn1.branches.0.1.weight', 'clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l1.tcn1.branches.1.3.bn.weight', 'image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'image_encoder.transformer.resblocks.5.ln_2.bias', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l1.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.9.ln_1.weight', 'text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'hyperformer_model.l8.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'hyperformer_model.fc2.bias', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'text_encoder.transformer.resblocks.10.ln_1.weight', 'text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'hyperformer_model.l2.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l9.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l3.tcn1.branches.2.0.weight', 'hyperformer_model.l4.tcn1.branches.1.0.weight', 'clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l8.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'clip_text_encoder.positional_embedding', 'image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'hyperformer_model.l4.vit1.attn.alpha', 'hyperformer_model.l6.vit1.norm1.weight', 'text_encoder.ln_final.weight', 'hyperformer_model.l7.tcn1.branches.0.1.weight', 'hyperformer_model.l3.tcn1.branches.2.0.bias', 'hyperformer_model.l10.tcn1.branches.3.0.bias', 'hyperformer_model.l2.tcn1.branches.3.1.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l3.vit1.attn.outer', 'image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.3.ln_1.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'hyperformer_model.l3.tcn1.branches.0.1.bias', 'text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'hyperformer_model.l1.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'hyperformer_model.l5.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.8.ln_2.weight', 'image_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.data_bn.weight', 'hyperformer_model.l7.tcn1.branches.2.1.weight', 'hyperformer_model.l9.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.5.ln_2.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l3.vit1.norm1.bias', 'image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'image_encoder.transformer.resblocks.1.ln_2.bias', 'text_encoder.text_projection', 'hyperformer_model.l9.tcn1.branches.1.3.conv.bias', 'image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'hyperformer_model.l3.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l2.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'hyperformer_model.l8.tcn1.branches.3.0.weight', 'hyperformer_model.l6.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'hyperformer_model.l5.vit1.norm1.weight', 'hyperformer_model.l9.tcn1.branches.3.1.bias', 'hyperformer_model.l6.vit1.norm1.bias', 'hyperformer_model.l3.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'hyperformer_model.l8.tcn1.branches.2.4.weight', 'hyperformer_model.l2.tcn1.branches.3.0.bias', 'hyperformer_model.l9.vit1.attn.kv.weight', 'hyperformer_model.l3.vit1.attn.w1', 'hyperformer_model.l2.tcn1.branches.1.1.weight', 'hyperformer_model.l7.tcn1.branches.0.0.weight', 'hyperformer_model.l8.vit1.attn.q.weight', 'hyperformer_model.l3.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.1.ln_2.weight', 'image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'hyperformer_model.l8.residual.bn.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'hyperformer_model.l10.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'hyperformer_model.l3.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'hyperformer_model.l6.vit1.attn.proj.bias', 'hyperformer_model.l10.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l6.tcn1.branches.2.1.weight', 'hyperformer_model.l5.vit1.pe_proj.weight', 'hyperformer_model.l1.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'hyperformer_model.l7.vit1.attn.w1', 'text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'text_encoder.transformer.resblocks.11.ln_2.weight', 'image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.6.ln_1.bias', 'hyperformer_model.l8.tcn1.branches.0.0.bias', 'hyperformer_model.l4.vit1.attn.kv.weight', 'hyperformer_model.l9.tcn1.branches.1.3.conv.weight', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'hyperformer_model.l5.tcn1.branches.1.1.weight', 'hyperformer_model.l7.tcn1.branches.0.1.bias', 'hyperformer_model.l9.vit1.norm1.weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'hyperformer_model.l10.vit1.pe_proj.weight', 'clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.11.ln_1.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l1.vit1.attn.outer', 'hyperformer_model.l6.tcn1.branches.3.0.bias', 'hyperformer_model.l5.tcn1.branches.2.1.bias', 'hyperformer_model.l7.tcn1.branches.3.1.bias', 'text_encoder.transformer.resblocks.7.ln_2.weight', 'image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'hyperformer_model.l1.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'hyperformer_model.l9.tcn1.branches.2.0.bias', 'hyperformer_model.l5.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l9.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l4.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'hyperformer_model.l7.vit1.pe_proj.weight', 'hyperformer_model.l5.tcn1.branches.2.0.bias', 'hyperformer_model.l10.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'image_encoder.class_embedding', 'text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'hyperformer_model.l5.vit1.attn.proj.weight', 'hyperformer_model.l10.tcn1.branches.2.0.bias', 'hyperformer_model.l8.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.9.ln_1.weight', 'text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'hyperformer_model.l3.tcn1.branches.2.1.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'hyperformer_model.l4.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'hyperformer_model.l9.vit1.attn.proj.bias', 'text_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.l9.vit1.attn.alpha', 'hyperformer_model.l1.vit1.attn.rpe', 'hyperformer_model.l3.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'hyperformer_model.l3.vit1.attn.proj.bias', 'hyperformer_model.l5.residual.bn.weight', 'hyperformer_model.l8.vit1.attn.alpha', 'image_encoder.transformer.resblocks.8.ln_1.weight', 'hyperformer_model.fc2.weight', 'hyperformer_model.l5.vit1.attn.kv.weight', 'text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'image_encoder.transformer.resblocks.7.ln_1.bias', 'hyperformer_model.l1.tcn1.branches.1.1.weight', 'hyperformer_model.l7.vit1.attn.alpha', 'hyperformer_model.l3.tcn1.branches.3.1.weight', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'image_encoder.transformer.resblocks.4.ln_2.bias', 'text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'text_encoder.ln_final.bias', 'hyperformer_model.l4.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'hyperformer_model.l1.residual.conv.weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'hyperformer_model.l10.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.6.ln_2.bias', 'hyperformer_model.l10.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l6.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l10.tcn1.branches.1.1.bias', 'image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'hyperformer_model.l1.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.4.ln_1.bias', 'image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'hyperformer_model.l7.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l6.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'hyperformer_model.l4.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l3.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'hyperformer_model.l10.vit1.attn.proj.weight', 'clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'image_encoder.transformer.resblocks.11.ln_1.weight', 'hyperformer_model.l3.tcn1.branches.1.1.weight', 'image_encoder.transformer.resblocks.5.ln_1.weight', 'text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'hyperformer_model.l1.vit1.skip_proj.weight', 'text_encoder.transformer.resblocks.9.ln_2.bias', 'hyperformer_model.l2.tcn1.branches.2.4.bias', 'hyperformer_model.l6.tcn1.branches.2.0.bias', 'clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'hyperformer_model.l5.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.11.ln_2.bias', 'text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.0.0.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'text_encoder.transformer.resblocks.9.ln_1.bias', 'clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'text_encoder.transformer.resblocks.10.ln_2.weight', 'hyperformer_model.l10.tcn1.branches.1.1.weight', 'image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'image_encoder.transformer.resblocks.8.ln_1.bias', 'text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'hyperformer_model.l9.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l9.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'hyperformer_model.l9.tcn1.branches.3.0.bias', 'hyperformer_model.l6.tcn1.branches.3.1.bias', 'text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.3.1.weight', 'image_encoder.ln_pre.weight', 'text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'hyperformer_model.l3.tcn1.branches.3.0.weight', 'hyperformer_model.l8.tcn1.branches.3.0.bias', 'clip_text_encoder.text_projection', 'hyperformer_model.l5.vit1.attn.outer', 'hyperformer_model.l1.vit1.attn.kv.weight', 'hyperformer_model.l4.tcn1.branches.2.0.bias', 'hyperformer_model.l10.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l1.tcn1.branches.1.0.bias', 'hyperformer_model.l7.tcn1.branches.3.0.weight', 'image_encoder.proj', 'image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'text_encoder.transformer.resblocks.0.ln_2.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.1.1.bias', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'hyperformer_model.l9.vit1.attn.proj.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'text_encoder.positional_embedding', 'hyperformer_model.l4.vit1.norm1.weight', 'text_encoder.transformer.resblocks.2.ln_2.bias', 'hyperformer_model.l1.residual.bn.weight', 'hyperformer_model.l6.tcn1.branches.0.3.conv.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'hyperformer_model.l10.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l1.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l4.tcn1.branches.2.0.weight', 'clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'text_encoder.transformer.resblocks.1.ln_1.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'hyperformer_model.l2.tcn1.branches.2.1.bias', 'hyperformer_model.l7.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'hyperformer_model.l8.vit1.norm1.bias', 'hyperformer_model.l5.tcn1.branches.1.0.bias', 'hyperformer_model.l8.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'hyperformer_model.l6.vit1.attn.outer', 'image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l4.vit1.attn.proj.weight', 'hyperformer_model.l7.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'image_encoder.positional_embedding', 'hyperformer_model.l9.tcn1.branches.1.1.bias', 'hyperformer_model.l8.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.10.ln_1.bias', 'text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l4.vit1.attn.rpe', 'hyperformer_model.l2.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.9.ln_2.weight', 'hyperformer_model.l9.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.9.ln_1.bias', 'text_encoder.transformer.resblocks.6.ln_1.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'hyperformer_model.l1.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'hyperformer_model.l3.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'text_encoder.transformer.resblocks.4.ln_2.bias', 'text_encoder.transformer.resblocks.9.ln_2.weight', 'image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'image_encoder.transformer.resblocks.6.ln_1.bias', 'text_encoder.transformer.resblocks.8.ln_1.weight', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l8.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l8.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l1.vit1.attn.w1', 'hyperformer_model.l6.tcn1.branches.2.1.bias', 'hyperformer_model.l1.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.9.ln_2.bias', 'hyperformer_model.l3.tcn1.branches.2.4.weight', 'hyperformer_model.l7.vit1.norm1.bias', 'hyperformer_model.l7.tcn1.branches.2.4.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'hyperformer_model.l9.vit1.attn.q.weight', 'hyperformer_model.l1.residual.bn.bias', 'text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'hyperformer_model.l5.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l2.tcn1.branches.1.1.bias', 'hyperformer_model.l6.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'hyperformer_model.l8.vit1.attn.w1', 'image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'hyperformer_model.l8.vit1.norm1.weight', 'text_encoder.transformer.resblocks.5.ln_2.bias', 'hyperformer_model.l6.vit1.attn.alpha', 'image_encoder.transformer.resblocks.10.ln_2.bias', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l5.residual.bn.bias', 'hyperformer_model.l6.vit1.attn.proj.weight', 'image_encoder.transformer.resblocks.7.ln_1.weight', 'hyperformer_model.l5.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l7.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l7.tcn1.branches.1.3.bn.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.3.ln_2.bias', 'text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'text_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l5.tcn1.branches.3.1.weight', 'hyperformer_model.l8.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'hyperformer_model.l3.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'hyperformer_model.l10.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'hyperformer_model.l5.tcn1.branches.0.0.weight', 'hyperformer_model.l8.residual.conv.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l2.vit1.norm1.bias', 'image_encoder.transformer.resblocks.3.ln_1.bias', 'image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'hyperformer_model.l3.tcn1.branches.3.1.bias', 'hyperformer_model.l1.vit1.norm1.weight', 'image_encoder.transformer.resblocks.1.ln_1.bias', 'hyperformer_model.l2.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'hyperformer_model.l5.tcn1.branches.3.1.bias', 'clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'hyperformer_model.l8.tcn1.branches.0.0.weight', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'image_encoder.transformer.resblocks.7.ln_2.bias', 'hyperformer_model.l7.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'hyperformer_model.l3.tcn1.branches.1.0.weight', 'hyperformer_model.l5.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l2.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.l5.residual.conv.bias', 'hyperformer_model.l3.vit1.norm1.weight', 'hyperformer_model.l9.vit1.norm1.bias', 'hyperformer_model.l2.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l8.tcn1.branches.2.1.bias', 'hyperformer_model.l4.vit1.pe_proj.weight', 'hyperformer_model.l8.vit1.attn.rpe', 'image_encoder.ln_pre.bias', 'clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l1.tcn1.branches.0.1.weight', 'image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l4.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l2.tcn1.branches.0.0.weight', 'hyperformer_model.l9.vit1.attn.rpe', 'image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'hyperformer_model.l6.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l4.tcn1.branches.1.0.bias', 'hyperformer_model.l5.vit1.attn.alpha', 'text_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l2.tcn1.branches.0.0.bias', 'hyperformer_model.l1.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l2.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l7.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'image_encoder.conv1.weight', 'text_encoder.transformer.resblocks.10.ln_1.bias', 'clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l2.tcn1.branches.2.1.weight', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.0.ln_2.bias', 'text_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l4.tcn1.branches.2.4.bias', 'text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'hyperformer_model.l8.tcn1.branches.3.1.bias', 'hyperformer_model.l4.tcn1.branches.1.1.bias', 'hyperformer_model.l1.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'hyperformer_model.l1.vit1.pe_proj.weight', 'hyperformer_model.l7.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l9.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'hyperformer_model.l5.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l3.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l6.tcn1.branches.0.0.bias', 'hyperformer_model.l2.tcn1.branches.0.1.weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'clip_text_encoder.ln_final.bias', 'clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'image_encoder.transformer.resblocks.2.ln_2.weight', 'image_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l4.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.3.0.bias', 'hyperformer_model.l6.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'hyperformer_model.l3.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.5.ln_1.bias', 'text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'hyperformer_model.l5.tcn1.branches.0.0.bias', 'hyperformer_model.l8.vit1.attn.proj.weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'hyperformer_model.l1.tcn1.branches.2.0.bias', 'image_encoder.transformer.resblocks.7.ln_2.weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'hyperformer_model.data_bn.bias', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'hyperformer_model.l2.tcn1.branches.2.0.bias', 'image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'hyperformer_model.l5.tcn1.branches.1.0.weight', 'hyperformer_model.l8.residual.bn.weight', 'hyperformer_model.l2.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'image_encoder.transformer.resblocks.2.ln_1.weight', 'image_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'hyperformer_model.l2.vit1.attn.alpha', 'hyperformer_model.l6.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l5.vit1.attn.w1', 'hyperformer_model.l10.tcn1.branches.2.4.weight', 'hyperformer_model.l4.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l5.vit1.norm1.bias', 'hyperformer_model.l9.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l2.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'hyperformer_model.l4.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'hyperformer_model.l9.tcn1.branches.2.0.weight', 'hyperformer_model.l10.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.0.ln_1.weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'hyperformer_model.l3.tcn1.branches.0.0.bias', 'hyperformer_model.l6.tcn1.branches.0.1.weight', 'image_encoder.transformer.resblocks.1.ln_2.weight', 'hyperformer_model.l4.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'hyperformer_model.l1.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'hyperformer_model.l1.tcn1.branches.2.1.bias', 'text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'hyperformer_model.l6.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l8.vit1.pe_proj.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'text_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l2.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l4.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'hyperformer_model.l7.tcn1.branches.1.0.bias', 'hyperformer_model.l10.tcn1.branches.3.1.bias', 'hyperformer_model.l9.vit1.attn.outer', 'clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'hyperformer_model.l4.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l4.vit1.attn.q.weight', 'hyperformer_model.l5.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.4.ln_2.weight', 'clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'hyperformer_model.l2.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'hyperformer_model.l10.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l10.vit1.attn.proj.bias', 'text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'hyperformer_model.l7.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.7.ln_2.bias', 'text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l8.tcn1.branches.0.1.bias', 'hyperformer_model.l10.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.11.ln_2.bias', 'image_encoder.transformer.resblocks.10.ln_1.weight', 'hyperformer_model.l8.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'hyperformer_model.l3.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.3.ln_2.bias', 'text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'image_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l5.tcn1.branches.0.1.bias', 'hyperformer_model.l2.vit1.attn.rpe', 'image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'text_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l2.vit1.attn.proj.bias', 'hyperformer_model.l8.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'hyperformer_model.l5.tcn1.branches.2.0.weight'}
[2024-12-24 21:36:29 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 316): INFO Total learnable items: 835
[2024-12-24 21:36:30 ViT-B/16] (tools.py 147): INFO ==============> Resuming from ./workdirs/TEST_P1_SKeletonCLIP_alltrn_HFinit_zs_48_17Dec24/ckpt_epoch_0.pth....................
[2024-12-24 21:36:30 ViT-B/16] (tools.py 172): INFO resume VIFICLIP model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.clip_text_encoder.positional_embedding', 'module.clip_text_encoder.text_projection', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'module.clip_text_encoder.ln_final.weight', 'module.clip_text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:36:30 ViT-B/16] (tools.py 176): INFO ==============> Resuming from /data/users/asinha13/projects/CLIP4ADL/model_chkpnts/ntu_CS_P1_HF_pretrain_frzn_txt_zs_48_AS_16Jan24/ckpt_epoch_99.pth....................
[2024-12-24 21:36:31 ViT-B/16] (tools.py 218): INFO resume Hyperformer model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.text_encoder.positional_embedding', 'module.text_encoder.text_projection', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_1.weight', 'module.text_encoder.transformer.resblocks.0.ln_1.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_2.weight', 'module.text_encoder.transformer.resblocks.0.ln_2.bias', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_1.weight', 'module.text_encoder.transformer.resblocks.1.ln_1.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_2.weight', 'module.text_encoder.transformer.resblocks.1.ln_2.bias', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_1.weight', 'module.text_encoder.transformer.resblocks.2.ln_1.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_2.weight', 'module.text_encoder.transformer.resblocks.2.ln_2.bias', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_1.weight', 'module.text_encoder.transformer.resblocks.3.ln_1.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_2.weight', 'module.text_encoder.transformer.resblocks.3.ln_2.bias', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_1.weight', 'module.text_encoder.transformer.resblocks.4.ln_1.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_2.weight', 'module.text_encoder.transformer.resblocks.4.ln_2.bias', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_1.weight', 'module.text_encoder.transformer.resblocks.5.ln_1.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_2.weight', 'module.text_encoder.transformer.resblocks.5.ln_2.bias', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_1.weight', 'module.text_encoder.transformer.resblocks.6.ln_1.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_2.weight', 'module.text_encoder.transformer.resblocks.6.ln_2.bias', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_1.weight', 'module.text_encoder.transformer.resblocks.7.ln_1.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_2.weight', 'module.text_encoder.transformer.resblocks.7.ln_2.bias', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_1.weight', 'module.text_encoder.transformer.resblocks.8.ln_1.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_2.weight', 'module.text_encoder.transformer.resblocks.8.ln_2.bias', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_1.weight', 'module.text_encoder.transformer.resblocks.9.ln_1.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_2.weight', 'module.text_encoder.transformer.resblocks.9.ln_2.bias', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_1.weight', 'module.text_encoder.transformer.resblocks.10.ln_1.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_2.weight', 'module.text_encoder.transformer.resblocks.10.ln_2.bias', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_1.weight', 'module.text_encoder.transformer.resblocks.11.ln_1.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_2.weight', 'module.text_encoder.transformer.resblocks.11.ln_2.bias', 'module.text_encoder.ln_final.weight', 'module.text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:36:36 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][0/11317]	eta 16:34:18 lr 0.000022000	time 5.2716 (5.2716)	dist_loss 0.2850 (0.2850)	image_text_loss 3.9417 (3.9417)	pose_text_loss 2.8081 (2.8081)	tot_loss 9.5998 (9.5998)	mem 29650MB
[2024-12-24 21:36:53 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][50/11317]	eta 1:22:59 lr 0.000021999	time 0.3494 (0.4420)	dist_loss 0.0034 (0.1306)	image_text_loss 3.8688 (3.8683)	pose_text_loss 3.7475 (3.7192)	tot_loss 7.6499 (8.8932)	mem 29650MB
[2024-12-24 21:37:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][100/11317]	eta 1:14:26 lr 0.000021996	time 0.3560 (0.3982)	dist_loss 0.0192 (0.0721)	image_text_loss 3.8044 (3.8684)	pose_text_loss 3.5345 (3.7408)	tot_loss 7.5306 (8.3305)	mem 29650MB
[2024-12-24 21:38:19 ViT-B/16] (CL_main_v2.py 442): INFO working dir: ./workdirs/TEST_P2_SKIViFiCLIP_zs_48_25Dec24/
[2024-12-24 21:39:54 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 261): INFO Loading CLIP (backbone: ViT-B/16)
[2024-12-24 21:39:58 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 265): INFO Building Model
[2024-12-24 21:39:58 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 282): INFO Turning on gradients for COMPLETE SKI_VLM model
[2024-12-24 21:39:58 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 315): INFO Parameters to be updated: {'hyperformer_model.l3.tcn1.branches.1.1.bias', 'clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'hyperformer_model.l9.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l10.tcn1.branches.2.1.weight', 'hyperformer_model.l2.tcn1.branches.0.0.weight', 'hyperformer_model.l3.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.8.ln_2.weight', 'hyperformer_model.l4.vit1.attn.proj.weight', 'hyperformer_model.l1.vit1.pe_proj.weight', 'image_encoder.transformer.resblocks.2.ln_2.bias', 'hyperformer_model.l1.vit1.norm1.weight', 'image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'hyperformer_model.l7.vit1.attn.w1', 'hyperformer_model.l5.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l10.tcn1.branches.3.1.weight', 'hyperformer_model.l6.tcn1.branches.3.1.bias', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'hyperformer_model.l5.tcn1.branches.3.1.weight', 'hyperformer_model.l3.tcn1.branches.3.1.bias', 'hyperformer_model.l8.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l8.vit1.norm1.bias', 'text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'text_encoder.transformer.resblocks.0.ln_1.bias', 'text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'hyperformer_model.l7.vit1.attn.proj.weight', 'hyperformer_model.l8.tcn1.branches.0.1.weight', 'hyperformer_model.l8.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l8.tcn1.branches.1.1.bias', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.9.ln_2.weight', 'hyperformer_model.l3.tcn1.branches.0.1.bias', 'hyperformer_model.l9.tcn1.branches.0.0.bias', 'hyperformer_model.l9.vit1.pe_proj.weight', 'text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l2.vit1.attn.q.weight', 'hyperformer_model.l6.vit1.pe_proj.weight', 'text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'hyperformer_model.l8.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l1.tcn1.branches.1.0.bias', 'hyperformer_model.l9.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l4.tcn1.branches.2.0.bias', 'hyperformer_model.l9.tcn1.branches.1.0.weight', 'hyperformer_model.l5.tcn1.branches.2.0.bias', 'hyperformer_model.l3.tcn1.branches.2.0.bias', 'hyperformer_model.l6.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'hyperformer_model.l6.vit1.attn.rpe', 'hyperformer_model.l6.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l6.tcn1.branches.0.3.bn.weight', 'image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.10.ln_1.bias', 'clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'hyperformer_model.l8.tcn1.branches.2.0.bias', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'hyperformer_model.l3.vit1.attn.q.weight', 'hyperformer_model.l6.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l8.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.11.ln_2.bias', 'hyperformer_model.l3.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l5.tcn1.branches.0.0.bias', 'hyperformer_model.l5.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.8.ln_2.bias', 'image_encoder.ln_post.bias', 'text_encoder.transformer.resblocks.2.ln_2.weight', 'text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'hyperformer_model.l10.tcn1.branches.2.0.bias', 'hyperformer_model.l5.vit1.attn.alpha', 'hyperformer_model.l4.vit1.norm1.bias', 'image_encoder.ln_pre.weight', 'hyperformer_model.l10.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'hyperformer_model.l6.tcn1.branches.3.1.weight', 'clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l3.tcn1.branches.0.0.weight', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.2.0.weight', 'hyperformer_model.l6.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'hyperformer_model.l6.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l1.vit1.attn.proj.weight', 'text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'hyperformer_model.l3.tcn1.branches.3.1.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.0.1.bias', 'text_encoder.ln_final.bias', 'hyperformer_model.l10.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l9.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.5.ln_2.bias', 'image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'hyperformer_model.l8.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l4.tcn1.branches.3.1.bias', 'hyperformer_model.l9.tcn1.branches.2.4.weight', 'hyperformer_model.l6.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'text_encoder.transformer.resblocks.5.ln_1.weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l2.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l6.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l8.tcn1.branches.0.0.bias', 'hyperformer_model.l9.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l2.tcn1.branches.0.3.conv.bias', 'clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'hyperformer_model.l6.tcn1.branches.1.0.bias', 'hyperformer_model.l8.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.1.ln_1.bias', 'clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'hyperformer_model.l5.tcn1.branches.0.1.weight', 'hyperformer_model.l1.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'hyperformer_model.l10.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l1.tcn1.branches.3.1.bias', 'hyperformer_model.l9.vit1.attn.alpha', 'hyperformer_model.l2.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.6.ln_1.bias', 'hyperformer_model.l10.tcn1.branches.2.4.weight', 'hyperformer_model.l6.tcn1.branches.0.1.weight', 'image_encoder.transformer.resblocks.2.ln_1.weight', 'clip_text_encoder.positional_embedding', 'hyperformer_model.l6.tcn1.branches.0.1.bias', 'hyperformer_model.l10.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'hyperformer_model.l5.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l6.vit1.attn.q.weight', 'hyperformer_model.l9.vit1.attn.outer', 'hyperformer_model.l8.vit1.attn.q.weight', 'hyperformer_model.l5.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'hyperformer_model.l3.vit1.attn.kv.weight', 'hyperformer_model.l4.tcn1.branches.0.0.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'hyperformer_model.l10.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'text_encoder.transformer.resblocks.6.ln_2.bias', 'text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l7.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l6.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'hyperformer_model.l7.vit1.pe_proj.weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'hyperformer_model.l2.tcn1.branches.3.0.weight', 'hyperformer_model.l10.vit1.attn.outer', 'image_encoder.transformer.resblocks.11.ln_1.bias', 'clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'image_encoder.transformer.resblocks.9.ln_2.bias', 'clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'image_encoder.transformer.resblocks.10.ln_2.weight', 'text_encoder.transformer.resblocks.10.ln_2.weight', 'hyperformer_model.l10.tcn1.branches.0.3.bn.bias', 'image_encoder.transformer.resblocks.3.ln_2.bias', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'clip_text_encoder.ln_final.bias', 'image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'hyperformer_model.l1.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'hyperformer_model.l5.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l6.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l7.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l8.tcn1.branches.1.0.bias', 'hyperformer_model.l10.tcn1.branches.0.0.bias', 'image_encoder.transformer.resblocks.3.ln_2.weight', 'image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'text_encoder.transformer.resblocks.2.ln_2.bias', 'image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'hyperformer_model.l6.vit1.attn.proj.bias', 'hyperformer_model.l2.tcn1.branches.1.1.bias', 'hyperformer_model.l2.tcn1.branches.1.3.bn.weight', 'text_encoder.transformer.resblocks.3.ln_1.weight', 'hyperformer_model.l5.tcn1.branches.2.4.bias', 'hyperformer_model.l9.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'hyperformer_model.l3.tcn1.branches.0.1.weight', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'hyperformer_model.l2.tcn1.branches.2.4.bias', 'text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'hyperformer_model.l6.vit1.norm1.weight', 'image_encoder.positional_embedding', 'hyperformer_model.l2.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.5.ln_1.bias', 'hyperformer_model.l10.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l2.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'hyperformer_model.l5.tcn1.branches.1.0.bias', 'text_encoder.positional_embedding', 'text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'hyperformer_model.l5.tcn1.branches.0.1.bias', 'text_encoder.transformer.resblocks.9.ln_1.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l9.vit1.attn.rpe', 'hyperformer_model.l9.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'text_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l3.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'hyperformer_model.l10.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'image_encoder.transformer.resblocks.7.ln_1.bias', 'hyperformer_model.l1.tcn1.branches.0.0.bias', 'hyperformer_model.l7.tcn1.branches.0.0.weight', 'hyperformer_model.l1.tcn1.branches.2.4.weight', 'hyperformer_model.l5.tcn1.branches.2.1.bias', 'hyperformer_model.l8.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'hyperformer_model.l1.tcn1.branches.1.0.weight', 'hyperformer_model.l3.vit1.pe_proj.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'hyperformer_model.l3.vit1.norm1.weight', 'text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'image_encoder.transformer.resblocks.9.ln_1.bias', 'hyperformer_model.l8.tcn1.branches.2.0.weight', 'hyperformer_model.l7.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'image_encoder.transformer.resblocks.4.ln_2.bias', 'hyperformer_model.l6.vit1.attn.kv.weight', 'hyperformer_model.l5.residual.conv.bias', 'text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'hyperformer_model.l8.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l1.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l2.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'hyperformer_model.l5.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.3.1.bias', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l4.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'text_encoder.transformer.resblocks.4.ln_1.weight', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'hyperformer_model.l1.residual.conv.weight', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'hyperformer_model.l9.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'hyperformer_model.l3.vit1.attn.outer', 'text_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l9.vit1.attn.q.weight', 'hyperformer_model.l9.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l1.vit1.attn.outer', 'hyperformer_model.l4.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l9.vit1.attn.proj.bias', 'hyperformer_model.l9.tcn1.branches.1.1.weight', 'hyperformer_model.l3.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l7.vit1.attn.rpe', 'image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'hyperformer_model.l7.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'hyperformer_model.l9.tcn1.branches.0.1.weight', 'hyperformer_model.l1.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'hyperformer_model.data_bn.weight', 'hyperformer_model.l9.tcn1.branches.0.1.bias', 'hyperformer_model.l3.tcn1.branches.3.0.weight', 'hyperformer_model.fc2.bias', 'text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'hyperformer_model.l2.tcn1.branches.2.1.bias', 'text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.3.1.weight', 'hyperformer_model.l2.vit1.attn.rpe', 'hyperformer_model.l9.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'text_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l4.tcn1.branches.0.3.bn.weight', 'image_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l9.vit1.attn.kv.weight', 'hyperformer_model.l1.residual.bn.weight', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'hyperformer_model.l2.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l1.residual.bn.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.3.0.weight', 'image_encoder.transformer.resblocks.10.ln_2.bias', 'image_encoder.transformer.resblocks.6.ln_2.bias', 'hyperformer_model.l1.vit1.attn.q.weight', 'hyperformer_model.l4.vit1.norm1.weight', 'hyperformer_model.l8.vit1.attn.kv.weight', 'text_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l2.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l7.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l8.vit1.pe_proj.weight', 'hyperformer_model.l5.vit1.attn.q.weight', 'hyperformer_model.l6.tcn1.branches.2.4.bias', 'hyperformer_model.l1.tcn1.branches.0.3.conv.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.7.ln_1.bias', 'hyperformer_model.l6.vit1.attn.alpha', 'hyperformer_model.l9.tcn1.branches.1.1.bias', 'clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l2.vit1.attn.proj.bias', 'text_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l4.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'hyperformer_model.l10.vit1.attn.rpe', 'hyperformer_model.l3.tcn1.branches.2.1.bias', 'hyperformer_model.l8.tcn1.branches.1.1.weight', 'hyperformer_model.l2.tcn1.branches.1.1.weight', 'hyperformer_model.l2.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.9.ln_2.weight', 'hyperformer_model.l7.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.4.ln_1.bias', 'hyperformer_model.l1.tcn1.branches.1.3.conv.weight', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'hyperformer_model.l6.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l2.vit1.attn.proj.weight', 'hyperformer_model.l8.tcn1.branches.3.0.weight', 'hyperformer_model.l10.vit1.attn.proj.weight', 'hyperformer_model.l4.tcn1.branches.1.3.bn.weight', 'image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'hyperformer_model.l3.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'hyperformer_model.l8.residual.conv.weight', 'hyperformer_model.l5.residual.conv.weight', 'text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l2.vit1.attn.outer', 'hyperformer_model.l4.tcn1.branches.0.1.weight', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l4.vit1.pe_proj.weight', 'hyperformer_model.l5.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l6.vit1.attn.w1', 'text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.1.0.weight', 'hyperformer_model.l10.tcn1.branches.3.0.weight', 'hyperformer_model.l3.tcn1.branches.1.0.bias', 'hyperformer_model.l7.vit1.attn.outer', 'hyperformer_model.l5.tcn1.branches.1.3.bn.weight', 'text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'hyperformer_model.l3.vit1.attn.proj.weight', 'hyperformer_model.l1.tcn1.branches.2.1.bias', 'hyperformer_model.l5.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l7.tcn1.branches.1.0.bias', 'hyperformer_model.l7.vit1.norm1.bias', 'text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l7.tcn1.branches.2.4.bias', 'text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.l8.tcn1.branches.1.3.conv.bias', 'image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'text_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l5.vit1.norm1.weight', 'hyperformer_model.l10.tcn1.branches.2.1.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'image_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.l10.tcn1.branches.1.1.weight', 'hyperformer_model.l6.tcn1.branches.1.1.weight', 'clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l2.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l2.tcn1.branches.2.0.bias', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'hyperformer_model.l1.vit1.skip_proj.weight', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l3.tcn1.branches.0.0.bias', 'hyperformer_model.l7.tcn1.branches.1.1.weight', 'hyperformer_model.l3.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l3.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'image_encoder.ln_pre.bias', 'clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l6.vit1.attn.proj.weight', 'image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l4.tcn1.branches.2.1.bias', 'hyperformer_model.l7.tcn1.branches.1.1.bias', 'image_encoder.transformer.resblocks.8.ln_1.weight', 'hyperformer_model.l1.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'hyperformer_model.l3.tcn1.branches.1.1.weight', 'hyperformer_model.l1.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l9.vit1.norm1.bias', 'text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'hyperformer_model.l9.vit1.attn.proj.weight', 'hyperformer_model.l3.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'hyperformer_model.l9.vit1.norm1.weight', 'hyperformer_model.l9.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'hyperformer_model.l1.vit1.attn.rpe', 'hyperformer_model.l10.vit1.pe_proj.weight', 'hyperformer_model.l4.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.3.1.bias', 'hyperformer_model.l10.vit1.norm1.bias', 'image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l2.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'text_encoder.text_projection', 'image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'hyperformer_model.l5.vit1.attn.proj.weight', 'text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'image_encoder.transformer.resblocks.3.ln_1.bias', 'text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'hyperformer_model.l2.tcn1.branches.3.0.bias', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.10.ln_1.weight', 'text_encoder.transformer.resblocks.11.ln_2.bias', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'hyperformer_model.l8.tcn1.branches.3.0.bias', 'clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.0.1.weight', 'hyperformer_model.l2.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l9.tcn1.branches.2.0.weight', 'text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'hyperformer_model.l9.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.7.ln_1.weight', 'hyperformer_model.l8.vit1.attn.w1', 'hyperformer_model.l8.residual.bn.weight', 'hyperformer_model.l8.residual.bn.bias', 'hyperformer_model.l4.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'hyperformer_model.data_bn.bias', 'hyperformer_model.l5.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.9.ln_1.bias', 'text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'hyperformer_model.l9.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l5.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l2.vit1.attn.w1', 'hyperformer_model.l10.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'hyperformer_model.l1.tcn1.branches.2.1.weight', 'hyperformer_model.l4.vit1.attn.rpe', 'image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'image_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l7.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l8.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'text_encoder.transformer.resblocks.6.ln_1.weight', 'text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l8.vit1.attn.proj.weight', 'text_encoder.transformer.resblocks.0.ln_2.bias', 'image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l5.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'clip_text_encoder.ln_final.weight', 'hyperformer_model.l10.vit1.attn.alpha', 'image_encoder.transformer.resblocks.4.ln_2.weight', 'hyperformer_model.l4.vit1.attn.w1', 'image_encoder.transformer.resblocks.0.ln_2.weight', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l1.tcn1.branches.0.0.weight', 'hyperformer_model.l10.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'hyperformer_model.l4.tcn1.branches.0.0.bias', 'hyperformer_model.l8.vit1.attn.alpha', 'image_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l10.tcn1.branches.0.1.bias', 'hyperformer_model.l2.vit1.attn.alpha', 'image_encoder.class_embedding', 'image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'hyperformer_model.l2.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'hyperformer_model.l7.tcn1.branches.2.0.bias', 'hyperformer_model.l7.tcn1.branches.2.1.weight', 'hyperformer_model.l3.vit1.attn.rpe', 'image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.2.0.weight', 'hyperformer_model.l7.tcn1.branches.2.1.bias', 'hyperformer_model.l1.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'hyperformer_model.l8.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.1.ln_2.weight', 'text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'hyperformer_model.l5.tcn1.branches.0.0.weight', 'hyperformer_model.l5.tcn1.branches.3.0.weight', 'hyperformer_model.l9.vit1.attn.w1', 'text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'text_encoder.transformer.resblocks.4.ln_1.bias', 'hyperformer_model.l4.tcn1.branches.2.1.weight', 'hyperformer_model.l8.vit1.attn.outer', 'image_encoder.transformer.resblocks.3.ln_1.weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'text_encoder.transformer.resblocks.4.ln_2.weight', 'hyperformer_model.l5.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l6.tcn1.branches.2.0.bias', 'hyperformer_model.l9.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.8.ln_1.weight', 'text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l7.tcn1.branches.0.3.bn.bias', 'image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'image_encoder.transformer.resblocks.8.ln_1.bias', 'image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'hyperformer_model.l10.vit1.attn.q.weight', 'hyperformer_model.l8.residual.conv.bias', 'hyperformer_model.l6.tcn1.branches.0.3.conv.weight', 'image_encoder.transformer.resblocks.7.ln_1.weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'hyperformer_model.l5.tcn1.branches.1.1.weight', 'hyperformer_model.l7.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l5.vit1.attn.rpe', 'image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'hyperformer_model.l7.vit1.attn.q.weight', 'hyperformer_model.l7.vit1.attn.alpha', 'hyperformer_model.l7.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l10.tcn1.branches.0.1.weight', 'hyperformer_model.l5.vit1.norm1.bias', 'hyperformer_model.l10.vit1.attn.kv.weight', 'hyperformer_model.l9.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'hyperformer_model.l4.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l7.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'hyperformer_model.l5.residual.bn.weight', 'hyperformer_model.l10.vit1.attn.w1', 'image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l6.tcn1.branches.2.0.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'hyperformer_model.l3.vit1.attn.alpha', 'hyperformer_model.l2.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.1.1.bias', 'hyperformer_model.l4.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'hyperformer_model.l3.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l7.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.3.ln_2.bias', 'hyperformer_model.l1.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l3.vit1.attn.proj.bias', 'hyperformer_model.l7.tcn1.branches.3.0.weight', 'hyperformer_model.l8.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l10.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.9.ln_1.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'hyperformer_model.l2.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'hyperformer_model.l2.tcn1.branches.3.1.bias', 'hyperformer_model.l4.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'text_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l1.vit1.attn.alpha', 'hyperformer_model.l10.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.1.ln_2.weight', 'hyperformer_model.l9.tcn1.branches.2.0.bias', 'image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'hyperformer_model.l6.tcn1.branches.1.1.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'hyperformer_model.l2.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l5.vit1.pe_proj.weight', 'hyperformer_model.l2.vit1.norm1.weight', 'text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.l5.tcn1.branches.3.1.bias', 'text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'hyperformer_model.l7.vit1.attn.kv.weight', 'hyperformer_model.l7.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'hyperformer_model.l5.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.0.ln_2.weight', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'hyperformer_model.l7.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.9.ln_2.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l3.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'hyperformer_model.l3.tcn1.branches.2.4.weight', 'hyperformer_model.l4.vit1.attn.q.weight', 'text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'text_encoder.transformer.resblocks.2.ln_1.weight', 'hyperformer_model.l3.tcn1.branches.2.0.weight', 'hyperformer_model.l4.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.2.4.weight', 'hyperformer_model.l3.tcn1.branches.3.0.bias', 'hyperformer_model.l7.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l4.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l4.vit1.attn.alpha', 'hyperformer_model.l8.tcn1.branches.1.0.weight', 'hyperformer_model.l5.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'hyperformer_model.l10.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.7.ln_2.bias', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.8.ln_2.weight', 'image_encoder.transformer.resblocks.4.ln_1.weight', 'text_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l1.residual.conv.bias', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'hyperformer_model.l8.tcn1.branches.2.1.weight', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'hyperformer_model.l8.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.fc2.weight', 'image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'image_encoder.transformer.resblocks.2.ln_2.weight', 'clip_text_encoder.text_projection', 'text_encoder.ln_final.weight', 'clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.l6.vit1.attn.outer', 'clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'hyperformer_model.l5.vit1.attn.w1', 'image_encoder.transformer.resblocks.7.ln_2.bias', 'hyperformer_model.l8.vit1.norm1.weight', 'hyperformer_model.l1.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'hyperformer_model.l9.tcn1.branches.3.0.weight', 'hyperformer_model.l10.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l1.vit1.norm1.bias', 'hyperformer_model.l4.vit1.attn.proj.bias', 'hyperformer_model.l5.residual.bn.bias', 'hyperformer_model.l1.tcn1.branches.2.0.bias', 'hyperformer_model.l7.tcn1.branches.3.1.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'image_encoder.proj', 'hyperformer_model.l4.tcn1.branches.1.1.weight', 'hyperformer_model.l10.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'hyperformer_model.l3.vit1.norm1.bias', 'hyperformer_model.l7.tcn1.branches.1.0.weight', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'hyperformer_model.l1.tcn1.branches.3.1.weight', 'hyperformer_model.l7.vit1.norm1.weight', 'image_encoder.transformer.resblocks.6.ln_1.weight', 'text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.10.ln_2.bias', 'clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'hyperformer_model.l1.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l8.vit1.attn.rpe', 'hyperformer_model.l1.tcn1.branches.1.1.bias', 'hyperformer_model.l5.vit1.attn.outer', 'image_encoder.conv1.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'hyperformer_model.l6.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'text_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l10.vit1.attn.proj.bias', 'hyperformer_model.l2.vit1.pe_proj.weight', 'hyperformer_model.l3.tcn1.branches.1.0.weight', 'hyperformer_model.l3.tcn1.branches.2.4.bias', 'hyperformer_model.l9.tcn1.branches.3.0.bias', 'hyperformer_model.l4.tcn1.branches.1.0.bias', 'hyperformer_model.l6.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.6.ln_1.bias', 'image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'hyperformer_model.l2.tcn1.branches.0.1.weight', 'image_encoder.ln_post.weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.8.ln_1.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l2.vit1.norm1.bias', 'image_encoder.transformer.resblocks.1.ln_1.bias', 'text_encoder.transformer.resblocks.4.ln_2.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'hyperformer_model.l8.tcn1.branches.3.1.bias', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'text_encoder.transformer.resblocks.5.ln_2.weight', 'text_encoder.transformer.resblocks.11.ln_1.weight', 'image_encoder.transformer.resblocks.5.ln_1.bias', 'text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'hyperformer_model.l4.vit1.attn.outer', 'hyperformer_model.l6.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.11.ln_1.weight', 'text_encoder.transformer.resblocks.10.ln_1.weight', 'image_encoder.transformer.resblocks.5.ln_1.weight', 'clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'image_encoder.transformer.resblocks.0.ln_2.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.weight', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.ln_2.bias', 'image_encoder.transformer.resblocks.0.mlp.c_fc.weight'}
[2024-12-24 21:39:58 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 316): INFO Total learnable items: 835
[2024-12-24 21:40:13 ViT-B/16] (tools.py 147): INFO ==============> Resuming from ./workdirs/TEST_P1_SKeletonCLIP_alltrn_HFinit_zs_48_17Dec24/ckpt_epoch_0.pth....................
[2024-12-24 21:40:14 ViT-B/16] (tools.py 172): INFO resume VIFICLIP model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.clip_text_encoder.positional_embedding', 'module.clip_text_encoder.text_projection', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'module.clip_text_encoder.ln_final.weight', 'module.clip_text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:40:14 ViT-B/16] (tools.py 176): INFO ==============> Resuming from /data/users/asinha13/projects/CLIP4ADL/model_chkpnts/ntu_CS_P1_HF_pretrain_frzn_txt_zs_48_AS_16Jan24/ckpt_epoch_99.pth....................
[2024-12-24 21:40:14 ViT-B/16] (tools.py 218): INFO resume Hyperformer model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.text_encoder.positional_embedding', 'module.text_encoder.text_projection', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_1.weight', 'module.text_encoder.transformer.resblocks.0.ln_1.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_2.weight', 'module.text_encoder.transformer.resblocks.0.ln_2.bias', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_1.weight', 'module.text_encoder.transformer.resblocks.1.ln_1.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_2.weight', 'module.text_encoder.transformer.resblocks.1.ln_2.bias', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_1.weight', 'module.text_encoder.transformer.resblocks.2.ln_1.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_2.weight', 'module.text_encoder.transformer.resblocks.2.ln_2.bias', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_1.weight', 'module.text_encoder.transformer.resblocks.3.ln_1.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_2.weight', 'module.text_encoder.transformer.resblocks.3.ln_2.bias', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_1.weight', 'module.text_encoder.transformer.resblocks.4.ln_1.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_2.weight', 'module.text_encoder.transformer.resblocks.4.ln_2.bias', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_1.weight', 'module.text_encoder.transformer.resblocks.5.ln_1.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_2.weight', 'module.text_encoder.transformer.resblocks.5.ln_2.bias', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_1.weight', 'module.text_encoder.transformer.resblocks.6.ln_1.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_2.weight', 'module.text_encoder.transformer.resblocks.6.ln_2.bias', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_1.weight', 'module.text_encoder.transformer.resblocks.7.ln_1.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_2.weight', 'module.text_encoder.transformer.resblocks.7.ln_2.bias', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_1.weight', 'module.text_encoder.transformer.resblocks.8.ln_1.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_2.weight', 'module.text_encoder.transformer.resblocks.8.ln_2.bias', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_1.weight', 'module.text_encoder.transformer.resblocks.9.ln_1.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_2.weight', 'module.text_encoder.transformer.resblocks.9.ln_2.bias', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_1.weight', 'module.text_encoder.transformer.resblocks.10.ln_1.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_2.weight', 'module.text_encoder.transformer.resblocks.10.ln_2.bias', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_1.weight', 'module.text_encoder.transformer.resblocks.11.ln_1.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_2.weight', 'module.text_encoder.transformer.resblocks.11.ln_2.bias', 'module.text_encoder.ln_final.weight', 'module.text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:40:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][0/11317]	eta 17:13:01 lr 0.000022000	time 5.4768 (5.4768)	dist_loss 0.2850 (0.2850)	image_text_loss 3.9417 (3.9417)	pose_text_loss 2.8081 (2.8081)	tot_loss 9.5998 (9.5998)	mem 29650MB
[2024-12-24 21:40:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][50/11317]	eta 1:26:28 lr 0.000021999	time 0.3748 (0.4605)	dist_loss 0.0035 (0.1304)	image_text_loss 3.8673 (3.8683)	pose_text_loss 3.7481 (3.7203)	tot_loss 7.6503 (8.8930)	mem 29650MB
[2024-12-24 21:40:56 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][100/11317]	eta 1:17:44 lr 0.000021996	time 0.3770 (0.4159)	dist_loss 0.0204 (0.0720)	image_text_loss 3.8085 (3.8685)	pose_text_loss 3.5411 (3.7420)	tot_loss 7.5532 (8.3305)	mem 29650MB
[2024-12-24 21:41:14 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][150/11317]	eta 1:14:18 lr 0.000021991	time 0.3681 (0.3993)	dist_loss 0.0059 (0.0526)	image_text_loss 3.7818 (3.8637)	pose_text_loss 3.6942 (3.7226)	tot_loss 7.5350 (8.1124)	mem 29650MB
[2024-12-24 21:41:32 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][200/11317]	eta 1:12:21 lr 0.000021983	time 0.3606 (0.3905)	dist_loss 0.0210 (0.0433)	image_text_loss 3.8914 (3.8682)	pose_text_loss 3.5470 (3.7048)	tot_loss 7.6483 (8.0063)	mem 29650MB
[2024-12-24 21:41:50 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][250/11317]	eta 1:10:42 lr 0.000021974	time 0.3666 (0.3834)	dist_loss 0.0500 (0.0383)	image_text_loss 3.7315 (3.8721)	pose_text_loss 3.2626 (3.6883)	tot_loss 7.4937 (7.9429)	mem 29650MB
[2024-12-24 21:42:08 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][300/11317]	eta 1:09:33 lr 0.000021962	time 0.3634 (0.3789)	dist_loss 0.0125 (0.0351)	image_text_loss 3.8602 (3.8672)	pose_text_loss 3.5787 (3.6620)	tot_loss 7.5636 (7.8802)	mem 29650MB
[2024-12-24 21:42:26 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][350/11317]	eta 1:08:42 lr 0.000021949	time 0.3655 (0.3759)	dist_loss 0.0125 (0.0327)	image_text_loss 3.8698 (3.8703)	pose_text_loss 3.6219 (3.6535)	tot_loss 7.6170 (7.8508)	mem 29650MB
[2024-12-24 21:42:44 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][400/11317]	eta 1:08:01 lr 0.000021933	time 0.3490 (0.3738)	dist_loss 0.0348 (0.0309)	image_text_loss 3.8618 (3.8711)	pose_text_loss 3.1346 (3.6380)	tot_loss 7.3447 (7.8184)	mem 29650MB
[2024-12-24 21:43:01 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][450/11317]	eta 1:07:16 lr 0.000021915	time 0.3450 (0.3714)	dist_loss 0.0173 (0.0296)	image_text_loss 3.8983 (3.8709)	pose_text_loss 3.5064 (3.6216)	tot_loss 7.5776 (7.7886)	mem 29650MB
[2024-12-24 21:43:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][500/11317]	eta 1:06:42 lr 0.000021895	time 0.3501 (0.3700)	dist_loss 0.0227 (0.0287)	image_text_loss 3.7208 (3.8689)	pose_text_loss 3.1443 (3.6074)	tot_loss 7.0917 (7.7633)	mem 29650MB
[2024-12-24 21:43:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][550/11317]	eta 1:06:02 lr 0.000021873	time 0.3474 (0.3681)	dist_loss 0.0380 (0.0283)	image_text_loss 3.7938 (3.8689)	pose_text_loss 3.0414 (3.5967)	tot_loss 7.2149 (7.7482)	mem 29650MB
[2024-12-24 21:43:54 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][600/11317]	eta 1:05:27 lr 0.000021849	time 0.3495 (0.3665)	dist_loss 0.0335 (0.0277)	image_text_loss 3.8850 (3.8702)	pose_text_loss 3.6490 (3.5869)	tot_loss 7.8686 (7.7343)	mem 29650MB
[2024-12-24 21:44:12 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][650/11317]	eta 1:05:02 lr 0.000021823	time 0.3558 (0.3659)	dist_loss 0.0340 (0.0274)	image_text_loss 3.8407 (3.8708)	pose_text_loss 3.4714 (3.5794)	tot_loss 7.6523 (7.7246)	mem 29650MB
[2024-12-24 21:44:30 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][700/11317]	eta 1:04:35 lr 0.000021795	time 0.3547 (0.3650)	dist_loss 0.0155 (0.0274)	image_text_loss 3.8423 (3.8702)	pose_text_loss 3.5321 (3.5613)	tot_loss 7.5293 (7.7049)	mem 29650MB
[2024-12-24 21:44:47 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][750/11317]	eta 1:04:07 lr 0.000021765	time 0.3520 (0.3641)	dist_loss 0.0230 (0.0269)	image_text_loss 3.9088 (3.8708)	pose_text_loss 3.5465 (3.5577)	tot_loss 7.6850 (7.6976)	mem 29650MB
[2024-12-24 21:45:05 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][800/11317]	eta 1:03:46 lr 0.000021733	time 0.3490 (0.3638)	dist_loss 0.0201 (0.0268)	image_text_loss 3.8644 (3.8718)	pose_text_loss 3.4837 (3.5501)	tot_loss 7.5490 (7.6896)	mem 29650MB
[2024-12-24 21:45:23 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][850/11317]	eta 1:03:23 lr 0.000021698	time 0.3363 (0.3633)	dist_loss 0.0397 (0.0268)	image_text_loss 3.8928 (3.8721)	pose_text_loss 3.4056 (3.5394)	tot_loss 7.6948 (7.6796)	mem 29650MB
[2024-12-24 21:45:41 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][900/11317]	eta 1:02:59 lr 0.000021662	time 0.3509 (0.3628)	dist_loss 0.0060 (0.0266)	image_text_loss 3.9660 (3.8712)	pose_text_loss 3.9269 (3.5312)	tot_loss 7.9528 (7.6686)	mem 29650MB
[2024-12-24 21:45:58 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][950/11317]	eta 1:02:37 lr 0.000021624	time 0.3488 (0.3624)	dist_loss 0.0342 (0.0268)	image_text_loss 3.9412 (3.8709)	pose_text_loss 3.5946 (3.5186)	tot_loss 7.8773 (7.6570)	mem 29650MB
[2024-12-24 21:46:16 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1000/11317]	eta 1:02:14 lr 0.000021583	time 0.3519 (0.3620)	dist_loss 0.0278 (0.0267)	image_text_loss 3.8366 (3.8713)	pose_text_loss 3.0950 (3.5120)	tot_loss 7.2094 (7.6503)	mem 29650MB
[2024-12-24 21:46:34 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1050/11317]	eta 1:01:51 lr 0.000021541	time 0.4356 (0.3615)	dist_loss 0.0301 (0.0266)	image_text_loss 3.8491 (3.8715)	pose_text_loss 3.1802 (3.5066)	tot_loss 7.3308 (7.6442)	mem 29650MB
[2024-12-24 21:46:52 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1100/11317]	eta 1:01:32 lr 0.000021496	time 0.3604 (0.3614)	dist_loss 0.0525 (0.0268)	image_text_loss 3.8130 (3.8718)	pose_text_loss 2.5777 (3.4969)	tot_loss 6.9159 (7.6364)	mem 29650MB
[2024-12-24 21:47:09 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1150/11317]	eta 1:01:12 lr 0.000021450	time 0.3537 (0.3612)	dist_loss 0.0158 (0.0268)	image_text_loss 3.9488 (3.8717)	pose_text_loss 3.5797 (3.4900)	tot_loss 7.6869 (7.6296)	mem 29650MB
[2024-12-24 21:47:27 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1200/11317]	eta 1:00:52 lr 0.000021401	time 0.3487 (0.3610)	dist_loss 0.0197 (0.0269)	image_text_loss 3.8220 (3.8716)	pose_text_loss 3.6638 (3.4793)	tot_loss 7.6833 (7.6200)	mem 29650MB
[2024-12-24 21:47:45 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1250/11317]	eta 1:00:32 lr 0.000021351	time 0.3352 (0.3608)	dist_loss 0.0343 (0.0270)	image_text_loss 3.8403 (3.8715)	pose_text_loss 3.1325 (3.4694)	tot_loss 7.3156 (7.6114)	mem 29650MB
[2024-12-24 21:48:03 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1300/11317]	eta 1:00:11 lr 0.000021299	time 0.3500 (0.3605)	dist_loss 0.0197 (0.0270)	image_text_loss 3.7948 (3.8710)	pose_text_loss 3.2324 (3.4628)	tot_loss 7.2244 (7.6043)	mem 29650MB
[2024-12-24 21:48:21 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1350/11317]	eta 0:59:53 lr 0.000021244	time 0.4435 (0.3605)	dist_loss 0.0357 (0.0272)	image_text_loss 3.8672 (3.8721)	pose_text_loss 2.9617 (3.4536)	tot_loss 7.1863 (7.5981)	mem 29650MB
[2024-12-24 21:48:39 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1400/11317]	eta 0:59:33 lr 0.000021188	time 0.3563 (0.3603)	dist_loss 0.0366 (0.0274)	image_text_loss 3.8584 (3.8721)	pose_text_loss 2.9962 (3.4442)	tot_loss 7.2211 (7.5907)	mem 29650MB
[2024-12-24 21:48:56 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1450/11317]	eta 0:59:12 lr 0.000021130	time 0.3435 (0.3600)	dist_loss 0.0456 (0.0275)	image_text_loss 3.8388 (3.8717)	pose_text_loss 2.7693 (3.4374)	tot_loss 7.0636 (7.5839)	mem 29650MB
[2024-12-24 21:49:14 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1500/11317]	eta 0:58:51 lr 0.000021069	time 0.3354 (0.3598)	dist_loss 0.0396 (0.0277)	image_text_loss 3.8598 (3.8715)	pose_text_loss 3.0177 (3.4277)	tot_loss 7.2738 (7.5763)	mem 29650MB
[2024-12-24 21:49:31 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1550/11317]	eta 0:58:32 lr 0.000021007	time 0.3606 (0.3596)	dist_loss 0.0399 (0.0279)	image_text_loss 3.8766 (3.8714)	pose_text_loss 2.8874 (3.4202)	tot_loss 7.1632 (7.5703)	mem 29650MB
[2024-12-24 21:49:49 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1600/11317]	eta 0:58:12 lr 0.000020943	time 0.3464 (0.3594)	dist_loss 0.0318 (0.0280)	image_text_loss 3.9748 (3.8712)	pose_text_loss 3.4189 (3.4118)	tot_loss 7.7114 (7.5634)	mem 29650MB
[2024-12-24 21:50:07 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1650/11317]	eta 0:57:54 lr 0.000020877	time 0.3411 (0.3594)	dist_loss 0.0270 (0.0282)	image_text_loss 3.8314 (3.8712)	pose_text_loss 3.5115 (3.4041)	tot_loss 7.6125 (7.5576)	mem 29650MB
[2024-12-24 21:50:25 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1700/11317]	eta 0:57:35 lr 0.000020810	time 0.3499 (0.3593)	dist_loss 0.0429 (0.0284)	image_text_loss 3.8287 (3.8715)	pose_text_loss 2.6837 (3.3992)	tot_loss 6.9410 (7.5544)	mem 29650MB
[2024-12-24 21:50:43 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1750/11317]	eta 0:57:15 lr 0.000020740	time 0.3440 (0.3591)	dist_loss 0.0538 (0.0285)	image_text_loss 3.8708 (3.8714)	pose_text_loss 2.6049 (3.3933)	tot_loss 7.0139 (7.5498)	mem 29650MB
[2024-12-24 21:51:00 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1800/11317]	eta 0:56:57 lr 0.000020669	time 0.4302 (0.3591)	dist_loss 0.0368 (0.0287)	image_text_loss 3.8634 (3.8714)	pose_text_loss 3.0816 (3.3861)	tot_loss 7.3133 (7.5446)	mem 29650MB
[2024-12-24 21:51:18 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1850/11317]	eta 0:56:37 lr 0.000020595	time 0.3570 (0.3589)	dist_loss 0.0559 (0.0290)	image_text_loss 3.8695 (3.8713)	pose_text_loss 2.6791 (3.3783)	tot_loss 7.1078 (7.5392)	mem 29650MB
[2024-12-24 21:51:36 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1900/11317]	eta 0:56:18 lr 0.000020520	time 0.3661 (0.3588)	dist_loss 0.0492 (0.0290)	image_text_loss 3.8751 (3.8713)	pose_text_loss 2.7567 (3.3732)	tot_loss 7.1243 (7.5350)	mem 29650MB
[2024-12-24 21:51:54 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1950/11317]	eta 0:56:00 lr 0.000020443	time 0.3539 (0.3588)	dist_loss 0.0439 (0.0292)	image_text_loss 3.8716 (3.8713)	pose_text_loss 3.0890 (3.3667)	tot_loss 7.4001 (7.5300)	mem 29650MB
[2024-12-24 21:52:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2000/11317]	eta 0:55:41 lr 0.000020364	time 0.3400 (0.3586)	dist_loss 0.0148 (0.0294)	image_text_loss 3.8411 (3.8713)	pose_text_loss 3.4729 (3.3598)	tot_loss 7.4623 (7.5254)	mem 29650MB
[2024-12-24 21:52:29 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2050/11317]	eta 0:55:22 lr 0.000020284	time 0.3497 (0.3585)	dist_loss 0.0164 (0.0295)	image_text_loss 3.8699 (3.8715)	pose_text_loss 3.5682 (3.3554)	tot_loss 7.6024 (7.5223)	mem 29650MB
[2024-12-24 21:52:47 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2100/11317]	eta 0:55:03 lr 0.000020201	time 0.3575 (0.3584)	dist_loss 0.0455 (0.0296)	image_text_loss 3.8790 (3.8716)	pose_text_loss 2.8924 (3.3508)	tot_loss 7.2259 (7.5188)	mem 29650MB
[2024-12-24 21:53:05 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2150/11317]	eta 0:54:44 lr 0.000020117	time 0.3572 (0.3583)	dist_loss 0.0524 (0.0298)	image_text_loss 3.8731 (3.8717)	pose_text_loss 2.6902 (3.3429)	tot_loss 7.0872 (7.5130)	mem 29650MB
[2024-12-24 21:53:22 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2200/11317]	eta 0:54:26 lr 0.000020031	time 0.3645 (0.3583)	dist_loss 0.0173 (0.0301)	image_text_loss 3.8722 (3.8716)	pose_text_loss 3.4348 (3.3369)	tot_loss 7.4801 (7.5091)	mem 29650MB
[2024-12-24 21:53:40 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2250/11317]	eta 0:54:07 lr 0.000019944	time 0.3510 (0.3582)	dist_loss 0.0519 (0.0302)	image_text_loss 3.8763 (3.8715)	pose_text_loss 2.7592 (3.3316)	tot_loss 7.1544 (7.5054)	mem 29650MB
[2024-12-24 21:53:58 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2300/11317]	eta 0:53:48 lr 0.000019855	time 0.3480 (0.3581)	dist_loss 0.0299 (0.0304)	image_text_loss 3.8737 (3.8715)	pose_text_loss 3.5670 (3.3256)	tot_loss 7.7402 (7.5014)	mem 29650MB
[2024-12-24 21:54:15 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2350/11317]	eta 0:53:29 lr 0.000019764	time 0.3448 (0.3579)	dist_loss 0.0280 (0.0306)	image_text_loss 3.9042 (3.8718)	pose_text_loss 3.2777 (3.3216)	tot_loss 7.4623 (7.4990)	mem 29650MB
[2024-12-24 21:54:33 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2400/11317]	eta 0:53:11 lr 0.000019671	time 0.3610 (0.3579)	dist_loss 0.0341 (0.0308)	image_text_loss 3.8808 (3.8719)	pose_text_loss 3.0784 (3.3161)	tot_loss 7.3001 (7.4955)	mem 29650MB
[2024-12-24 21:54:51 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2450/11317]	eta 0:52:52 lr 0.000019577	time 0.3535 (0.3578)	dist_loss 0.0352 (0.0310)	image_text_loss 3.8617 (3.8721)	pose_text_loss 3.2630 (3.3103)	tot_loss 7.4772 (7.4921)	mem 29650MB
[2024-12-24 21:55:08 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2500/11317]	eta 0:52:33 lr 0.000019481	time 0.3432 (0.3577)	dist_loss 0.0194 (0.0312)	image_text_loss 3.8690 (3.8721)	pose_text_loss 3.5495 (3.3037)	tot_loss 7.6127 (7.4877)	mem 29650MB
[2024-12-24 21:55:26 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2550/11317]	eta 0:52:15 lr 0.000019384	time 0.3495 (0.3576)	dist_loss 0.0242 (0.0314)	image_text_loss 3.8787 (3.8721)	pose_text_loss 3.3881 (3.2969)	tot_loss 7.5091 (7.4831)	mem 29650MB
[2024-12-24 21:55:44 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2600/11317]	eta 0:51:57 lr 0.000019285	time 0.3403 (0.3576)	dist_loss 0.0479 (0.0315)	image_text_loss 3.8615 (3.8719)	pose_text_loss 2.6929 (3.2934)	tot_loss 7.0335 (7.4805)	mem 29650MB
[2024-12-24 21:56:01 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2650/11317]	eta 0:51:38 lr 0.000019184	time 0.3391 (0.3575)	dist_loss 0.0255 (0.0316)	image_text_loss 3.8673 (3.8719)	pose_text_loss 3.4238 (3.2901)	tot_loss 7.5459 (7.4784)	mem 29650MB
[2024-12-24 21:56:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2700/11317]	eta 0:51:20 lr 0.000019082	time 0.3588 (0.3575)	dist_loss 0.0718 (0.0318)	image_text_loss 3.8827 (3.8719)	pose_text_loss 2.4214 (3.2853)	tot_loss 7.0224 (7.4752)	mem 29650MB
[2024-12-24 21:56:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2750/11317]	eta 0:51:02 lr 0.000018978	time 0.3475 (0.3574)	dist_loss 0.0229 (0.0319)	image_text_loss 3.8678 (3.8719)	pose_text_loss 3.2730 (3.2819)	tot_loss 7.3694 (7.4725)	mem 29650MB
[2024-12-24 21:56:55 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2800/11317]	eta 0:50:44 lr 0.000018873	time 0.3628 (0.3574)	dist_loss 0.0149 (0.0320)	image_text_loss 3.7943 (3.8718)	pose_text_loss 3.4916 (3.2779)	tot_loss 7.4345 (7.4695)	mem 29650MB
[2024-12-24 21:57:13 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2850/11317]	eta 0:50:26 lr 0.000018766	time 0.3552 (0.3574)	dist_loss 0.0580 (0.0321)	image_text_loss 3.8799 (3.8719)	pose_text_loss 2.5728 (3.2728)	tot_loss 7.0326 (7.4661)	mem 29650MB
[2024-12-24 21:57:31 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2900/11317]	eta 0:50:08 lr 0.000018658	time 0.3528 (0.3574)	dist_loss 0.0554 (0.0323)	image_text_loss 3.8789 (3.8719)	pose_text_loss 2.6452 (3.2678)	tot_loss 7.0782 (7.4631)	mem 29650MB
[2024-12-24 21:57:48 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2950/11317]	eta 0:49:50 lr 0.000018548	time 0.3555 (0.3574)	dist_loss 0.0412 (0.0325)	image_text_loss 3.8569 (3.8718)	pose_text_loss 2.8607 (3.2627)	tot_loss 7.1296 (7.4595)	mem 29650MB
[2024-12-24 21:58:06 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3000/11317]	eta 0:49:32 lr 0.000018437	time 0.3618 (0.3574)	dist_loss 0.0605 (0.0327)	image_text_loss 3.8673 (3.8718)	pose_text_loss 2.4699 (3.2571)	tot_loss 6.9419 (7.4560)	mem 29650MB
[2024-12-24 21:58:24 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3050/11317]	eta 0:49:14 lr 0.000018324	time 0.3536 (0.3574)	dist_loss 0.0518 (0.0329)	image_text_loss 3.8723 (3.8718)	pose_text_loss 2.6703 (3.2521)	tot_loss 7.0608 (7.4525)	mem 29650MB
[2024-12-24 21:58:42 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3100/11317]	eta 0:48:56 lr 0.000018210	time 0.3533 (0.3573)	dist_loss 0.0365 (0.0330)	image_text_loss 3.8696 (3.8718)	pose_text_loss 3.4515 (3.2480)	tot_loss 7.6858 (7.4499)	mem 29650MB
[2024-12-24 21:59:00 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3150/11317]	eta 0:48:38 lr 0.000018095	time 0.3633 (0.3574)	dist_loss 0.0932 (0.0331)	image_text_loss 3.8691 (3.8718)	pose_text_loss 2.1505 (3.2454)	tot_loss 6.9516 (7.4483)	mem 29650MB
[2024-12-24 21:59:18 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3200/11317]	eta 0:48:20 lr 0.000017979	time 0.3545 (0.3573)	dist_loss 0.0531 (0.0333)	image_text_loss 3.8703 (3.8718)	pose_text_loss 2.7259 (3.2414)	tot_loss 7.1274 (7.4458)	mem 29650MB
[2024-12-24 21:59:35 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3250/11317]	eta 0:48:01 lr 0.000017861	time 0.3613 (0.3573)	dist_loss 0.0266 (0.0334)	image_text_loss 3.8715 (3.8718)	pose_text_loss 3.8701 (3.2383)	tot_loss 8.0079 (7.4441)	mem 29650MB
[2024-12-24 21:59:53 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3300/11317]	eta 0:47:44 lr 0.000017741	time 0.3536 (0.3572)	dist_loss 0.0352 (0.0335)	image_text_loss 3.8739 (3.8717)	pose_text_loss 3.0854 (3.2343)	tot_loss 7.3111 (7.4412)	mem 29650MB
[2024-12-24 22:00:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3350/11317]	eta 0:47:25 lr 0.000017621	time 0.3519 (0.3572)	dist_loss 0.0624 (0.0337)	image_text_loss 3.8716 (3.8717)	pose_text_loss 2.4631 (3.2279)	tot_loss 6.9586 (7.4370)	mem 29650MB
[2024-12-24 22:00:28 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3400/11317]	eta 0:47:07 lr 0.000017499	time 0.3468 (0.3571)	dist_loss 0.0210 (0.0339)	image_text_loss 3.8708 (3.8717)	pose_text_loss 3.5195 (3.2237)	tot_loss 7.6001 (7.4341)	mem 29650MB
[2024-12-24 22:00:46 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3450/11317]	eta 0:46:49 lr 0.000017376	time 0.3566 (0.3572)	dist_loss 0.0613 (0.0340)	image_text_loss 3.8738 (3.8717)	pose_text_loss 2.4628 (3.2202)	tot_loss 6.9496 (7.4317)	mem 29650MB
[2024-12-24 22:01:04 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3500/11317]	eta 0:46:31 lr 0.000017252	time 0.3534 (0.3571)	dist_loss 0.0452 (0.0341)	image_text_loss 3.8702 (3.8717)	pose_text_loss 2.8123 (3.2160)	tot_loss 7.1348 (7.4289)	mem 29650MB
[2024-12-24 22:01:22 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3550/11317]	eta 0:46:13 lr 0.000017126	time 0.3607 (0.3571)	dist_loss 0.0463 (0.0342)	image_text_loss 3.8685 (3.8717)	pose_text_loss 3.2437 (3.2120)	tot_loss 7.5751 (7.4260)	mem 29650MB
[2024-12-24 22:01:40 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3600/11317]	eta 0:45:55 lr 0.000017000	time 0.3513 (0.3571)	dist_loss 0.0274 (0.0344)	image_text_loss 3.8464 (3.8717)	pose_text_loss 3.4434 (3.2076)	tot_loss 7.5637 (7.4232)	mem 29650MB
[2024-12-24 22:01:58 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3650/11317]	eta 0:45:37 lr 0.000016872	time 0.3583 (0.3571)	dist_loss 0.0611 (0.0346)	image_text_loss 3.8728 (3.8717)	pose_text_loss 2.5453 (3.2026)	tot_loss 7.0287 (7.4201)	mem 29650MB
[2024-12-24 22:02:15 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3700/11317]	eta 0:45:19 lr 0.000016743	time 0.3482 (0.3570)	dist_loss 0.0310 (0.0347)	image_text_loss 3.8781 (3.8717)	pose_text_loss 3.0700 (3.1981)	tot_loss 7.2577 (7.4169)	mem 29650MB
[2024-12-24 22:02:33 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3750/11317]	eta 0:45:01 lr 0.000016613	time 0.3430 (0.3571)	dist_loss 0.0264 (0.0348)	image_text_loss 3.8725 (3.8717)	pose_text_loss 3.2606 (3.1951)	tot_loss 7.3975 (7.4147)	mem 29650MB
[2024-12-24 22:02:51 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3800/11317]	eta 0:44:43 lr 0.000016482	time 0.3543 (0.3571)	dist_loss 0.0641 (0.0349)	image_text_loss 3.8716 (3.8717)	pose_text_loss 2.4439 (3.1919)	tot_loss 6.9560 (7.4126)	mem 29650MB
[2024-12-24 22:03:09 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3850/11317]	eta 0:44:25 lr 0.000016350	time 0.3579 (0.3570)	dist_loss 0.0692 (0.0350)	image_text_loss 3.8723 (3.8717)	pose_text_loss 2.3918 (3.1887)	tot_loss 6.9564 (7.4106)	mem 29650MB
[2024-12-24 22:03:27 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3900/11317]	eta 0:44:08 lr 0.000016217	time 0.3436 (0.3571)	dist_loss 0.0647 (0.0351)	image_text_loss 3.8600 (3.8717)	pose_text_loss 2.4028 (3.1859)	tot_loss 6.9102 (7.4087)	mem 29650MB
[2024-12-24 22:03:45 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3950/11317]	eta 0:43:50 lr 0.000016083	time 0.3463 (0.3571)	dist_loss 0.0649 (0.0352)	image_text_loss 3.8723 (3.8716)	pose_text_loss 2.4621 (3.1826)	tot_loss 6.9834 (7.4065)	mem 29650MB
[2024-12-24 22:04:02 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4000/11317]	eta 0:43:32 lr 0.000015948	time 0.3520 (0.3570)	dist_loss 0.0373 (0.0353)	image_text_loss 3.8752 (3.8716)	pose_text_loss 3.3102 (3.1788)	tot_loss 7.5586 (7.4039)	mem 29650MB
[2024-12-24 22:04:20 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4050/11317]	eta 0:43:14 lr 0.000015813	time 0.3574 (0.3570)	dist_loss 0.0426 (0.0354)	image_text_loss 3.9724 (3.8717)	pose_text_loss 2.8717 (3.1760)	tot_loss 7.2697 (7.4019)	mem 29650MB
[2024-12-24 22:04:38 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4100/11317]	eta 0:42:56 lr 0.000015676	time 0.3499 (0.3570)	dist_loss 0.0539 (0.0355)	image_text_loss 3.8687 (3.8717)	pose_text_loss 2.5957 (3.1731)	tot_loss 7.0032 (7.3999)	mem 29650MB
[2024-12-24 22:04:56 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4150/11317]	eta 0:42:38 lr 0.000015538	time 0.3580 (0.3570)	dist_loss 0.0393 (0.0356)	image_text_loss 3.8720 (3.8717)	pose_text_loss 2.8345 (3.1706)	tot_loss 7.0994 (7.3980)	mem 29650MB
[2024-12-24 22:05:13 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4200/11317]	eta 0:42:20 lr 0.000015400	time 0.3455 (0.3569)	dist_loss 0.0381 (0.0357)	image_text_loss 3.8734 (3.8717)	pose_text_loss 2.8653 (3.1668)	tot_loss 7.1197 (7.3956)	mem 29650MB
[2024-12-24 22:05:31 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4250/11317]	eta 0:42:02 lr 0.000015260	time 0.3569 (0.3569)	dist_loss 0.0539 (0.0358)	image_text_loss 3.8668 (3.8717)	pose_text_loss 2.6161 (3.1639)	tot_loss 7.0219 (7.3937)	mem 29650MB
[2024-12-24 22:05:49 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4300/11317]	eta 0:41:44 lr 0.000015120	time 0.3488 (0.3569)	dist_loss 0.0631 (0.0359)	image_text_loss 3.9012 (3.8717)	pose_text_loss 2.4576 (3.1603)	tot_loss 6.9901 (7.3914)	mem 29650MB
[2024-12-24 22:06:07 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4350/11317]	eta 0:41:26 lr 0.000014979	time 0.3578 (0.3569)	dist_loss 0.0447 (0.0361)	image_text_loss 3.8460 (3.8717)	pose_text_loss 2.6371 (3.1560)	tot_loss 6.9300 (7.3884)	mem 29650MB
[2024-12-24 22:06:25 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4400/11317]	eta 0:41:08 lr 0.000014838	time 0.3495 (0.3569)	dist_loss 0.0798 (0.0362)	image_text_loss 3.8821 (3.8717)	pose_text_loss 2.2691 (3.1522)	tot_loss 6.9491 (7.3862)	mem 29650MB
[2024-12-24 22:06:42 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4450/11317]	eta 0:40:50 lr 0.000014695	time 0.3456 (0.3569)	dist_loss 0.0478 (0.0364)	image_text_loss 3.8772 (3.8717)	pose_text_loss 2.6888 (3.1487)	tot_loss 7.0437 (7.3840)	mem 29650MB
[2024-12-24 22:07:00 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4500/11317]	eta 0:40:33 lr 0.000014552	time 0.3464 (0.3569)	dist_loss 0.0552 (0.0364)	image_text_loss 3.8726 (3.8717)	pose_text_loss 2.6291 (3.1464)	tot_loss 7.0539 (7.3825)	mem 29650MB
[2024-12-24 22:07:18 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4550/11317]	eta 0:40:15 lr 0.000014408	time 0.3524 (0.3569)	dist_loss 0.0396 (0.0366)	image_text_loss 3.8715 (3.8717)	pose_text_loss 2.8731 (3.1433)	tot_loss 7.1405 (7.3807)	mem 29650MB
[2024-12-24 22:07:36 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4600/11317]	eta 0:39:56 lr 0.000014264	time 0.3718 (0.3568)	dist_loss 0.0340 (0.0366)	image_text_loss 3.8701 (3.8717)	pose_text_loss 3.0436 (3.1412)	tot_loss 7.2537 (7.3790)	mem 29650MB
[2024-12-24 22:07:54 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4650/11317]	eta 0:39:39 lr 0.000014119	time 0.4480 (0.3569)	dist_loss 0.0281 (0.0367)	image_text_loss 3.8984 (3.8717)	pose_text_loss 3.4415 (3.1374)	tot_loss 7.6212 (7.3764)	mem 29650MB
[2024-12-24 22:08:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4700/11317]	eta 0:39:21 lr 0.000013974	time 0.3534 (0.3569)	dist_loss 0.0311 (0.0369)	image_text_loss 3.8678 (3.8716)	pose_text_loss 3.5612 (3.1335)	tot_loss 7.7400 (7.3737)	mem 29650MB
[2024-12-24 22:08:29 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4750/11317]	eta 0:39:03 lr 0.000013827	time 0.3590 (0.3568)	dist_loss 0.0350 (0.0370)	image_text_loss 3.8770 (3.8716)	pose_text_loss 2.8920 (3.1302)	tot_loss 7.1195 (7.3714)	mem 29650MB
[2024-12-24 22:08:47 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4800/11317]	eta 0:38:45 lr 0.000013681	time 0.3572 (0.3569)	dist_loss 0.0585 (0.0370)	image_text_loss 3.8755 (3.8716)	pose_text_loss 2.6021 (3.1277)	tot_loss 7.0623 (7.3697)	mem 29650MB
[2024-12-24 22:09:05 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4850/11317]	eta 0:38:27 lr 0.000013534	time 0.3541 (0.3568)	dist_loss 0.0664 (0.0371)	image_text_loss 3.8718 (3.8715)	pose_text_loss 2.5338 (3.1257)	tot_loss 7.0695 (7.3683)	mem 29650MB
[2024-12-24 22:09:22 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4900/11317]	eta 0:38:09 lr 0.000013386	time 0.3491 (0.3568)	dist_loss 0.0610 (0.0372)	image_text_loss 3.8738 (3.8714)	pose_text_loss 2.5313 (3.1241)	tot_loss 7.0153 (7.3673)	mem 29650MB
[2024-12-24 22:09:40 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4950/11317]	eta 0:37:51 lr 0.000013238	time 0.3463 (0.3568)	dist_loss 0.0526 (0.0373)	image_text_loss 3.9561 (3.8714)	pose_text_loss 2.7234 (3.1200)	tot_loss 7.2057 (7.3646)	mem 29650MB
[2024-12-24 22:09:58 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5000/11317]	eta 0:37:33 lr 0.000013090	time 0.3577 (0.3568)	dist_loss 0.0678 (0.0375)	image_text_loss 3.9023 (3.8714)	pose_text_loss 2.4307 (3.1163)	tot_loss 7.0113 (7.3622)	mem 29650MB
[2024-12-24 22:10:16 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5050/11317]	eta 0:37:16 lr 0.000012941	time 0.3619 (0.3568)	dist_loss 0.0582 (0.0375)	image_text_loss 3.8744 (3.8714)	pose_text_loss 2.5544 (3.1138)	tot_loss 7.0107 (7.3606)	mem 29650MB
[2024-12-24 22:10:34 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5100/11317]	eta 0:36:58 lr 0.000012792	time 0.3528 (0.3569)	dist_loss 0.0369 (0.0376)	image_text_loss 3.8829 (3.8714)	pose_text_loss 2.9857 (3.1118)	tot_loss 7.2378 (7.3591)	mem 29650MB
[2024-12-24 22:10:52 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5150/11317]	eta 0:36:40 lr 0.000012642	time 0.3638 (0.3568)	dist_loss 0.0441 (0.0377)	image_text_loss 3.8709 (3.8714)	pose_text_loss 2.8848 (3.1100)	tot_loss 7.1970 (7.3579)	mem 29650MB
[2024-12-24 22:11:10 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5200/11317]	eta 0:36:22 lr 0.000012492	time 0.3621 (0.3568)	dist_loss 0.0689 (0.0378)	image_text_loss 3.8722 (3.8714)	pose_text_loss 2.3546 (3.1072)	tot_loss 6.9160 (7.3562)	mem 29650MB
[2024-12-24 22:11:28 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5250/11317]	eta 0:36:05 lr 0.000012342	time 0.3560 (0.3569)	dist_loss 0.0299 (0.0378)	image_text_loss 3.8721 (3.8714)	pose_text_loss 3.1620 (3.1049)	tot_loss 7.3332 (7.3547)	mem 29650MB
[2024-12-24 22:11:46 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5300/11317]	eta 0:35:47 lr 0.000012192	time 0.3486 (0.3569)	dist_loss 0.0244 (0.0379)	image_text_loss 3.8715 (3.8714)	pose_text_loss 3.3455 (3.1022)	tot_loss 7.4611 (7.3529)	mem 29650MB
[2024-12-24 22:12:03 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5350/11317]	eta 0:35:29 lr 0.000012041	time 0.3567 (0.3569)	dist_loss 0.0252 (0.0380)	image_text_loss 3.8682 (3.8714)	pose_text_loss 3.2058 (3.1008)	tot_loss 7.3256 (7.3518)	mem 29650MB
[2024-12-24 22:12:21 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5400/11317]	eta 0:35:11 lr 0.000011891	time 0.3539 (0.3569)	dist_loss 0.0359 (0.0381)	image_text_loss 3.8651 (3.8714)	pose_text_loss 2.8551 (3.0981)	tot_loss 7.0789 (7.3500)	mem 29650MB
[2024-12-24 22:12:39 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5450/11317]	eta 0:34:53 lr 0.000011740	time 0.3569 (0.3569)	dist_loss 0.0231 (0.0381)	image_text_loss 3.8717 (3.8714)	pose_text_loss 3.3899 (3.0962)	tot_loss 7.4923 (7.3487)	mem 29650MB
[2024-12-24 22:12:57 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5500/11317]	eta 0:34:36 lr 0.000011589	time 0.3527 (0.3569)	dist_loss 0.0445 (0.0382)	image_text_loss 3.9057 (3.8714)	pose_text_loss 2.8806 (3.0939)	tot_loss 7.2317 (7.3470)	mem 29650MB
[2024-12-24 22:13:15 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5550/11317]	eta 0:34:18 lr 0.000011438	time 0.3569 (0.3569)	dist_loss 0.0441 (0.0382)	image_text_loss 3.8801 (3.8713)	pose_text_loss 2.8018 (3.0929)	tot_loss 7.1229 (7.3461)	mem 29650MB
[2024-12-24 22:13:33 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5600/11317]	eta 0:34:00 lr 0.000011287	time 0.3558 (0.3569)	dist_loss 0.0863 (0.0383)	image_text_loss 3.8736 (3.8713)	pose_text_loss 2.1750 (3.0895)	tot_loss 6.9119 (7.3440)	mem 29650MB
[2024-12-24 22:13:51 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5650/11317]	eta 0:33:42 lr 0.000011136	time 0.3522 (0.3569)	dist_loss 0.0211 (0.0384)	image_text_loss 3.8410 (3.8713)	pose_text_loss 3.3985 (3.0875)	tot_loss 7.4504 (7.3425)	mem 29650MB
[2024-12-24 22:14:09 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5700/11317]	eta 0:33:24 lr 0.000010985	time 0.3531 (0.3569)	dist_loss 0.0558 (0.0385)	image_text_loss 3.8610 (3.8712)	pose_text_loss 2.5175 (3.0852)	tot_loss 6.9369 (7.3411)	mem 29650MB
[2024-12-24 22:14:26 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5750/11317]	eta 0:33:06 lr 0.000010833	time 0.3528 (0.3569)	dist_loss 0.0298 (0.0385)	image_text_loss 3.8630 (3.8712)	pose_text_loss 3.4922 (3.0839)	tot_loss 7.6531 (7.3403)	mem 29650MB
[2024-12-24 22:14:44 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5800/11317]	eta 0:32:49 lr 0.000010682	time 0.3492 (0.3569)	dist_loss 0.0831 (0.0385)	image_text_loss 3.8727 (3.8712)	pose_text_loss 2.2522 (3.0829)	tot_loss 6.9555 (7.3395)	mem 29650MB
[2024-12-24 22:15:02 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5850/11317]	eta 0:32:31 lr 0.000010531	time 0.3590 (0.3569)	dist_loss 0.0366 (0.0386)	image_text_loss 3.8729 (3.8712)	pose_text_loss 3.0032 (3.0811)	tot_loss 7.2421 (7.3382)	mem 29650MB
[2024-12-24 22:15:20 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5900/11317]	eta 0:32:13 lr 0.000010380	time 0.3644 (0.3569)	dist_loss 0.0248 (0.0387)	image_text_loss 3.8630 (3.8712)	pose_text_loss 3.4384 (3.0790)	tot_loss 7.5491 (7.3367)	mem 29650MB
[2024-12-24 22:15:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5950/11317]	eta 0:31:55 lr 0.000010230	time 0.3641 (0.3569)	dist_loss 0.0514 (0.0387)	image_text_loss 3.8675 (3.8712)	pose_text_loss 2.6088 (3.0771)	tot_loss 6.9905 (7.3354)	mem 29650MB
[2024-12-24 22:15:56 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6000/11317]	eta 0:31:37 lr 0.000010079	time 0.3446 (0.3569)	dist_loss 0.0255 (0.0387)	image_text_loss 3.8571 (3.8712)	pose_text_loss 3.0356 (3.0761)	tot_loss 7.1478 (7.3346)	mem 29650MB
[2024-12-24 22:16:14 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6050/11317]	eta 0:31:19 lr 0.000009929	time 0.3577 (0.3569)	dist_loss 0.0610 (0.0388)	image_text_loss 3.8741 (3.8712)	pose_text_loss 2.4729 (3.0739)	tot_loss 6.9568 (7.3330)	mem 29650MB
[2024-12-24 22:16:31 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6100/11317]	eta 0:31:02 lr 0.000009779	time 0.3545 (0.3569)	dist_loss 0.0481 (0.0388)	image_text_loss 3.8655 (3.8712)	pose_text_loss 2.6468 (3.0732)	tot_loss 6.9935 (7.3325)	mem 29650MB
[2024-12-24 22:16:49 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6150/11317]	eta 0:30:44 lr 0.000009629	time 0.3621 (0.3569)	dist_loss 0.0195 (0.0389)	image_text_loss 3.8726 (3.8712)	pose_text_loss 3.4613 (3.0712)	tot_loss 7.5291 (7.3312)	mem 29650MB
[2024-12-24 22:17:07 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6200/11317]	eta 0:30:26 lr 0.000009479	time 0.3515 (0.3569)	dist_loss 0.0358 (0.0389)	image_text_loss 3.8688 (3.8712)	pose_text_loss 2.8678 (3.0695)	tot_loss 7.0947 (7.3301)	mem 29650MB
[2024-12-24 22:17:25 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6250/11317]	eta 0:30:08 lr 0.000009330	time 0.3752 (0.3569)	dist_loss 0.0083 (0.0390)	image_text_loss 3.8879 (3.8712)	pose_text_loss 3.8259 (3.0673)	tot_loss 7.7964 (7.3287)	mem 29650MB
[2024-12-24 22:17:43 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6300/11317]	eta 0:29:50 lr 0.000009181	time 0.3404 (0.3570)	dist_loss 0.0220 (0.0391)	image_text_loss 3.8714 (3.8712)	pose_text_loss 3.5699 (3.0658)	tot_loss 7.6615 (7.3278)	mem 29650MB
[2024-12-24 22:18:01 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6350/11317]	eta 0:29:32 lr 0.000009032	time 0.3527 (0.3569)	dist_loss 0.0571 (0.0392)	image_text_loss 3.8783 (3.8712)	pose_text_loss 2.5454 (3.0634)	tot_loss 6.9943 (7.3263)	mem 29650MB
[2024-12-24 22:18:18 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6400/11317]	eta 0:29:15 lr 0.000008884	time 0.3574 (0.3569)	dist_loss 0.0410 (0.0392)	image_text_loss 3.8678 (3.8712)	pose_text_loss 2.7646 (3.0625)	tot_loss 7.0420 (7.3255)	mem 29650MB
[2024-12-24 22:18:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6450/11317]	eta 0:28:57 lr 0.000008736	time 0.3589 (0.3570)	dist_loss 0.0715 (0.0392)	image_text_loss 3.8831 (3.8712)	pose_text_loss 2.3304 (3.0608)	tot_loss 6.9285 (7.3243)	mem 29650MB
[2024-12-24 22:18:54 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6500/11317]	eta 0:28:39 lr 0.000008589	time 0.3649 (0.3570)	dist_loss 0.0542 (0.0393)	image_text_loss 3.8747 (3.8712)	pose_text_loss 2.7051 (3.0589)	tot_loss 7.1216 (7.3231)	mem 29650MB
[2024-12-24 22:19:12 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6550/11317]	eta 0:28:21 lr 0.000008442	time 0.3551 (0.3569)	dist_loss 0.0345 (0.0393)	image_text_loss 3.8862 (3.8712)	pose_text_loss 3.0728 (3.0580)	tot_loss 7.3039 (7.3227)	mem 29650MB
[2024-12-24 22:19:30 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6600/11317]	eta 0:28:03 lr 0.000008296	time 0.3535 (0.3570)	dist_loss 0.0505 (0.0394)	image_text_loss 3.8745 (3.8712)	pose_text_loss 2.7028 (3.0564)	tot_loss 7.0826 (7.3215)	mem 29650MB
[2024-12-24 22:19:48 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6650/11317]	eta 0:27:46 lr 0.000008150	time 0.3574 (0.3570)	dist_loss 0.0076 (0.0394)	image_text_loss 3.8684 (3.8712)	pose_text_loss 3.8201 (3.0549)	tot_loss 7.7648 (7.3204)	mem 29650MB
[2024-12-24 22:20:06 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6700/11317]	eta 0:27:27 lr 0.000008005	time 0.3468 (0.3569)	dist_loss 0.0223 (0.0395)	image_text_loss 3.8585 (3.8712)	pose_text_loss 3.3876 (3.0534)	tot_loss 7.4689 (7.3193)	mem 29650MB
[2024-12-24 22:20:23 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6750/11317]	eta 0:27:10 lr 0.000007861	time 0.3424 (0.3569)	dist_loss 0.0458 (0.0395)	image_text_loss 3.8766 (3.8712)	pose_text_loss 2.7095 (3.0519)	tot_loss 7.0442 (7.3185)	mem 29650MB
[2024-12-24 22:20:41 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6800/11317]	eta 0:26:52 lr 0.000007717	time 0.3617 (0.3569)	dist_loss 0.0855 (0.0395)	image_text_loss 3.8617 (3.8712)	pose_text_loss 2.1933 (3.0509)	tot_loss 6.9102 (7.3176)	mem 29650MB
[2024-12-24 22:20:59 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6850/11317]	eta 0:26:34 lr 0.000007573	time 0.3626 (0.3569)	dist_loss 0.0449 (0.0396)	image_text_loss 3.8746 (3.8712)	pose_text_loss 2.8727 (3.0497)	tot_loss 7.1965 (7.3167)	mem 29650MB
[2024-12-24 22:21:17 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6900/11317]	eta 0:26:16 lr 0.000007431	time 0.3486 (0.3569)	dist_loss 0.0632 (0.0396)	image_text_loss 3.8488 (3.8712)	pose_text_loss 2.4692 (3.0483)	tot_loss 6.9502 (7.3157)	mem 29650MB
[2024-12-24 22:21:34 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6950/11317]	eta 0:25:58 lr 0.000007289	time 0.3534 (0.3569)	dist_loss 0.0428 (0.0397)	image_text_loss 3.8663 (3.8712)	pose_text_loss 2.7277 (3.0464)	tot_loss 7.0219 (7.3144)	mem 29650MB
[2024-12-24 22:21:52 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7000/11317]	eta 0:25:40 lr 0.000007148	time 0.3599 (0.3569)	dist_loss 0.0486 (0.0397)	image_text_loss 3.8683 (3.8712)	pose_text_loss 2.6847 (3.0445)	tot_loss 7.0385 (7.3130)	mem 29650MB
[2024-12-24 22:22:10 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7050/11317]	eta 0:25:22 lr 0.000007007	time 0.3510 (0.3568)	dist_loss 0.0570 (0.0398)	image_text_loss 3.8733 (3.8712)	pose_text_loss 2.5343 (3.0426)	tot_loss 6.9775 (7.3117)	mem 29650MB
[2024-12-24 22:22:27 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7100/11317]	eta 0:25:04 lr 0.000006868	time 0.3497 (0.3568)	dist_loss 0.0912 (0.0399)	image_text_loss 3.8580 (3.8712)	pose_text_loss 2.1284 (3.0406)	tot_loss 6.8986 (7.3104)	mem 29650MB
[2024-12-24 22:22:45 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7150/11317]	eta 0:24:46 lr 0.000006729	time 0.3473 (0.3568)	dist_loss 0.0639 (0.0399)	image_text_loss 3.8723 (3.8712)	pose_text_loss 2.4963 (3.0387)	tot_loss 7.0075 (7.3092)	mem 29650MB
[2024-12-24 22:23:03 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7200/11317]	eta 0:24:28 lr 0.000006591	time 0.3472 (0.3568)	dist_loss 0.0421 (0.0400)	image_text_loss 3.8720 (3.8712)	pose_text_loss 3.0294 (3.0368)	tot_loss 7.3224 (7.3080)	mem 29650MB
[2024-12-24 22:23:21 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7250/11317]	eta 0:24:10 lr 0.000006454	time 0.3404 (0.3568)	dist_loss 0.0765 (0.0401)	image_text_loss 3.8563 (3.8712)	pose_text_loss 2.2584 (3.0351)	tot_loss 6.8795 (7.3070)	mem 29650MB
[2024-12-24 22:23:38 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7300/11317]	eta 0:23:53 lr 0.000006318	time 0.3639 (0.3568)	dist_loss 0.0785 (0.0401)	image_text_loss 3.8678 (3.8712)	pose_text_loss 2.2439 (3.0337)	tot_loss 6.8965 (7.3060)	mem 29650MB
[2024-12-24 22:23:57 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7350/11317]	eta 0:23:35 lr 0.000006182	time 0.3451 (0.3568)	dist_loss 0.0605 (0.0402)	image_text_loss 3.8661 (3.8712)	pose_text_loss 3.8671 (3.0324)	tot_loss 8.3381 (7.3052)	mem 29650MB
[2024-12-24 22:24:15 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7400/11317]	eta 0:23:17 lr 0.000006048	time 0.3612 (0.3568)	dist_loss 0.0296 (0.0402)	image_text_loss 3.8612 (3.8712)	pose_text_loss 3.1162 (3.0312)	tot_loss 7.2735 (7.3043)	mem 29650MB
[2024-12-24 22:24:32 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7450/11317]	eta 0:22:59 lr 0.000005915	time 0.3639 (0.3568)	dist_loss 0.0649 (0.0402)	image_text_loss 3.8705 (3.8712)	pose_text_loss 2.4344 (3.0299)	tot_loss 6.9543 (7.3034)	mem 29650MB
[2024-12-24 22:24:51 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7500/11317]	eta 0:22:42 lr 0.000005782	time 0.3510 (0.3569)	dist_loss 0.0316 (0.0403)	image_text_loss 3.8667 (3.8712)	pose_text_loss 3.5964 (3.0284)	tot_loss 7.7791 (7.3024)	mem 29650MB
[2024-12-24 22:25:08 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7550/11317]	eta 0:22:24 lr 0.000005651	time 0.3480 (0.3569)	dist_loss 0.0361 (0.0404)	image_text_loss 3.8973 (3.8711)	pose_text_loss 3.2505 (3.0263)	tot_loss 7.5086 (7.3010)	mem 29650MB
[2024-12-24 22:25:26 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7600/11317]	eta 0:22:06 lr 0.000005521	time 0.3535 (0.3568)	dist_loss 0.0786 (0.0404)	image_text_loss 3.8898 (3.8711)	pose_text_loss 2.3102 (3.0250)	tot_loss 6.9856 (7.3002)	mem 29650MB
[2024-12-24 22:25:44 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7650/11317]	eta 0:21:48 lr 0.000005392	time 0.3538 (0.3569)	dist_loss 0.0436 (0.0404)	image_text_loss 3.8706 (3.8711)	pose_text_loss 2.8295 (3.0243)	tot_loss 7.1366 (7.2997)	mem 29650MB
[2024-12-24 22:26:02 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7700/11317]	eta 0:21:30 lr 0.000005264	time 0.3575 (0.3569)	dist_loss 0.0690 (0.0405)	image_text_loss 3.8732 (3.8711)	pose_text_loss 2.3811 (3.0228)	tot_loss 6.9443 (7.2987)	mem 29650MB
[2024-12-24 22:26:20 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7750/11317]	eta 0:21:12 lr 0.000005137	time 0.3581 (0.3568)	dist_loss 0.0192 (0.0405)	image_text_loss 3.8609 (3.8711)	pose_text_loss 3.5206 (3.0215)	tot_loss 7.5734 (7.2979)	mem 29650MB
[2024-12-24 22:26:38 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7800/11317]	eta 0:20:55 lr 0.000005011	time 0.3547 (0.3569)	dist_loss 0.0215 (0.0406)	image_text_loss 3.8776 (3.8711)	pose_text_loss 3.3613 (3.0197)	tot_loss 7.4542 (7.2968)	mem 29650MB
[2024-12-24 22:26:55 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7850/11317]	eta 0:20:37 lr 0.000004886	time 0.3437 (0.3569)	dist_loss 0.0175 (0.0407)	image_text_loss 3.8688 (3.8711)	pose_text_loss 3.4839 (3.0181)	tot_loss 7.5272 (7.2957)	mem 29650MB
[2024-12-24 22:27:13 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7900/11317]	eta 0:20:19 lr 0.000004763	time 0.3389 (0.3569)	dist_loss 0.0211 (0.0407)	image_text_loss 3.8642 (3.8711)	pose_text_loss 3.3668 (3.0170)	tot_loss 7.4422 (7.2950)	mem 29650MB
[2024-12-24 22:27:31 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7950/11317]	eta 0:20:01 lr 0.000004640	time 0.3514 (0.3569)	dist_loss 0.0377 (0.0407)	image_text_loss 3.8691 (3.8711)	pose_text_loss 3.1517 (3.0157)	tot_loss 7.3977 (7.2942)	mem 29650MB
[2024-12-24 22:27:49 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8000/11317]	eta 0:19:43 lr 0.000004520	time 0.3663 (0.3569)	dist_loss 0.0406 (0.0408)	image_text_loss 3.8753 (3.8711)	pose_text_loss 3.0536 (3.0139)	tot_loss 7.3350 (7.2931)	mem 29650MB
[2024-12-24 22:28:07 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8050/11317]	eta 0:19:25 lr 0.000004400	time 0.3673 (0.3569)	dist_loss 0.0308 (0.0408)	image_text_loss 3.8688 (3.8711)	pose_text_loss 3.0864 (3.0130)	tot_loss 7.2629 (7.2925)	mem 29650MB
[2024-12-24 22:28:25 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8100/11317]	eta 0:19:08 lr 0.000004281	time 0.3463 (0.3569)	dist_loss 0.0396 (0.0409)	image_text_loss 3.8794 (3.8711)	pose_text_loss 2.8688 (3.0116)	tot_loss 7.1437 (7.2916)	mem 29650MB
[2024-12-24 22:28:43 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8150/11317]	eta 0:18:50 lr 0.000004164	time 0.3744 (0.3569)	dist_loss 0.0600 (0.0409)	image_text_loss 3.8340 (3.8711)	pose_text_loss 2.4559 (3.0103)	tot_loss 6.8896 (7.2907)	mem 29650MB
[2024-12-24 22:29:01 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8200/11317]	eta 0:18:32 lr 0.000004049	time 0.3479 (0.3569)	dist_loss 0.0222 (0.0410)	image_text_loss 3.8825 (3.8711)	pose_text_loss 3.3795 (3.0090)	tot_loss 7.4842 (7.2898)	mem 29650MB
[2024-12-24 22:29:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8250/11317]	eta 0:18:14 lr 0.000003934	time 0.3658 (0.3569)	dist_loss 0.0900 (0.0410)	image_text_loss 3.8399 (3.8711)	pose_text_loss 2.1316 (3.0086)	tot_loss 6.8718 (7.2895)	mem 29650MB
[2024-12-24 22:29:36 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8300/11317]	eta 0:17:56 lr 0.000003821	time 0.3464 (0.3569)	dist_loss 0.0169 (0.0410)	image_text_loss 3.8957 (3.8711)	pose_text_loss 3.5175 (3.0077)	tot_loss 7.5818 (7.2888)	mem 29650MB
[2024-12-24 22:29:54 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8350/11317]	eta 0:17:38 lr 0.000003710	time 0.3601 (0.3569)	dist_loss 0.0224 (0.0410)	image_text_loss 3.8395 (3.8711)	pose_text_loss 3.4111 (3.0064)	tot_loss 7.4745 (7.2879)	mem 29650MB
[2024-12-24 22:30:12 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8400/11317]	eta 0:17:21 lr 0.000003599	time 0.3637 (0.3569)	dist_loss 0.0691 (0.0411)	image_text_loss 3.8636 (3.8711)	pose_text_loss 2.3454 (3.0052)	tot_loss 6.9001 (7.2872)	mem 29650MB
[2024-12-24 22:30:30 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8450/11317]	eta 0:17:03 lr 0.000003491	time 0.3474 (0.3569)	dist_loss 0.0540 (0.0411)	image_text_loss 3.8884 (3.8711)	pose_text_loss 2.6873 (3.0037)	tot_loss 7.1152 (7.2862)	mem 29650MB
[2024-12-24 22:30:48 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8500/11317]	eta 0:16:45 lr 0.000003383	time 0.3571 (0.3569)	dist_loss 0.0462 (0.0412)	image_text_loss 3.8686 (3.8711)	pose_text_loss 2.7042 (3.0024)	tot_loss 7.0346 (7.2853)	mem 29650MB
[2024-12-24 22:31:06 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8550/11317]	eta 0:16:27 lr 0.000003278	time 0.3523 (0.3570)	dist_loss 0.0065 (0.0412)	image_text_loss 3.8587 (3.8711)	pose_text_loss 3.7292 (3.0017)	tot_loss 7.6531 (7.2848)	mem 29650MB
[2024-12-24 22:31:24 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8600/11317]	eta 0:16:09 lr 0.000003173	time 0.3624 (0.3569)	dist_loss 0.0722 (0.0412)	image_text_loss 3.8754 (3.8711)	pose_text_loss 2.3272 (3.0010)	tot_loss 6.9243 (7.2842)	mem 29650MB
[2024-12-24 22:31:42 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8650/11317]	eta 0:15:51 lr 0.000003071	time 0.3575 (0.3569)	dist_loss 0.0212 (0.0412)	image_text_loss 3.8682 (3.8711)	pose_text_loss 3.6188 (3.0003)	tot_loss 7.6989 (7.2836)	mem 29650MB
[2024-12-24 22:32:00 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8700/11317]	eta 0:15:34 lr 0.000002970	time 0.3645 (0.3570)	dist_loss 0.0239 (0.0413)	image_text_loss 3.8559 (3.8711)	pose_text_loss 3.4715 (2.9991)	tot_loss 7.5661 (7.2828)	mem 29650MB
[2024-12-24 22:32:17 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8750/11317]	eta 0:15:16 lr 0.000002870	time 0.3654 (0.3569)	dist_loss 0.0489 (0.0413)	image_text_loss 3.8501 (3.8710)	pose_text_loss 2.5646 (2.9977)	tot_loss 6.9040 (7.2818)	mem 29650MB
[2024-12-24 22:32:35 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8800/11317]	eta 0:14:58 lr 0.000002772	time 0.3524 (0.3569)	dist_loss 0.0233 (0.0414)	image_text_loss 3.8740 (3.8710)	pose_text_loss 3.2448 (2.9960)	tot_loss 7.3518 (7.2808)	mem 29650MB
[2024-12-24 22:32:53 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8850/11317]	eta 0:14:40 lr 0.000002675	time 0.3470 (0.3569)	dist_loss 0.0310 (0.0415)	image_text_loss 3.9246 (3.8710)	pose_text_loss 3.0977 (2.9942)	tot_loss 7.3318 (7.2797)	mem 29650MB
[2024-12-24 22:33:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8900/11317]	eta 0:14:22 lr 0.000002581	time 0.3506 (0.3569)	dist_loss 0.0221 (0.0415)	image_text_loss 3.8744 (3.8710)	pose_text_loss 3.6661 (2.9933)	tot_loss 7.7619 (7.2791)	mem 29650MB
[2024-12-24 22:33:28 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8950/11317]	eta 0:14:04 lr 0.000002488	time 0.3447 (0.3569)	dist_loss 0.0326 (0.0415)	image_text_loss 3.8708 (3.8710)	pose_text_loss 3.1125 (2.9920)	tot_loss 7.3092 (7.2782)	mem 29650MB
[2024-12-24 22:33:47 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9000/11317]	eta 0:13:47 lr 0.000002396	time 0.3542 (0.3569)	dist_loss 0.0329 (0.0416)	image_text_loss 3.8350 (3.8710)	pose_text_loss 2.9104 (2.9909)	tot_loss 7.0747 (7.2775)	mem 29650MB
[2024-12-24 22:34:04 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9050/11317]	eta 0:13:29 lr 0.000002306	time 0.3501 (0.3569)	dist_loss 0.0618 (0.0416)	image_text_loss 3.8758 (3.8710)	pose_text_loss 2.4459 (2.9901)	tot_loss 6.9401 (7.2770)	mem 29650MB
[2024-12-24 22:34:22 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9100/11317]	eta 0:13:11 lr 0.000002218	time 0.3516 (0.3569)	dist_loss 0.0193 (0.0416)	image_text_loss 3.8697 (3.8710)	pose_text_loss 3.3777 (2.9888)	tot_loss 7.4409 (7.2761)	mem 29650MB
[2024-12-24 22:34:40 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9150/11317]	eta 0:12:53 lr 0.000002132	time 0.3577 (0.3569)	dist_loss 0.0467 (0.0417)	image_text_loss 3.8696 (3.8710)	pose_text_loss 2.8222 (2.9875)	tot_loss 7.1585 (7.2752)	mem 29650MB
[2024-12-24 22:34:58 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9200/11317]	eta 0:12:35 lr 0.000002047	time 0.3585 (0.3569)	dist_loss 0.0546 (0.0417)	image_text_loss 3.8702 (3.8710)	pose_text_loss 2.5819 (2.9867)	tot_loss 6.9980 (7.2747)	mem 29650MB
[2024-12-24 22:35:16 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9250/11317]	eta 0:12:17 lr 0.000001964	time 0.3516 (0.3569)	dist_loss 0.0218 (0.0417)	image_text_loss 3.8724 (3.8710)	pose_text_loss 3.7004 (2.9854)	tot_loss 7.7905 (7.2737)	mem 29650MB
[2024-12-24 22:35:33 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9300/11317]	eta 0:11:59 lr 0.000001883	time 0.3408 (0.3569)	dist_loss 0.0705 (0.0418)	image_text_loss 3.8702 (3.8710)	pose_text_loss 2.3367 (2.9844)	tot_loss 6.9120 (7.2730)	mem 29650MB
[2024-12-24 22:35:51 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9350/11317]	eta 0:11:41 lr 0.000001804	time 0.3528 (0.3569)	dist_loss 0.0359 (0.0418)	image_text_loss 3.8751 (3.8710)	pose_text_loss 2.8947 (2.9829)	tot_loss 7.1290 (7.2719)	mem 29650MB
[2024-12-24 22:36:09 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9400/11317]	eta 0:11:24 lr 0.000001726	time 0.3517 (0.3569)	dist_loss 0.0620 (0.0418)	image_text_loss 3.8915 (3.8710)	pose_text_loss 2.4288 (2.9820)	tot_loss 6.9402 (7.2714)	mem 29650MB
[2024-12-24 22:36:27 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9450/11317]	eta 0:11:06 lr 0.000001650	time 0.3617 (0.3569)	dist_loss 0.0453 (0.0418)	image_text_loss 3.8697 (3.8710)	pose_text_loss 3.1290 (2.9816)	tot_loss 7.4513 (7.2711)	mem 29650MB
[2024-12-24 22:36:44 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9500/11317]	eta 0:10:48 lr 0.000001576	time 0.3643 (0.3569)	dist_loss 0.0394 (0.0419)	image_text_loss 3.8553 (3.8710)	pose_text_loss 2.8221 (2.9802)	tot_loss 7.0712 (7.2702)	mem 29650MB
[2024-12-24 22:37:02 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9550/11317]	eta 0:10:30 lr 0.000001504	time 0.3645 (0.3569)	dist_loss 0.0608 (0.0419)	image_text_loss 3.8558 (3.8710)	pose_text_loss 2.4725 (2.9795)	tot_loss 6.9365 (7.2696)	mem 29650MB
[2024-12-24 22:37:20 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9600/11317]	eta 0:10:12 lr 0.000001434	time 0.3758 (0.3569)	dist_loss 0.0439 (0.0420)	image_text_loss 3.8693 (3.8709)	pose_text_loss 2.7785 (2.9777)	tot_loss 7.0864 (7.2685)	mem 29650MB
[2024-12-24 22:37:38 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9650/11317]	eta 0:09:54 lr 0.000001365	time 0.3586 (0.3569)	dist_loss 0.0125 (0.0420)	image_text_loss 3.8580 (3.8709)	pose_text_loss 3.6882 (2.9772)	tot_loss 7.6712 (7.2682)	mem 29650MB
[2024-12-24 22:37:56 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9700/11317]	eta 0:09:37 lr 0.000001299	time 0.3454 (0.3569)	dist_loss 0.0700 (0.0420)	image_text_loss 3.8608 (3.8709)	pose_text_loss 2.3278 (2.9760)	tot_loss 6.8889 (7.2674)	mem 29650MB
[2024-12-24 22:38:13 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9750/11317]	eta 0:09:19 lr 0.000001234	time 0.3490 (0.3569)	dist_loss 0.0386 (0.0421)	image_text_loss 3.8701 (3.8709)	pose_text_loss 2.8828 (2.9747)	tot_loss 7.1386 (7.2665)	mem 29650MB
[2024-12-24 22:38:31 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9800/11317]	eta 0:09:01 lr 0.000001171	time 0.3581 (0.3568)	dist_loss 0.0100 (0.0421)	image_text_loss 3.8636 (3.8709)	pose_text_loss 3.9360 (2.9738)	tot_loss 7.8991 (7.2660)	mem 29650MB
[2024-12-24 22:38:49 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9850/11317]	eta 0:08:43 lr 0.000001111	time 0.3625 (0.3568)	dist_loss 0.0456 (0.0422)	image_text_loss 3.8627 (3.8709)	pose_text_loss 2.6955 (2.9728)	tot_loss 7.0142 (7.2652)	mem 29650MB
[2024-12-24 22:39:07 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9900/11317]	eta 0:08:25 lr 0.000001052	time 0.3657 (0.3569)	dist_loss 0.0318 (0.0422)	image_text_loss 3.8813 (3.8709)	pose_text_loss 3.1265 (2.9724)	tot_loss 7.3258 (7.2650)	mem 29650MB
[2024-12-24 22:39:25 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9950/11317]	eta 0:08:07 lr 0.000000995	time 0.3385 (0.3569)	dist_loss 0.0077 (0.0422)	image_text_loss 3.8460 (3.8709)	pose_text_loss 3.5282 (2.9714)	tot_loss 7.4517 (7.2643)	mem 29650MB
[2024-12-24 22:39:43 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10000/11317]	eta 0:07:49 lr 0.000000940	time 0.3555 (0.3569)	dist_loss 0.0399 (0.0422)	image_text_loss 3.8701 (3.8709)	pose_text_loss 2.8496 (2.9705)	tot_loss 7.1191 (7.2637)	mem 29650MB
[2024-12-24 22:40:01 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10050/11317]	eta 0:07:32 lr 0.000000887	time 0.3637 (0.3569)	dist_loss 0.0646 (0.0422)	image_text_loss 3.8427 (3.8709)	pose_text_loss 2.3817 (2.9697)	tot_loss 6.8700 (7.2631)	mem 29650MB
[2024-12-24 22:40:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10100/11317]	eta 0:07:14 lr 0.000000836	time 0.3461 (0.3569)	dist_loss 0.0131 (0.0423)	image_text_loss 3.8677 (3.8709)	pose_text_loss 4.0260 (2.9692)	tot_loss 8.0246 (7.2628)	mem 29650MB
[2024-12-24 22:40:36 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10150/11317]	eta 0:06:56 lr 0.000000786	time 0.3568 (0.3569)	dist_loss 0.0748 (0.0423)	image_text_loss 3.8750 (3.8709)	pose_text_loss 2.2780 (2.9685)	tot_loss 6.9013 (7.2622)	mem 29650MB
[2024-12-24 22:40:54 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10200/11317]	eta 0:06:38 lr 0.000000739	time 0.3657 (0.3569)	dist_loss 0.0690 (0.0423)	image_text_loss 3.8624 (3.8709)	pose_text_loss 2.3474 (2.9676)	tot_loss 6.8995 (7.2617)	mem 29650MB
[2024-12-24 22:41:12 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10250/11317]	eta 0:06:20 lr 0.000000694	time 0.3692 (0.3569)	dist_loss 0.0618 (0.0424)	image_text_loss 3.8785 (3.8709)	pose_text_loss 2.4525 (2.9666)	tot_loss 6.9489 (7.2610)	mem 29650MB
[2024-12-24 22:41:30 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10300/11317]	eta 0:06:02 lr 0.000000651	time 0.3622 (0.3569)	dist_loss 0.0445 (0.0424)	image_text_loss 3.8706 (3.8709)	pose_text_loss 3.1187 (2.9656)	tot_loss 7.4348 (7.2603)	mem 29650MB
[2024-12-24 22:41:48 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10350/11317]	eta 0:05:45 lr 0.000000610	time 0.3615 (0.3569)	dist_loss 0.0145 (0.0424)	image_text_loss 3.8739 (3.8709)	pose_text_loss 3.8567 (2.9649)	tot_loss 7.8757 (7.2599)	mem 29650MB
[2024-12-24 22:42:05 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10400/11317]	eta 0:05:27 lr 0.000000571	time 0.3696 (0.3569)	dist_loss 0.0383 (0.0424)	image_text_loss 3.8686 (3.8709)	pose_text_loss 2.8098 (2.9644)	tot_loss 7.0618 (7.2595)	mem 29650MB
[2024-12-24 22:42:23 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10450/11317]	eta 0:05:09 lr 0.000000534	time 0.3599 (0.3569)	dist_loss 0.0729 (0.0425)	image_text_loss 3.8793 (3.8708)	pose_text_loss 2.3050 (2.9634)	tot_loss 6.9137 (7.2588)	mem 29650MB
[2024-12-24 22:42:41 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10500/11317]	eta 0:04:51 lr 0.000000499	time 0.3562 (0.3569)	dist_loss 0.0482 (0.0425)	image_text_loss 3.8496 (3.8709)	pose_text_loss 2.5760 (2.9631)	tot_loss 6.9080 (7.2586)	mem 29650MB
[2024-12-24 22:42:59 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10550/11317]	eta 0:04:33 lr 0.000000466	time 0.3601 (0.3569)	dist_loss 0.0276 (0.0425)	image_text_loss 3.8705 (3.8709)	pose_text_loss 3.2929 (2.9624)	tot_loss 7.4396 (7.2581)	mem 29650MB
[2024-12-24 22:43:17 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10600/11317]	eta 0:04:15 lr 0.000000435	time 0.3469 (0.3569)	dist_loss 0.0352 (0.0425)	image_text_loss 3.9195 (3.8709)	pose_text_loss 3.2951 (2.9616)	tot_loss 7.5664 (7.2576)	mem 29650MB
[2024-12-24 22:43:35 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10650/11317]	eta 0:03:58 lr 0.000000406	time 0.3477 (0.3569)	dist_loss 0.0408 (0.0425)	image_text_loss 3.8693 (3.8709)	pose_text_loss 2.7825 (2.9610)	tot_loss 7.0600 (7.2570)	mem 29650MB
[2024-12-24 22:43:53 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10700/11317]	eta 0:03:40 lr 0.000000379	time 0.3569 (0.3569)	dist_loss 0.0774 (0.0425)	image_text_loss 3.8695 (3.8709)	pose_text_loss 2.2496 (2.9607)	tot_loss 6.8933 (7.2569)	mem 29650MB
[2024-12-24 22:44:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10750/11317]	eta 0:03:22 lr 0.000000355	time 0.3563 (0.3569)	dist_loss 0.0675 (0.0426)	image_text_loss 3.8638 (3.8709)	pose_text_loss 2.3661 (2.9599)	tot_loss 6.9047 (7.2563)	mem 29650MB
[2024-12-24 22:44:29 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10800/11317]	eta 0:03:04 lr 0.000000332	time 0.3589 (0.3569)	dist_loss 0.0498 (0.0426)	image_text_loss 3.8644 (3.8709)	pose_text_loss 2.6782 (2.9587)	tot_loss 7.0406 (7.2555)	mem 29650MB
[2024-12-24 22:44:47 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10850/11317]	eta 0:02:46 lr 0.000000311	time 0.3488 (0.3569)	dist_loss 0.0684 (0.0426)	image_text_loss 3.8654 (3.8708)	pose_text_loss 2.3939 (2.9581)	tot_loss 6.9434 (7.2550)	mem 29650MB
[2024-12-24 22:45:04 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10900/11317]	eta 0:02:28 lr 0.000000293	time 0.3573 (0.3569)	dist_loss 0.0176 (0.0426)	image_text_loss 3.8688 (3.8708)	pose_text_loss 3.7509 (2.9574)	tot_loss 7.7960 (7.2546)	mem 29650MB
[2024-12-24 22:45:22 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10950/11317]	eta 0:02:10 lr 0.000000276	time 0.3491 (0.3569)	dist_loss 0.0307 (0.0426)	image_text_loss 3.8684 (3.8708)	pose_text_loss 3.1403 (2.9570)	tot_loss 7.3153 (7.2543)	mem 29650MB
[2024-12-24 22:45:40 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11000/11317]	eta 0:01:53 lr 0.000000262	time 0.3602 (0.3569)	dist_loss 0.0346 (0.0427)	image_text_loss 3.8689 (3.8708)	pose_text_loss 2.9478 (2.9563)	tot_loss 7.1630 (7.2539)	mem 29650MB
[2024-12-24 22:45:58 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11050/11317]	eta 0:01:35 lr 0.000000250	time 0.4371 (0.3569)	dist_loss 0.0391 (0.0427)	image_text_loss 3.8804 (3.8708)	pose_text_loss 2.8955 (2.9559)	tot_loss 7.1672 (7.2536)	mem 29650MB
[2024-12-24 22:46:16 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11100/11317]	eta 0:01:17 lr 0.000000240	time 0.3582 (0.3570)	dist_loss 0.0338 (0.0427)	image_text_loss 3.8846 (3.8708)	pose_text_loss 2.9855 (2.9552)	tot_loss 7.2083 (7.2530)	mem 29650MB
[2024-12-24 22:46:34 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11150/11317]	eta 0:00:59 lr 0.000000232	time 0.3588 (0.3569)	dist_loss 0.0534 (0.0427)	image_text_loss 3.8754 (3.8708)	pose_text_loss 2.5747 (2.9543)	tot_loss 6.9845 (7.2524)	mem 29650MB
[2024-12-24 22:46:52 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11200/11317]	eta 0:00:41 lr 0.000000226	time 0.3724 (0.3569)	dist_loss 0.0782 (0.0428)	image_text_loss 3.8763 (3.8708)	pose_text_loss 2.2407 (2.9535)	tot_loss 6.8992 (7.2519)	mem 29650MB
[2024-12-24 22:47:10 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11250/11317]	eta 0:00:23 lr 0.000000222	time 0.3532 (0.3569)	dist_loss 0.0169 (0.0428)	image_text_loss 3.8683 (3.8708)	pose_text_loss 3.3453 (2.9528)	tot_loss 7.3826 (7.2514)	mem 29650MB
[2024-12-24 22:47:28 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11300/11317]	eta 0:00:06 lr 0.000000220	time 0.3511 (0.3569)	dist_loss 0.0212 (0.0428)	image_text_loss 3.8798 (3.8708)	pose_text_loss 3.2344 (2.9521)	tot_loss 7.3260 (7.2508)	mem 29650MB
[2024-12-24 22:47:33 ViT-B/16] (CL_main_v2.py 290): INFO EPOCH 0 training takes 1:07:19
[2024-12-24 22:47:33 ViT-B/16] (CL_main_v2.py 307): INFO 1 views inference
[2024-12-24 22:47:35 ViT-B/16] (CL_main_v2.py 379): INFO Test: [0/250]	Acc@1 for Image-Text: 0.000	mCA for Image-Text: 0.000	
[2024-12-24 22:47:35 ViT-B/16] (CL_main_v2.py 379): INFO Test: [0/250]	Acc@1 for Text-Pose: 50.000	mCA for Text-Pose: 2.083	
[2024-12-24 22:47:35 ViT-B/16] (CL_main_v2.py 379): INFO Test: [0/250]	Acc@1 for Image-Text-Pose: 50.000	mCA for Image-Text-Pose: 2.083	
[2024-12-24 22:47:42 ViT-B/16] (CL_main_v2.py 379): INFO Test: [50/250]	Acc@1 for Image-Text: 0.980	mCA for Image-Text: 0.694	
[2024-12-24 22:47:42 ViT-B/16] (CL_main_v2.py 379): INFO Test: [50/250]	Acc@1 for Text-Pose: 64.706	mCA for Text-Pose: 60.868	
[2024-12-24 22:47:42 ViT-B/16] (CL_main_v2.py 379): INFO Test: [50/250]	Acc@1 for Image-Text-Pose: 64.706	mCA for Image-Text-Pose: 60.868	
[2024-12-24 22:47:49 ViT-B/16] (CL_main_v2.py 379): INFO Test: [100/250]	Acc@1 for Image-Text: 3.465	mCA for Image-Text: 3.333	
[2024-12-24 22:47:49 ViT-B/16] (CL_main_v2.py 379): INFO Test: [100/250]	Acc@1 for Text-Pose: 68.812	mCA for Text-Pose: 70.627	
[2024-12-24 22:47:49 ViT-B/16] (CL_main_v2.py 379): INFO Test: [100/250]	Acc@1 for Image-Text-Pose: 68.812	mCA for Image-Text-Pose: 70.627	
[2024-12-24 22:47:56 ViT-B/16] (CL_main_v2.py 379): INFO Test: [150/250]	Acc@1 for Image-Text: 2.649	mCA for Image-Text: 3.333	
[2024-12-24 22:47:56 ViT-B/16] (CL_main_v2.py 379): INFO Test: [150/250]	Acc@1 for Text-Pose: 68.543	mCA for Text-Pose: 72.001	
[2024-12-24 22:47:56 ViT-B/16] (CL_main_v2.py 379): INFO Test: [150/250]	Acc@1 for Image-Text-Pose: 68.543	mCA for Image-Text-Pose: 72.001	
[2024-12-24 22:48:03 ViT-B/16] (CL_main_v2.py 379): INFO Test: [200/250]	Acc@1 for Image-Text: 2.488	mCA for Image-Text: 3.423	
[2024-12-24 22:48:03 ViT-B/16] (CL_main_v2.py 379): INFO Test: [200/250]	Acc@1 for Text-Pose: 70.149	mCA for Text-Pose: 73.023	
[2024-12-24 22:48:03 ViT-B/16] (CL_main_v2.py 379): INFO Test: [200/250]	Acc@1 for Image-Text-Pose: 70.398	mCA for Image-Text-Pose: 73.283	
[2024-12-24 22:48:10 ViT-B/16] (CL_main_v2.py 406): INFO  * Acc@1 for Image-Text: 3.150 Acc@5 for Image-Text: 12.600 mCA for Image-Text: 2.885
[2024-12-24 22:48:10 ViT-B/16] (CL_main_v2.py 406): INFO  * Acc@1 for Text-Pose: 70.550 Acc@5 for Text-Pose: 86.350 mCA for Text-Pose: 71.699
[2024-12-24 22:48:10 ViT-B/16] (CL_main_v2.py 406): INFO  * Acc@1 for Image-Text-Pose: 70.550 Acc@5 for Image-Text-Pose: 86.400 mCA for Image-Text-Pose: 71.696
[2024-12-24 22:48:10 ViT-B/16] (CL_main_v2.py 157): INFO Accuracy of the network on the 2004 test videos on Image-Text: 3.1%. mCA: 2.9
[2024-12-24 22:48:10 ViT-B/16] (CL_main_v2.py 165): INFO Max accuracy: 3.15%
