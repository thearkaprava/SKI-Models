[2024-12-24 21:35:50 ViT-B/16] (CL_main_v2.py 442): INFO working dir: ./workdirs/TEST_P2_SKIViFiCLIP_zs_48_25Dec24/
[2024-12-24 21:36:25 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 261): INFO Loading CLIP (backbone: ViT-B/16)
[2024-12-24 21:36:29 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 265): INFO Building Model
[2024-12-24 21:36:29 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 282): INFO Turning on gradients for COMPLETE SKI_VLM model
[2024-12-24 21:36:29 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 315): INFO Parameters to be updated: {'hyperformer_model.l1.residual.conv.bias', 'clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l7.vit1.attn.outer', 'image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'text_encoder.transformer.resblocks.8.ln_2.bias', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'hyperformer_model.l8.tcn1.branches.1.0.weight', 'hyperformer_model.l5.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'hyperformer_model.l3.vit1.attn.rpe', 'hyperformer_model.l5.tcn1.branches.2.4.bias', 'hyperformer_model.l10.vit1.norm1.bias', 'image_encoder.transformer.resblocks.2.ln_1.bias', 'text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'hyperformer_model.l2.vit1.norm1.weight', 'text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l10.vit1.attn.rpe', 'hyperformer_model.l6.tcn1.branches.1.1.weight', 'image_encoder.ln_post.bias', 'text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l4.tcn1.branches.3.1.bias', 'hyperformer_model.l2.tcn1.branches.2.0.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'hyperformer_model.l2.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'hyperformer_model.l8.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'hyperformer_model.l9.vit1.attn.w1', 'hyperformer_model.l8.tcn1.branches.2.0.bias', 'hyperformer_model.l2.vit1.pe_proj.weight', 'image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l6.vit1.attn.kv.weight', 'hyperformer_model.l6.tcn1.branches.1.1.bias', 'image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'hyperformer_model.l1.tcn1.branches.1.1.bias', 'hyperformer_model.l3.tcn1.branches.2.1.bias', 'text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'hyperformer_model.l4.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.5.ln_1.bias', 'hyperformer_model.l6.tcn1.branches.2.0.weight', 'text_encoder.transformer.resblocks.2.ln_2.weight', 'text_encoder.transformer.resblocks.8.ln_2.weight', 'hyperformer_model.l3.tcn1.branches.0.1.weight', 'hyperformer_model.l3.vit1.attn.alpha', 'hyperformer_model.l10.vit1.attn.w1', 'text_encoder.transformer.resblocks.2.ln_1.weight', 'hyperformer_model.l9.tcn1.branches.0.0.weight', 'hyperformer_model.l3.tcn1.branches.1.1.bias', 'hyperformer_model.l7.vit1.attn.proj.weight', 'hyperformer_model.l1.tcn1.branches.2.0.weight', 'hyperformer_model.l2.vit1.attn.proj.weight', 'image_encoder.transformer.resblocks.6.ln_2.weight', 'clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'hyperformer_model.l4.vit1.norm1.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'text_encoder.transformer.resblocks.1.ln_2.bias', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l1.vit1.attn.proj.weight', 'hyperformer_model.l8.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l10.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'hyperformer_model.l2.tcn1.branches.1.0.weight', 'hyperformer_model.l8.tcn1.branches.1.1.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l5.vit1.attn.rpe', 'hyperformer_model.l4.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l3.vit1.pe_proj.weight', 'hyperformer_model.l9.vit1.pe_proj.weight', 'hyperformer_model.l1.vit1.attn.alpha', 'image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.6.ln_2.bias', 'image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.1.ln_1.bias', 'hyperformer_model.l10.tcn1.branches.2.1.weight', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l10.tcn1.branches.2.0.weight', 'clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'hyperformer_model.l9.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l10.tcn1.branches.3.0.weight', 'hyperformer_model.l3.vit1.attn.q.weight', 'text_encoder.transformer.resblocks.3.ln_1.bias', 'image_encoder.transformer.resblocks.4.ln_1.weight', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'hyperformer_model.l7.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'hyperformer_model.l7.vit1.attn.rpe', 'hyperformer_model.l9.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'image_encoder.transformer.resblocks.3.ln_1.weight', 'hyperformer_model.l6.tcn1.branches.2.4.weight', 'hyperformer_model.l7.vit1.attn.q.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'hyperformer_model.l9.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'hyperformer_model.l10.tcn1.branches.0.0.bias', 'image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'text_encoder.transformer.resblocks.7.ln_1.bias', 'clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'hyperformer_model.l4.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'image_encoder.ln_post.weight', 'hyperformer_model.l2.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l9.tcn1.branches.0.0.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l2.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'hyperformer_model.l8.tcn1.branches.0.1.weight', 'image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l6.tcn1.branches.1.3.conv.weight', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.0.ln_1.weight', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.1.0.weight', 'hyperformer_model.l8.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.2.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.2.4.bias', 'hyperformer_model.l5.tcn1.branches.2.4.weight', 'hyperformer_model.l4.tcn1.branches.1.1.weight', 'hyperformer_model.l8.residual.conv.weight', 'hyperformer_model.l5.tcn1.branches.0.1.weight', 'hyperformer_model.l8.tcn1.branches.2.4.bias', 'hyperformer_model.l9.tcn1.branches.3.0.weight', 'hyperformer_model.l1.tcn1.branches.3.0.bias', 'hyperformer_model.l10.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.10.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'hyperformer_model.l1.tcn1.branches.3.1.bias', 'text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'hyperformer_model.l6.vit1.pe_proj.weight', 'hyperformer_model.l9.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.4.ln_1.bias', 'text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l5.residual.conv.weight', 'text_encoder.transformer.resblocks.5.ln_1.weight', 'text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'hyperformer_model.l6.tcn1.branches.1.0.weight', 'hyperformer_model.l5.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l1.vit1.attn.proj.bias', 'hyperformer_model.l4.vit1.attn.proj.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l6.vit1.attn.w1', 'hyperformer_model.l4.vit1.attn.outer', 'hyperformer_model.l7.vit1.norm1.weight', 'image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'hyperformer_model.l1.tcn1.branches.2.1.weight', 'hyperformer_model.l10.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l8.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l4.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l10.vit1.attn.outer', 'text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.7.ln_1.weight', 'hyperformer_model.l2.vit1.attn.outer', 'hyperformer_model.l2.tcn1.branches.1.0.bias', 'hyperformer_model.l5.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l2.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.l4.tcn1.branches.0.1.bias', 'hyperformer_model.l7.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'hyperformer_model.l7.vit1.attn.kv.weight', 'hyperformer_model.l7.tcn1.branches.2.0.bias', 'image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'hyperformer_model.l7.tcn1.branches.1.1.weight', 'hyperformer_model.l8.vit1.attn.outer', 'clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'hyperformer_model.l3.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l10.vit1.attn.alpha', 'image_encoder.transformer.resblocks.10.ln_2.weight', 'image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'hyperformer_model.l7.vit1.attn.proj.bias', 'hyperformer_model.l10.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l3.tcn1.branches.0.0.weight', 'hyperformer_model.l4.tcn1.branches.3.1.weight', 'hyperformer_model.l9.tcn1.branches.1.1.weight', 'hyperformer_model.l4.vit1.attn.w1', 'clip_text_encoder.ln_final.weight', 'hyperformer_model.l7.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'hyperformer_model.l7.tcn1.branches.2.4.bias', 'hyperformer_model.l6.tcn1.branches.0.3.bn.weight', 'image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'hyperformer_model.l5.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.4.ln_2.weight', 'text_encoder.transformer.resblocks.4.ln_1.weight', 'hyperformer_model.l7.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l10.tcn1.branches.0.1.weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'hyperformer_model.l3.vit1.attn.proj.weight', 'hyperformer_model.l10.tcn1.branches.0.3.bn.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'hyperformer_model.l1.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l9.tcn1.branches.0.1.weight', 'clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l1.tcn1.branches.1.3.bn.weight', 'image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'image_encoder.transformer.resblocks.5.ln_2.bias', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l1.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.9.ln_1.weight', 'text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'hyperformer_model.l8.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'hyperformer_model.fc2.bias', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'text_encoder.transformer.resblocks.10.ln_1.weight', 'text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'hyperformer_model.l2.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l9.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l3.tcn1.branches.2.0.weight', 'hyperformer_model.l4.tcn1.branches.1.0.weight', 'clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l8.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'clip_text_encoder.positional_embedding', 'image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'hyperformer_model.l4.vit1.attn.alpha', 'hyperformer_model.l6.vit1.norm1.weight', 'text_encoder.ln_final.weight', 'hyperformer_model.l7.tcn1.branches.0.1.weight', 'hyperformer_model.l3.tcn1.branches.2.0.bias', 'hyperformer_model.l10.tcn1.branches.3.0.bias', 'hyperformer_model.l2.tcn1.branches.3.1.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l3.vit1.attn.outer', 'image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.3.ln_1.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'hyperformer_model.l3.tcn1.branches.0.1.bias', 'text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'hyperformer_model.l1.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'hyperformer_model.l5.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.8.ln_2.weight', 'image_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.data_bn.weight', 'hyperformer_model.l7.tcn1.branches.2.1.weight', 'hyperformer_model.l9.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.5.ln_2.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l3.vit1.norm1.bias', 'image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'image_encoder.transformer.resblocks.1.ln_2.bias', 'text_encoder.text_projection', 'hyperformer_model.l9.tcn1.branches.1.3.conv.bias', 'image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'hyperformer_model.l3.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l2.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'hyperformer_model.l8.tcn1.branches.3.0.weight', 'hyperformer_model.l6.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'hyperformer_model.l5.vit1.norm1.weight', 'hyperformer_model.l9.tcn1.branches.3.1.bias', 'hyperformer_model.l6.vit1.norm1.bias', 'hyperformer_model.l3.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'hyperformer_model.l8.tcn1.branches.2.4.weight', 'hyperformer_model.l2.tcn1.branches.3.0.bias', 'hyperformer_model.l9.vit1.attn.kv.weight', 'hyperformer_model.l3.vit1.attn.w1', 'hyperformer_model.l2.tcn1.branches.1.1.weight', 'hyperformer_model.l7.tcn1.branches.0.0.weight', 'hyperformer_model.l8.vit1.attn.q.weight', 'hyperformer_model.l3.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.1.ln_2.weight', 'image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'hyperformer_model.l8.residual.bn.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'hyperformer_model.l10.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'hyperformer_model.l3.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'hyperformer_model.l6.vit1.attn.proj.bias', 'hyperformer_model.l10.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l6.tcn1.branches.2.1.weight', 'hyperformer_model.l5.vit1.pe_proj.weight', 'hyperformer_model.l1.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'hyperformer_model.l7.vit1.attn.w1', 'text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'text_encoder.transformer.resblocks.11.ln_2.weight', 'image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.6.ln_1.bias', 'hyperformer_model.l8.tcn1.branches.0.0.bias', 'hyperformer_model.l4.vit1.attn.kv.weight', 'hyperformer_model.l9.tcn1.branches.1.3.conv.weight', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'hyperformer_model.l5.tcn1.branches.1.1.weight', 'hyperformer_model.l7.tcn1.branches.0.1.bias', 'hyperformer_model.l9.vit1.norm1.weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'hyperformer_model.l10.vit1.pe_proj.weight', 'clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.11.ln_1.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l1.vit1.attn.outer', 'hyperformer_model.l6.tcn1.branches.3.0.bias', 'hyperformer_model.l5.tcn1.branches.2.1.bias', 'hyperformer_model.l7.tcn1.branches.3.1.bias', 'text_encoder.transformer.resblocks.7.ln_2.weight', 'image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'hyperformer_model.l1.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'hyperformer_model.l9.tcn1.branches.2.0.bias', 'hyperformer_model.l5.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l9.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l4.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'hyperformer_model.l7.vit1.pe_proj.weight', 'hyperformer_model.l5.tcn1.branches.2.0.bias', 'hyperformer_model.l10.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'image_encoder.class_embedding', 'text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'hyperformer_model.l5.vit1.attn.proj.weight', 'hyperformer_model.l10.tcn1.branches.2.0.bias', 'hyperformer_model.l8.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.9.ln_1.weight', 'text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'hyperformer_model.l3.tcn1.branches.2.1.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'hyperformer_model.l4.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'hyperformer_model.l9.vit1.attn.proj.bias', 'text_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.l9.vit1.attn.alpha', 'hyperformer_model.l1.vit1.attn.rpe', 'hyperformer_model.l3.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'hyperformer_model.l3.vit1.attn.proj.bias', 'hyperformer_model.l5.residual.bn.weight', 'hyperformer_model.l8.vit1.attn.alpha', 'image_encoder.transformer.resblocks.8.ln_1.weight', 'hyperformer_model.fc2.weight', 'hyperformer_model.l5.vit1.attn.kv.weight', 'text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'image_encoder.transformer.resblocks.7.ln_1.bias', 'hyperformer_model.l1.tcn1.branches.1.1.weight', 'hyperformer_model.l7.vit1.attn.alpha', 'hyperformer_model.l3.tcn1.branches.3.1.weight', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'image_encoder.transformer.resblocks.4.ln_2.bias', 'text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'text_encoder.ln_final.bias', 'hyperformer_model.l4.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'hyperformer_model.l1.residual.conv.weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'hyperformer_model.l10.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.6.ln_2.bias', 'hyperformer_model.l10.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l6.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l10.tcn1.branches.1.1.bias', 'image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'hyperformer_model.l1.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.4.ln_1.bias', 'image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'hyperformer_model.l7.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l6.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'hyperformer_model.l4.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l3.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'hyperformer_model.l10.vit1.attn.proj.weight', 'clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'image_encoder.transformer.resblocks.11.ln_1.weight', 'hyperformer_model.l3.tcn1.branches.1.1.weight', 'image_encoder.transformer.resblocks.5.ln_1.weight', 'text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'hyperformer_model.l1.vit1.skip_proj.weight', 'text_encoder.transformer.resblocks.9.ln_2.bias', 'hyperformer_model.l2.tcn1.branches.2.4.bias', 'hyperformer_model.l6.tcn1.branches.2.0.bias', 'clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'hyperformer_model.l5.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.11.ln_2.bias', 'text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.0.0.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'text_encoder.transformer.resblocks.9.ln_1.bias', 'clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'text_encoder.transformer.resblocks.10.ln_2.weight', 'hyperformer_model.l10.tcn1.branches.1.1.weight', 'image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'image_encoder.transformer.resblocks.8.ln_1.bias', 'text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'hyperformer_model.l9.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l9.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'hyperformer_model.l9.tcn1.branches.3.0.bias', 'hyperformer_model.l6.tcn1.branches.3.1.bias', 'text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.3.1.weight', 'image_encoder.ln_pre.weight', 'text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'hyperformer_model.l3.tcn1.branches.3.0.weight', 'hyperformer_model.l8.tcn1.branches.3.0.bias', 'clip_text_encoder.text_projection', 'hyperformer_model.l5.vit1.attn.outer', 'hyperformer_model.l1.vit1.attn.kv.weight', 'hyperformer_model.l4.tcn1.branches.2.0.bias', 'hyperformer_model.l10.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l1.tcn1.branches.1.0.bias', 'hyperformer_model.l7.tcn1.branches.3.0.weight', 'image_encoder.proj', 'image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'text_encoder.transformer.resblocks.0.ln_2.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.1.1.bias', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'hyperformer_model.l9.vit1.attn.proj.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'text_encoder.positional_embedding', 'hyperformer_model.l4.vit1.norm1.weight', 'text_encoder.transformer.resblocks.2.ln_2.bias', 'hyperformer_model.l1.residual.bn.weight', 'hyperformer_model.l6.tcn1.branches.0.3.conv.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'hyperformer_model.l10.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l1.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l4.tcn1.branches.2.0.weight', 'clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'text_encoder.transformer.resblocks.1.ln_1.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'hyperformer_model.l2.tcn1.branches.2.1.bias', 'hyperformer_model.l7.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'hyperformer_model.l8.vit1.norm1.bias', 'hyperformer_model.l5.tcn1.branches.1.0.bias', 'hyperformer_model.l8.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'hyperformer_model.l6.vit1.attn.outer', 'image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l4.vit1.attn.proj.weight', 'hyperformer_model.l7.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'image_encoder.positional_embedding', 'hyperformer_model.l9.tcn1.branches.1.1.bias', 'hyperformer_model.l8.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.10.ln_1.bias', 'text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l4.vit1.attn.rpe', 'hyperformer_model.l2.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.9.ln_2.weight', 'hyperformer_model.l9.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.9.ln_1.bias', 'text_encoder.transformer.resblocks.6.ln_1.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'hyperformer_model.l1.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'hyperformer_model.l3.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'text_encoder.transformer.resblocks.4.ln_2.bias', 'text_encoder.transformer.resblocks.9.ln_2.weight', 'image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'image_encoder.transformer.resblocks.6.ln_1.bias', 'text_encoder.transformer.resblocks.8.ln_1.weight', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l8.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l8.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l1.vit1.attn.w1', 'hyperformer_model.l6.tcn1.branches.2.1.bias', 'hyperformer_model.l1.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.9.ln_2.bias', 'hyperformer_model.l3.tcn1.branches.2.4.weight', 'hyperformer_model.l7.vit1.norm1.bias', 'hyperformer_model.l7.tcn1.branches.2.4.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'hyperformer_model.l9.vit1.attn.q.weight', 'hyperformer_model.l1.residual.bn.bias', 'text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'hyperformer_model.l5.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l2.tcn1.branches.1.1.bias', 'hyperformer_model.l6.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'hyperformer_model.l8.vit1.attn.w1', 'image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'hyperformer_model.l8.vit1.norm1.weight', 'text_encoder.transformer.resblocks.5.ln_2.bias', 'hyperformer_model.l6.vit1.attn.alpha', 'image_encoder.transformer.resblocks.10.ln_2.bias', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l5.residual.bn.bias', 'hyperformer_model.l6.vit1.attn.proj.weight', 'image_encoder.transformer.resblocks.7.ln_1.weight', 'hyperformer_model.l5.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l7.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l7.tcn1.branches.1.3.bn.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.3.ln_2.bias', 'text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'text_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l5.tcn1.branches.3.1.weight', 'hyperformer_model.l8.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'hyperformer_model.l3.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'hyperformer_model.l10.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'hyperformer_model.l5.tcn1.branches.0.0.weight', 'hyperformer_model.l8.residual.conv.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l2.vit1.norm1.bias', 'image_encoder.transformer.resblocks.3.ln_1.bias', 'image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'hyperformer_model.l3.tcn1.branches.3.1.bias', 'hyperformer_model.l1.vit1.norm1.weight', 'image_encoder.transformer.resblocks.1.ln_1.bias', 'hyperformer_model.l2.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'hyperformer_model.l5.tcn1.branches.3.1.bias', 'clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'hyperformer_model.l8.tcn1.branches.0.0.weight', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'image_encoder.transformer.resblocks.7.ln_2.bias', 'hyperformer_model.l7.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'hyperformer_model.l3.tcn1.branches.1.0.weight', 'hyperformer_model.l5.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l2.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.l5.residual.conv.bias', 'hyperformer_model.l3.vit1.norm1.weight', 'hyperformer_model.l9.vit1.norm1.bias', 'hyperformer_model.l2.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l8.tcn1.branches.2.1.bias', 'hyperformer_model.l4.vit1.pe_proj.weight', 'hyperformer_model.l8.vit1.attn.rpe', 'image_encoder.ln_pre.bias', 'clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l1.tcn1.branches.0.1.weight', 'image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l4.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l2.tcn1.branches.0.0.weight', 'hyperformer_model.l9.vit1.attn.rpe', 'image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'hyperformer_model.l6.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l4.tcn1.branches.1.0.bias', 'hyperformer_model.l5.vit1.attn.alpha', 'text_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l2.tcn1.branches.0.0.bias', 'hyperformer_model.l1.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l2.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l7.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'image_encoder.conv1.weight', 'text_encoder.transformer.resblocks.10.ln_1.bias', 'clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l2.tcn1.branches.2.1.weight', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.0.ln_2.bias', 'text_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l4.tcn1.branches.2.4.bias', 'text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'hyperformer_model.l8.tcn1.branches.3.1.bias', 'hyperformer_model.l4.tcn1.branches.1.1.bias', 'hyperformer_model.l1.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'hyperformer_model.l1.vit1.pe_proj.weight', 'hyperformer_model.l7.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l9.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'hyperformer_model.l5.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l3.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l6.tcn1.branches.0.0.bias', 'hyperformer_model.l2.tcn1.branches.0.1.weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'clip_text_encoder.ln_final.bias', 'clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'image_encoder.transformer.resblocks.2.ln_2.weight', 'image_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l4.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.3.0.bias', 'hyperformer_model.l6.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'hyperformer_model.l3.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.5.ln_1.bias', 'text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'hyperformer_model.l5.tcn1.branches.0.0.bias', 'hyperformer_model.l8.vit1.attn.proj.weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'hyperformer_model.l1.tcn1.branches.2.0.bias', 'image_encoder.transformer.resblocks.7.ln_2.weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'hyperformer_model.data_bn.bias', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'hyperformer_model.l2.tcn1.branches.2.0.bias', 'image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'hyperformer_model.l5.tcn1.branches.1.0.weight', 'hyperformer_model.l8.residual.bn.weight', 'hyperformer_model.l2.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'image_encoder.transformer.resblocks.2.ln_1.weight', 'image_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'hyperformer_model.l2.vit1.attn.alpha', 'hyperformer_model.l6.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l5.vit1.attn.w1', 'hyperformer_model.l10.tcn1.branches.2.4.weight', 'hyperformer_model.l4.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l5.vit1.norm1.bias', 'hyperformer_model.l9.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l2.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'hyperformer_model.l4.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'hyperformer_model.l9.tcn1.branches.2.0.weight', 'hyperformer_model.l10.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.0.ln_1.weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'hyperformer_model.l3.tcn1.branches.0.0.bias', 'hyperformer_model.l6.tcn1.branches.0.1.weight', 'image_encoder.transformer.resblocks.1.ln_2.weight', 'hyperformer_model.l4.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'hyperformer_model.l1.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'hyperformer_model.l1.tcn1.branches.2.1.bias', 'text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'hyperformer_model.l6.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l8.vit1.pe_proj.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'text_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l2.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l4.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'hyperformer_model.l7.tcn1.branches.1.0.bias', 'hyperformer_model.l10.tcn1.branches.3.1.bias', 'hyperformer_model.l9.vit1.attn.outer', 'clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'hyperformer_model.l4.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l4.vit1.attn.q.weight', 'hyperformer_model.l5.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.4.ln_2.weight', 'clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'hyperformer_model.l2.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'hyperformer_model.l10.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l10.vit1.attn.proj.bias', 'text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'hyperformer_model.l7.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.7.ln_2.bias', 'text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l8.tcn1.branches.0.1.bias', 'hyperformer_model.l10.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.11.ln_2.bias', 'image_encoder.transformer.resblocks.10.ln_1.weight', 'hyperformer_model.l8.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'hyperformer_model.l3.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.3.ln_2.bias', 'text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'image_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l5.tcn1.branches.0.1.bias', 'hyperformer_model.l2.vit1.attn.rpe', 'image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'text_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l2.vit1.attn.proj.bias', 'hyperformer_model.l8.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'hyperformer_model.l5.tcn1.branches.2.0.weight'}
[2024-12-24 21:36:29 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 316): INFO Total learnable items: 835
[2024-12-24 21:36:30 ViT-B/16] (tools.py 147): INFO ==============> Resuming from ./workdirs/TEST_P1_SKeletonCLIP_alltrn_HFinit_zs_48_17Dec24/ckpt_epoch_0.pth....................
[2024-12-24 21:36:30 ViT-B/16] (tools.py 172): INFO resume VIFICLIP model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.clip_text_encoder.positional_embedding', 'module.clip_text_encoder.text_projection', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'module.clip_text_encoder.ln_final.weight', 'module.clip_text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:36:30 ViT-B/16] (tools.py 176): INFO ==============> Resuming from /data/users/asinha13/projects/CLIP4ADL/model_chkpnts/ntu_CS_P1_HF_pretrain_frzn_txt_zs_48_AS_16Jan24/ckpt_epoch_99.pth....................
[2024-12-24 21:36:31 ViT-B/16] (tools.py 218): INFO resume Hyperformer model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.text_encoder.positional_embedding', 'module.text_encoder.text_projection', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_1.weight', 'module.text_encoder.transformer.resblocks.0.ln_1.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_2.weight', 'module.text_encoder.transformer.resblocks.0.ln_2.bias', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_1.weight', 'module.text_encoder.transformer.resblocks.1.ln_1.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_2.weight', 'module.text_encoder.transformer.resblocks.1.ln_2.bias', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_1.weight', 'module.text_encoder.transformer.resblocks.2.ln_1.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_2.weight', 'module.text_encoder.transformer.resblocks.2.ln_2.bias', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_1.weight', 'module.text_encoder.transformer.resblocks.3.ln_1.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_2.weight', 'module.text_encoder.transformer.resblocks.3.ln_2.bias', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_1.weight', 'module.text_encoder.transformer.resblocks.4.ln_1.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_2.weight', 'module.text_encoder.transformer.resblocks.4.ln_2.bias', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_1.weight', 'module.text_encoder.transformer.resblocks.5.ln_1.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_2.weight', 'module.text_encoder.transformer.resblocks.5.ln_2.bias', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_1.weight', 'module.text_encoder.transformer.resblocks.6.ln_1.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_2.weight', 'module.text_encoder.transformer.resblocks.6.ln_2.bias', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_1.weight', 'module.text_encoder.transformer.resblocks.7.ln_1.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_2.weight', 'module.text_encoder.transformer.resblocks.7.ln_2.bias', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_1.weight', 'module.text_encoder.transformer.resblocks.8.ln_1.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_2.weight', 'module.text_encoder.transformer.resblocks.8.ln_2.bias', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_1.weight', 'module.text_encoder.transformer.resblocks.9.ln_1.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_2.weight', 'module.text_encoder.transformer.resblocks.9.ln_2.bias', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_1.weight', 'module.text_encoder.transformer.resblocks.10.ln_1.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_2.weight', 'module.text_encoder.transformer.resblocks.10.ln_2.bias', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_1.weight', 'module.text_encoder.transformer.resblocks.11.ln_1.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_2.weight', 'module.text_encoder.transformer.resblocks.11.ln_2.bias', 'module.text_encoder.ln_final.weight', 'module.text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:36:36 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][0/11317]	eta 16:34:18 lr 0.000022000	time 5.2716 (5.2716)	dist_loss 0.2850 (0.2850)	image_text_loss 3.9417 (3.9417)	pose_text_loss 2.8081 (2.8081)	tot_loss 9.5998 (9.5998)	mem 29650MB
[2024-12-24 21:36:53 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][50/11317]	eta 1:22:59 lr 0.000021999	time 0.3494 (0.4420)	dist_loss 0.0034 (0.1306)	image_text_loss 3.8688 (3.8683)	pose_text_loss 3.7475 (3.7192)	tot_loss 7.6499 (8.8932)	mem 29650MB
[2024-12-24 21:37:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][100/11317]	eta 1:14:26 lr 0.000021996	time 0.3560 (0.3982)	dist_loss 0.0192 (0.0721)	image_text_loss 3.8044 (3.8684)	pose_text_loss 3.5345 (3.7408)	tot_loss 7.5306 (8.3305)	mem 29650MB
[2024-12-24 21:38:19 ViT-B/16] (CL_main_v2.py 442): INFO working dir: ./workdirs/TEST_P2_SKIViFiCLIP_zs_48_25Dec24/
[2024-12-24 21:39:54 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 261): INFO Loading CLIP (backbone: ViT-B/16)
[2024-12-24 21:39:58 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 265): INFO Building Model
[2024-12-24 21:39:58 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 282): INFO Turning on gradients for COMPLETE SKI_VLM model
[2024-12-24 21:39:58 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 315): INFO Parameters to be updated: {'hyperformer_model.l3.tcn1.branches.1.1.bias', 'clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'hyperformer_model.l9.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l10.tcn1.branches.2.1.weight', 'hyperformer_model.l2.tcn1.branches.0.0.weight', 'hyperformer_model.l3.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.8.ln_2.weight', 'hyperformer_model.l4.vit1.attn.proj.weight', 'hyperformer_model.l1.vit1.pe_proj.weight', 'image_encoder.transformer.resblocks.2.ln_2.bias', 'hyperformer_model.l1.vit1.norm1.weight', 'image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'hyperformer_model.l7.vit1.attn.w1', 'hyperformer_model.l5.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l10.tcn1.branches.3.1.weight', 'hyperformer_model.l6.tcn1.branches.3.1.bias', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'hyperformer_model.l5.tcn1.branches.3.1.weight', 'hyperformer_model.l3.tcn1.branches.3.1.bias', 'hyperformer_model.l8.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l8.vit1.norm1.bias', 'text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'text_encoder.transformer.resblocks.0.ln_1.bias', 'text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'hyperformer_model.l7.vit1.attn.proj.weight', 'hyperformer_model.l8.tcn1.branches.0.1.weight', 'hyperformer_model.l8.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l8.tcn1.branches.1.1.bias', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.9.ln_2.weight', 'hyperformer_model.l3.tcn1.branches.0.1.bias', 'hyperformer_model.l9.tcn1.branches.0.0.bias', 'hyperformer_model.l9.vit1.pe_proj.weight', 'text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l2.vit1.attn.q.weight', 'hyperformer_model.l6.vit1.pe_proj.weight', 'text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'hyperformer_model.l8.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l1.tcn1.branches.1.0.bias', 'hyperformer_model.l9.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l4.tcn1.branches.2.0.bias', 'hyperformer_model.l9.tcn1.branches.1.0.weight', 'hyperformer_model.l5.tcn1.branches.2.0.bias', 'hyperformer_model.l3.tcn1.branches.2.0.bias', 'hyperformer_model.l6.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'hyperformer_model.l6.vit1.attn.rpe', 'hyperformer_model.l6.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l6.tcn1.branches.0.3.bn.weight', 'image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.10.ln_1.bias', 'clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'hyperformer_model.l8.tcn1.branches.2.0.bias', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'hyperformer_model.l3.vit1.attn.q.weight', 'hyperformer_model.l6.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l8.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.11.ln_2.bias', 'hyperformer_model.l3.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l5.tcn1.branches.0.0.bias', 'hyperformer_model.l5.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.8.ln_2.bias', 'image_encoder.ln_post.bias', 'text_encoder.transformer.resblocks.2.ln_2.weight', 'text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'hyperformer_model.l10.tcn1.branches.2.0.bias', 'hyperformer_model.l5.vit1.attn.alpha', 'hyperformer_model.l4.vit1.norm1.bias', 'image_encoder.ln_pre.weight', 'hyperformer_model.l10.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'hyperformer_model.l6.tcn1.branches.3.1.weight', 'clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l3.tcn1.branches.0.0.weight', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.2.0.weight', 'hyperformer_model.l6.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'hyperformer_model.l6.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l1.vit1.attn.proj.weight', 'text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'hyperformer_model.l3.tcn1.branches.3.1.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.0.1.bias', 'text_encoder.ln_final.bias', 'hyperformer_model.l10.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l9.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.5.ln_2.bias', 'image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'hyperformer_model.l8.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l4.tcn1.branches.3.1.bias', 'hyperformer_model.l9.tcn1.branches.2.4.weight', 'hyperformer_model.l6.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'text_encoder.transformer.resblocks.5.ln_1.weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l2.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l6.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l8.tcn1.branches.0.0.bias', 'hyperformer_model.l9.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l2.tcn1.branches.0.3.conv.bias', 'clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'hyperformer_model.l6.tcn1.branches.1.0.bias', 'hyperformer_model.l8.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.1.ln_1.bias', 'clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'hyperformer_model.l5.tcn1.branches.0.1.weight', 'hyperformer_model.l1.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'hyperformer_model.l10.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l1.tcn1.branches.3.1.bias', 'hyperformer_model.l9.vit1.attn.alpha', 'hyperformer_model.l2.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.6.ln_1.bias', 'hyperformer_model.l10.tcn1.branches.2.4.weight', 'hyperformer_model.l6.tcn1.branches.0.1.weight', 'image_encoder.transformer.resblocks.2.ln_1.weight', 'clip_text_encoder.positional_embedding', 'hyperformer_model.l6.tcn1.branches.0.1.bias', 'hyperformer_model.l10.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'hyperformer_model.l5.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l6.vit1.attn.q.weight', 'hyperformer_model.l9.vit1.attn.outer', 'hyperformer_model.l8.vit1.attn.q.weight', 'hyperformer_model.l5.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'hyperformer_model.l3.vit1.attn.kv.weight', 'hyperformer_model.l4.tcn1.branches.0.0.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'hyperformer_model.l10.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'text_encoder.transformer.resblocks.6.ln_2.bias', 'text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l7.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l6.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'hyperformer_model.l7.vit1.pe_proj.weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'hyperformer_model.l2.tcn1.branches.3.0.weight', 'hyperformer_model.l10.vit1.attn.outer', 'image_encoder.transformer.resblocks.11.ln_1.bias', 'clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'image_encoder.transformer.resblocks.9.ln_2.bias', 'clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'image_encoder.transformer.resblocks.10.ln_2.weight', 'text_encoder.transformer.resblocks.10.ln_2.weight', 'hyperformer_model.l10.tcn1.branches.0.3.bn.bias', 'image_encoder.transformer.resblocks.3.ln_2.bias', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'clip_text_encoder.ln_final.bias', 'image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'hyperformer_model.l1.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'hyperformer_model.l5.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l6.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l7.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l8.tcn1.branches.1.0.bias', 'hyperformer_model.l10.tcn1.branches.0.0.bias', 'image_encoder.transformer.resblocks.3.ln_2.weight', 'image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'text_encoder.transformer.resblocks.2.ln_2.bias', 'image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'hyperformer_model.l6.vit1.attn.proj.bias', 'hyperformer_model.l2.tcn1.branches.1.1.bias', 'hyperformer_model.l2.tcn1.branches.1.3.bn.weight', 'text_encoder.transformer.resblocks.3.ln_1.weight', 'hyperformer_model.l5.tcn1.branches.2.4.bias', 'hyperformer_model.l9.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'hyperformer_model.l3.tcn1.branches.0.1.weight', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'hyperformer_model.l2.tcn1.branches.2.4.bias', 'text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'hyperformer_model.l6.vit1.norm1.weight', 'image_encoder.positional_embedding', 'hyperformer_model.l2.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.5.ln_1.bias', 'hyperformer_model.l10.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l2.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'hyperformer_model.l5.tcn1.branches.1.0.bias', 'text_encoder.positional_embedding', 'text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'hyperformer_model.l5.tcn1.branches.0.1.bias', 'text_encoder.transformer.resblocks.9.ln_1.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l9.vit1.attn.rpe', 'hyperformer_model.l9.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'text_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l3.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'hyperformer_model.l10.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'image_encoder.transformer.resblocks.7.ln_1.bias', 'hyperformer_model.l1.tcn1.branches.0.0.bias', 'hyperformer_model.l7.tcn1.branches.0.0.weight', 'hyperformer_model.l1.tcn1.branches.2.4.weight', 'hyperformer_model.l5.tcn1.branches.2.1.bias', 'hyperformer_model.l8.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'hyperformer_model.l1.tcn1.branches.1.0.weight', 'hyperformer_model.l3.vit1.pe_proj.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'hyperformer_model.l3.vit1.norm1.weight', 'text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'image_encoder.transformer.resblocks.9.ln_1.bias', 'hyperformer_model.l8.tcn1.branches.2.0.weight', 'hyperformer_model.l7.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'image_encoder.transformer.resblocks.4.ln_2.bias', 'hyperformer_model.l6.vit1.attn.kv.weight', 'hyperformer_model.l5.residual.conv.bias', 'text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'hyperformer_model.l8.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l1.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l2.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'hyperformer_model.l5.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.3.1.bias', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l4.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'text_encoder.transformer.resblocks.4.ln_1.weight', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'hyperformer_model.l1.residual.conv.weight', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'hyperformer_model.l9.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'hyperformer_model.l3.vit1.attn.outer', 'text_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l9.vit1.attn.q.weight', 'hyperformer_model.l9.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l1.vit1.attn.outer', 'hyperformer_model.l4.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l9.vit1.attn.proj.bias', 'hyperformer_model.l9.tcn1.branches.1.1.weight', 'hyperformer_model.l3.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l7.vit1.attn.rpe', 'image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'hyperformer_model.l7.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'hyperformer_model.l9.tcn1.branches.0.1.weight', 'hyperformer_model.l1.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'hyperformer_model.data_bn.weight', 'hyperformer_model.l9.tcn1.branches.0.1.bias', 'hyperformer_model.l3.tcn1.branches.3.0.weight', 'hyperformer_model.fc2.bias', 'text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'hyperformer_model.l2.tcn1.branches.2.1.bias', 'text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.3.1.weight', 'hyperformer_model.l2.vit1.attn.rpe', 'hyperformer_model.l9.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'text_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l4.tcn1.branches.0.3.bn.weight', 'image_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l9.vit1.attn.kv.weight', 'hyperformer_model.l1.residual.bn.weight', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'hyperformer_model.l2.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l1.residual.bn.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.3.0.weight', 'image_encoder.transformer.resblocks.10.ln_2.bias', 'image_encoder.transformer.resblocks.6.ln_2.bias', 'hyperformer_model.l1.vit1.attn.q.weight', 'hyperformer_model.l4.vit1.norm1.weight', 'hyperformer_model.l8.vit1.attn.kv.weight', 'text_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l2.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l7.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l8.vit1.pe_proj.weight', 'hyperformer_model.l5.vit1.attn.q.weight', 'hyperformer_model.l6.tcn1.branches.2.4.bias', 'hyperformer_model.l1.tcn1.branches.0.3.conv.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.7.ln_1.bias', 'hyperformer_model.l6.vit1.attn.alpha', 'hyperformer_model.l9.tcn1.branches.1.1.bias', 'clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l2.vit1.attn.proj.bias', 'text_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l4.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'hyperformer_model.l10.vit1.attn.rpe', 'hyperformer_model.l3.tcn1.branches.2.1.bias', 'hyperformer_model.l8.tcn1.branches.1.1.weight', 'hyperformer_model.l2.tcn1.branches.1.1.weight', 'hyperformer_model.l2.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.9.ln_2.weight', 'hyperformer_model.l7.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.4.ln_1.bias', 'hyperformer_model.l1.tcn1.branches.1.3.conv.weight', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'hyperformer_model.l6.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l2.vit1.attn.proj.weight', 'hyperformer_model.l8.tcn1.branches.3.0.weight', 'hyperformer_model.l10.vit1.attn.proj.weight', 'hyperformer_model.l4.tcn1.branches.1.3.bn.weight', 'image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'hyperformer_model.l3.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'hyperformer_model.l8.residual.conv.weight', 'hyperformer_model.l5.residual.conv.weight', 'text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l2.vit1.attn.outer', 'hyperformer_model.l4.tcn1.branches.0.1.weight', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l4.vit1.pe_proj.weight', 'hyperformer_model.l5.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l6.vit1.attn.w1', 'text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.1.0.weight', 'hyperformer_model.l10.tcn1.branches.3.0.weight', 'hyperformer_model.l3.tcn1.branches.1.0.bias', 'hyperformer_model.l7.vit1.attn.outer', 'hyperformer_model.l5.tcn1.branches.1.3.bn.weight', 'text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'hyperformer_model.l3.vit1.attn.proj.weight', 'hyperformer_model.l1.tcn1.branches.2.1.bias', 'hyperformer_model.l5.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l7.tcn1.branches.1.0.bias', 'hyperformer_model.l7.vit1.norm1.bias', 'text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l7.tcn1.branches.2.4.bias', 'text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.l8.tcn1.branches.1.3.conv.bias', 'image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'text_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l5.vit1.norm1.weight', 'hyperformer_model.l10.tcn1.branches.2.1.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'image_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.l10.tcn1.branches.1.1.weight', 'hyperformer_model.l6.tcn1.branches.1.1.weight', 'clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l2.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l2.tcn1.branches.2.0.bias', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'hyperformer_model.l1.vit1.skip_proj.weight', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l3.tcn1.branches.0.0.bias', 'hyperformer_model.l7.tcn1.branches.1.1.weight', 'hyperformer_model.l3.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l3.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'image_encoder.ln_pre.bias', 'clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l6.vit1.attn.proj.weight', 'image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l4.tcn1.branches.2.1.bias', 'hyperformer_model.l7.tcn1.branches.1.1.bias', 'image_encoder.transformer.resblocks.8.ln_1.weight', 'hyperformer_model.l1.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'hyperformer_model.l3.tcn1.branches.1.1.weight', 'hyperformer_model.l1.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l9.vit1.norm1.bias', 'text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'hyperformer_model.l9.vit1.attn.proj.weight', 'hyperformer_model.l3.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'hyperformer_model.l9.vit1.norm1.weight', 'hyperformer_model.l9.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'hyperformer_model.l1.vit1.attn.rpe', 'hyperformer_model.l10.vit1.pe_proj.weight', 'hyperformer_model.l4.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.3.1.bias', 'hyperformer_model.l10.vit1.norm1.bias', 'image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l2.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'text_encoder.text_projection', 'image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'hyperformer_model.l5.vit1.attn.proj.weight', 'text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'image_encoder.transformer.resblocks.3.ln_1.bias', 'text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'hyperformer_model.l2.tcn1.branches.3.0.bias', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.10.ln_1.weight', 'text_encoder.transformer.resblocks.11.ln_2.bias', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'hyperformer_model.l8.tcn1.branches.3.0.bias', 'clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.0.1.weight', 'hyperformer_model.l2.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l9.tcn1.branches.2.0.weight', 'text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'hyperformer_model.l9.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.7.ln_1.weight', 'hyperformer_model.l8.vit1.attn.w1', 'hyperformer_model.l8.residual.bn.weight', 'hyperformer_model.l8.residual.bn.bias', 'hyperformer_model.l4.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'hyperformer_model.data_bn.bias', 'hyperformer_model.l5.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.9.ln_1.bias', 'text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'hyperformer_model.l9.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l5.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l2.vit1.attn.w1', 'hyperformer_model.l10.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'hyperformer_model.l1.tcn1.branches.2.1.weight', 'hyperformer_model.l4.vit1.attn.rpe', 'image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'image_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l7.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l8.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'text_encoder.transformer.resblocks.6.ln_1.weight', 'text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l8.vit1.attn.proj.weight', 'text_encoder.transformer.resblocks.0.ln_2.bias', 'image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l5.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'clip_text_encoder.ln_final.weight', 'hyperformer_model.l10.vit1.attn.alpha', 'image_encoder.transformer.resblocks.4.ln_2.weight', 'hyperformer_model.l4.vit1.attn.w1', 'image_encoder.transformer.resblocks.0.ln_2.weight', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l1.tcn1.branches.0.0.weight', 'hyperformer_model.l10.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'hyperformer_model.l4.tcn1.branches.0.0.bias', 'hyperformer_model.l8.vit1.attn.alpha', 'image_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l10.tcn1.branches.0.1.bias', 'hyperformer_model.l2.vit1.attn.alpha', 'image_encoder.class_embedding', 'image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'hyperformer_model.l2.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'hyperformer_model.l7.tcn1.branches.2.0.bias', 'hyperformer_model.l7.tcn1.branches.2.1.weight', 'hyperformer_model.l3.vit1.attn.rpe', 'image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.2.0.weight', 'hyperformer_model.l7.tcn1.branches.2.1.bias', 'hyperformer_model.l1.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'hyperformer_model.l8.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.1.ln_2.weight', 'text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'hyperformer_model.l5.tcn1.branches.0.0.weight', 'hyperformer_model.l5.tcn1.branches.3.0.weight', 'hyperformer_model.l9.vit1.attn.w1', 'text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'text_encoder.transformer.resblocks.4.ln_1.bias', 'hyperformer_model.l4.tcn1.branches.2.1.weight', 'hyperformer_model.l8.vit1.attn.outer', 'image_encoder.transformer.resblocks.3.ln_1.weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'text_encoder.transformer.resblocks.4.ln_2.weight', 'hyperformer_model.l5.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l6.tcn1.branches.2.0.bias', 'hyperformer_model.l9.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.8.ln_1.weight', 'text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l7.tcn1.branches.0.3.bn.bias', 'image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'image_encoder.transformer.resblocks.8.ln_1.bias', 'image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'hyperformer_model.l10.vit1.attn.q.weight', 'hyperformer_model.l8.residual.conv.bias', 'hyperformer_model.l6.tcn1.branches.0.3.conv.weight', 'image_encoder.transformer.resblocks.7.ln_1.weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'hyperformer_model.l5.tcn1.branches.1.1.weight', 'hyperformer_model.l7.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l5.vit1.attn.rpe', 'image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'hyperformer_model.l7.vit1.attn.q.weight', 'hyperformer_model.l7.vit1.attn.alpha', 'hyperformer_model.l7.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l10.tcn1.branches.0.1.weight', 'hyperformer_model.l5.vit1.norm1.bias', 'hyperformer_model.l10.vit1.attn.kv.weight', 'hyperformer_model.l9.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'hyperformer_model.l4.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l7.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'hyperformer_model.l5.residual.bn.weight', 'hyperformer_model.l10.vit1.attn.w1', 'image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l6.tcn1.branches.2.0.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'hyperformer_model.l3.vit1.attn.alpha', 'hyperformer_model.l2.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.1.1.bias', 'hyperformer_model.l4.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'hyperformer_model.l3.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l7.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.3.ln_2.bias', 'hyperformer_model.l1.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l3.vit1.attn.proj.bias', 'hyperformer_model.l7.tcn1.branches.3.0.weight', 'hyperformer_model.l8.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l10.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.9.ln_1.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'hyperformer_model.l2.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'hyperformer_model.l2.tcn1.branches.3.1.bias', 'hyperformer_model.l4.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'text_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l1.vit1.attn.alpha', 'hyperformer_model.l10.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.1.ln_2.weight', 'hyperformer_model.l9.tcn1.branches.2.0.bias', 'image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'hyperformer_model.l6.tcn1.branches.1.1.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'hyperformer_model.l2.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l5.vit1.pe_proj.weight', 'hyperformer_model.l2.vit1.norm1.weight', 'text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.l5.tcn1.branches.3.1.bias', 'text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'hyperformer_model.l7.vit1.attn.kv.weight', 'hyperformer_model.l7.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'hyperformer_model.l5.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.0.ln_2.weight', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'hyperformer_model.l7.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.9.ln_2.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l3.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'hyperformer_model.l3.tcn1.branches.2.4.weight', 'hyperformer_model.l4.vit1.attn.q.weight', 'text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'text_encoder.transformer.resblocks.2.ln_1.weight', 'hyperformer_model.l3.tcn1.branches.2.0.weight', 'hyperformer_model.l4.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.2.4.weight', 'hyperformer_model.l3.tcn1.branches.3.0.bias', 'hyperformer_model.l7.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l4.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l4.vit1.attn.alpha', 'hyperformer_model.l8.tcn1.branches.1.0.weight', 'hyperformer_model.l5.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'hyperformer_model.l10.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.7.ln_2.bias', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.8.ln_2.weight', 'image_encoder.transformer.resblocks.4.ln_1.weight', 'text_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l1.residual.conv.bias', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'hyperformer_model.l8.tcn1.branches.2.1.weight', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'hyperformer_model.l8.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.fc2.weight', 'image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'image_encoder.transformer.resblocks.2.ln_2.weight', 'clip_text_encoder.text_projection', 'text_encoder.ln_final.weight', 'clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.l6.vit1.attn.outer', 'clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'hyperformer_model.l5.vit1.attn.w1', 'image_encoder.transformer.resblocks.7.ln_2.bias', 'hyperformer_model.l8.vit1.norm1.weight', 'hyperformer_model.l1.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'hyperformer_model.l9.tcn1.branches.3.0.weight', 'hyperformer_model.l10.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l1.vit1.norm1.bias', 'hyperformer_model.l4.vit1.attn.proj.bias', 'hyperformer_model.l5.residual.bn.bias', 'hyperformer_model.l1.tcn1.branches.2.0.bias', 'hyperformer_model.l7.tcn1.branches.3.1.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'image_encoder.proj', 'hyperformer_model.l4.tcn1.branches.1.1.weight', 'hyperformer_model.l10.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'hyperformer_model.l3.vit1.norm1.bias', 'hyperformer_model.l7.tcn1.branches.1.0.weight', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'hyperformer_model.l1.tcn1.branches.3.1.weight', 'hyperformer_model.l7.vit1.norm1.weight', 'image_encoder.transformer.resblocks.6.ln_1.weight', 'text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.10.ln_2.bias', 'clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'hyperformer_model.l1.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l8.vit1.attn.rpe', 'hyperformer_model.l1.tcn1.branches.1.1.bias', 'hyperformer_model.l5.vit1.attn.outer', 'image_encoder.conv1.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'hyperformer_model.l6.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'text_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l10.vit1.attn.proj.bias', 'hyperformer_model.l2.vit1.pe_proj.weight', 'hyperformer_model.l3.tcn1.branches.1.0.weight', 'hyperformer_model.l3.tcn1.branches.2.4.bias', 'hyperformer_model.l9.tcn1.branches.3.0.bias', 'hyperformer_model.l4.tcn1.branches.1.0.bias', 'hyperformer_model.l6.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.6.ln_1.bias', 'image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'hyperformer_model.l2.tcn1.branches.0.1.weight', 'image_encoder.ln_post.weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.8.ln_1.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l2.vit1.norm1.bias', 'image_encoder.transformer.resblocks.1.ln_1.bias', 'text_encoder.transformer.resblocks.4.ln_2.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'hyperformer_model.l8.tcn1.branches.3.1.bias', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'text_encoder.transformer.resblocks.5.ln_2.weight', 'text_encoder.transformer.resblocks.11.ln_1.weight', 'image_encoder.transformer.resblocks.5.ln_1.bias', 'text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'hyperformer_model.l4.vit1.attn.outer', 'hyperformer_model.l6.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.11.ln_1.weight', 'text_encoder.transformer.resblocks.10.ln_1.weight', 'image_encoder.transformer.resblocks.5.ln_1.weight', 'clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'image_encoder.transformer.resblocks.0.ln_2.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.weight', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.ln_2.bias', 'image_encoder.transformer.resblocks.0.mlp.c_fc.weight'}
[2024-12-24 21:39:58 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 316): INFO Total learnable items: 835
[2024-12-24 21:40:13 ViT-B/16] (tools.py 147): INFO ==============> Resuming from ./workdirs/TEST_P1_SKeletonCLIP_alltrn_HFinit_zs_48_17Dec24/ckpt_epoch_0.pth....................
[2024-12-24 21:40:14 ViT-B/16] (tools.py 172): INFO resume VIFICLIP model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.clip_text_encoder.positional_embedding', 'module.clip_text_encoder.text_projection', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'module.clip_text_encoder.ln_final.weight', 'module.clip_text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:40:14 ViT-B/16] (tools.py 176): INFO ==============> Resuming from /data/users/asinha13/projects/CLIP4ADL/model_chkpnts/ntu_CS_P1_HF_pretrain_frzn_txt_zs_48_AS_16Jan24/ckpt_epoch_99.pth....................
[2024-12-24 21:40:14 ViT-B/16] (tools.py 218): INFO resume Hyperformer model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.text_encoder.positional_embedding', 'module.text_encoder.text_projection', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_1.weight', 'module.text_encoder.transformer.resblocks.0.ln_1.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_2.weight', 'module.text_encoder.transformer.resblocks.0.ln_2.bias', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_1.weight', 'module.text_encoder.transformer.resblocks.1.ln_1.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_2.weight', 'module.text_encoder.transformer.resblocks.1.ln_2.bias', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_1.weight', 'module.text_encoder.transformer.resblocks.2.ln_1.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_2.weight', 'module.text_encoder.transformer.resblocks.2.ln_2.bias', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_1.weight', 'module.text_encoder.transformer.resblocks.3.ln_1.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_2.weight', 'module.text_encoder.transformer.resblocks.3.ln_2.bias', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_1.weight', 'module.text_encoder.transformer.resblocks.4.ln_1.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_2.weight', 'module.text_encoder.transformer.resblocks.4.ln_2.bias', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_1.weight', 'module.text_encoder.transformer.resblocks.5.ln_1.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_2.weight', 'module.text_encoder.transformer.resblocks.5.ln_2.bias', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_1.weight', 'module.text_encoder.transformer.resblocks.6.ln_1.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_2.weight', 'module.text_encoder.transformer.resblocks.6.ln_2.bias', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_1.weight', 'module.text_encoder.transformer.resblocks.7.ln_1.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_2.weight', 'module.text_encoder.transformer.resblocks.7.ln_2.bias', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_1.weight', 'module.text_encoder.transformer.resblocks.8.ln_1.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_2.weight', 'module.text_encoder.transformer.resblocks.8.ln_2.bias', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_1.weight', 'module.text_encoder.transformer.resblocks.9.ln_1.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_2.weight', 'module.text_encoder.transformer.resblocks.9.ln_2.bias', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_1.weight', 'module.text_encoder.transformer.resblocks.10.ln_1.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_2.weight', 'module.text_encoder.transformer.resblocks.10.ln_2.bias', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_1.weight', 'module.text_encoder.transformer.resblocks.11.ln_1.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_2.weight', 'module.text_encoder.transformer.resblocks.11.ln_2.bias', 'module.text_encoder.ln_final.weight', 'module.text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:40:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][0/11317]	eta 17:13:01 lr 0.000022000	time 5.4768 (5.4768)	dist_loss 0.2850 (0.2850)	image_text_loss 3.9417 (3.9417)	pose_text_loss 2.8081 (2.8081)	tot_loss 9.5998 (9.5998)	mem 29650MB
[2024-12-24 21:40:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][50/11317]	eta 1:26:28 lr 0.000021999	time 0.3748 (0.4605)	dist_loss 0.0035 (0.1304)	image_text_loss 3.8673 (3.8683)	pose_text_loss 3.7481 (3.7203)	tot_loss 7.6503 (8.8930)	mem 29650MB
[2024-12-24 21:40:56 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][100/11317]	eta 1:17:44 lr 0.000021996	time 0.3770 (0.4159)	dist_loss 0.0204 (0.0720)	image_text_loss 3.8085 (3.8685)	pose_text_loss 3.5411 (3.7420)	tot_loss 7.5532 (8.3305)	mem 29650MB
[2024-12-24 21:41:14 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][150/11317]	eta 1:14:18 lr 0.000021991	time 0.3681 (0.3993)	dist_loss 0.0059 (0.0526)	image_text_loss 3.7818 (3.8637)	pose_text_loss 3.6942 (3.7226)	tot_loss 7.5350 (8.1124)	mem 29650MB
[2024-12-24 21:41:32 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][200/11317]	eta 1:12:21 lr 0.000021983	time 0.3606 (0.3905)	dist_loss 0.0210 (0.0433)	image_text_loss 3.8914 (3.8682)	pose_text_loss 3.5470 (3.7048)	tot_loss 7.6483 (8.0063)	mem 29650MB
[2024-12-24 21:41:50 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][250/11317]	eta 1:10:42 lr 0.000021974	time 0.3666 (0.3834)	dist_loss 0.0500 (0.0383)	image_text_loss 3.7315 (3.8721)	pose_text_loss 3.2626 (3.6883)	tot_loss 7.4937 (7.9429)	mem 29650MB
[2024-12-24 21:42:08 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][300/11317]	eta 1:09:33 lr 0.000021962	time 0.3634 (0.3789)	dist_loss 0.0125 (0.0351)	image_text_loss 3.8602 (3.8672)	pose_text_loss 3.5787 (3.6620)	tot_loss 7.5636 (7.8802)	mem 29650MB
[2024-12-24 21:42:26 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][350/11317]	eta 1:08:42 lr 0.000021949	time 0.3655 (0.3759)	dist_loss 0.0125 (0.0327)	image_text_loss 3.8698 (3.8703)	pose_text_loss 3.6219 (3.6535)	tot_loss 7.6170 (7.8508)	mem 29650MB
[2024-12-24 21:42:44 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][400/11317]	eta 1:08:01 lr 0.000021933	time 0.3490 (0.3738)	dist_loss 0.0348 (0.0309)	image_text_loss 3.8618 (3.8711)	pose_text_loss 3.1346 (3.6380)	tot_loss 7.3447 (7.8184)	mem 29650MB
[2024-12-24 21:43:01 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][450/11317]	eta 1:07:16 lr 0.000021915	time 0.3450 (0.3714)	dist_loss 0.0173 (0.0296)	image_text_loss 3.8983 (3.8709)	pose_text_loss 3.5064 (3.6216)	tot_loss 7.5776 (7.7886)	mem 29650MB
[2024-12-24 21:43:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][500/11317]	eta 1:06:42 lr 0.000021895	time 0.3501 (0.3700)	dist_loss 0.0227 (0.0287)	image_text_loss 3.7208 (3.8689)	pose_text_loss 3.1443 (3.6074)	tot_loss 7.0917 (7.7633)	mem 29650MB
[2024-12-24 21:43:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][550/11317]	eta 1:06:02 lr 0.000021873	time 0.3474 (0.3681)	dist_loss 0.0380 (0.0283)	image_text_loss 3.7938 (3.8689)	pose_text_loss 3.0414 (3.5967)	tot_loss 7.2149 (7.7482)	mem 29650MB
