[2024-12-24 21:35:50 ViT-B/16] (CL_main_v2.py 442): INFO working dir: ./workdirs/TEST_P2_SKIViFiCLIP_zs_48_25Dec24/
[2024-12-24 21:36:05 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 261): INFO Loading CLIP (backbone: ViT-B/16)
[2024-12-24 21:36:09 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 265): INFO Building Model
[2024-12-24 21:36:09 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 282): INFO Turning on gradients for COMPLETE SKI_VLM model
[2024-12-24 21:36:09 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 315): INFO Parameters to be updated: {'text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'hyperformer_model.l4.tcn1.branches.0.0.weight', 'hyperformer_model.l7.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.2.ln_2.bias', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'clip_text_encoder.text_projection', 'clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'hyperformer_model.l2.tcn1.branches.3.1.bias', 'hyperformer_model.l9.vit1.attn.outer', 'image_encoder.positional_embedding', 'clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.8.ln_2.weight', 'image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'hyperformer_model.l9.tcn1.branches.2.0.weight', 'hyperformer_model.l8.tcn1.branches.0.3.conv.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'hyperformer_model.l2.tcn1.branches.3.0.weight', 'image_encoder.transformer.resblocks.9.ln_2.weight', 'hyperformer_model.l8.vit1.pe_proj.weight', 'hyperformer_model.l9.tcn1.branches.3.0.bias', 'hyperformer_model.l5.tcn1.branches.3.0.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.10.ln_2.bias', 'hyperformer_model.l2.tcn1.branches.1.1.weight', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'text_encoder.transformer.resblocks.7.ln_1.bias', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'hyperformer_model.l4.vit1.pe_proj.weight', 'image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'image_encoder.ln_post.weight', 'image_encoder.transformer.resblocks.6.ln_1.bias', 'text_encoder.transformer.resblocks.7.ln_1.weight', 'hyperformer_model.l3.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l6.tcn1.branches.0.1.weight', 'hyperformer_model.l7.tcn1.branches.3.1.weight', 'hyperformer_model.l9.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'hyperformer_model.l2.tcn1.branches.0.1.bias', 'hyperformer_model.l6.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l10.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'hyperformer_model.l8.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.2.1.weight', 'hyperformer_model.l9.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l2.tcn1.branches.1.0.weight', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'text_encoder.transformer.resblocks.4.ln_1.bias', 'hyperformer_model.l2.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l4.tcn1.branches.1.1.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'hyperformer_model.l6.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'hyperformer_model.l10.tcn1.branches.1.3.bn.bias', 'text_encoder.transformer.resblocks.0.ln_2.bias', 'hyperformer_model.l1.vit1.attn.proj.weight', 'hyperformer_model.l1.vit1.skip_proj.weight', 'hyperformer_model.l8.residual.conv.bias', 'hyperformer_model.l10.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l6.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l8.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l8.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'hyperformer_model.l5.tcn1.branches.2.0.weight', 'text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.2.ln_1.bias', 'clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.2.0.bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.3.ln_1.weight', 'hyperformer_model.l6.vit1.pe_proj.weight', 'image_encoder.transformer.resblocks.0.ln_1.weight', 'image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'text_encoder.transformer.resblocks.1.ln_1.bias', 'text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l3.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'hyperformer_model.l5.vit1.attn.rpe', 'text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'hyperformer_model.l7.vit1.norm1.weight', 'text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'image_encoder.conv1.weight', 'hyperformer_model.l2.tcn1.branches.3.1.weight', 'hyperformer_model.l5.tcn1.branches.1.3.conv.weight', 'image_encoder.ln_pre.weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l3.tcn1.branches.0.0.weight', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'hyperformer_model.l10.tcn1.branches.1.0.weight', 'hyperformer_model.l1.tcn1.branches.3.1.weight', 'hyperformer_model.l2.tcn1.branches.0.0.weight', 'hyperformer_model.l1.vit1.attn.q.weight', 'text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.2.0.bias', 'hyperformer_model.l8.tcn1.branches.2.1.bias', 'hyperformer_model.l8.tcn1.branches.2.4.weight', 'hyperformer_model.l10.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'hyperformer_model.l1.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.0.ln_2.bias', 'hyperformer_model.l1.vit1.attn.proj.bias', 'hyperformer_model.l8.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l3.vit1.attn.w1', 'text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'hyperformer_model.l4.vit1.norm1.bias', 'hyperformer_model.l7.vit1.attn.rpe', 'text_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.l6.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.3.0.weight', 'image_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.l7.vit1.attn.alpha', 'image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'hyperformer_model.l5.vit1.attn.kv.weight', 'hyperformer_model.l4.vit1.attn.proj.bias', 'hyperformer_model.l2.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l7.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l3.tcn1.branches.0.3.bn.weight', 'image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l8.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'hyperformer_model.l2.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l1.residual.conv.weight', 'text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.10.ln_1.weight', 'text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l9.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l8.tcn1.branches.0.1.bias', 'hyperformer_model.l3.vit1.norm1.bias', 'image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'hyperformer_model.l3.vit1.attn.outer', 'hyperformer_model.l2.vit1.norm1.weight', 'hyperformer_model.l4.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'hyperformer_model.l3.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l10.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'hyperformer_model.l6.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.9.ln_1.weight', 'hyperformer_model.l7.tcn1.branches.0.3.conv.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.4.ln_1.weight', 'image_encoder.transformer.resblocks.9.ln_1.bias', 'clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'hyperformer_model.l10.tcn1.branches.1.1.weight', 'hyperformer_model.l1.vit1.norm1.bias', 'hyperformer_model.l1.tcn1.branches.0.0.bias', 'hyperformer_model.l1.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'hyperformer_model.l5.vit1.attn.alpha', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.data_bn.bias', 'hyperformer_model.l9.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l6.vit1.attn.proj.weight', 'hyperformer_model.l9.tcn1.branches.0.3.conv.bias', 'clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'hyperformer_model.l4.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l3.vit1.attn.proj.weight', 'hyperformer_model.l10.tcn1.branches.0.0.bias', 'hyperformer_model.l9.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'hyperformer_model.l2.vit1.attn.w1', 'image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'text_encoder.transformer.resblocks.11.ln_1.weight', 'clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'hyperformer_model.l8.tcn1.branches.1.0.weight', 'hyperformer_model.l7.tcn1.branches.0.0.bias', 'hyperformer_model.l2.vit1.attn.alpha', 'hyperformer_model.l4.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l6.tcn1.branches.2.0.weight', 'hyperformer_model.l5.tcn1.branches.1.1.bias', 'hyperformer_model.l9.tcn1.branches.0.1.bias', 'hyperformer_model.l9.vit1.attn.kv.weight', 'hyperformer_model.l1.tcn1.branches.2.0.weight', 'hyperformer_model.l3.vit1.attn.alpha', 'image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'hyperformer_model.l6.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.11.ln_2.bias', 'hyperformer_model.l9.vit1.attn.rpe', 'image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'hyperformer_model.l4.vit1.attn.alpha', 'image_encoder.transformer.resblocks.4.ln_1.bias', 'image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l9.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'image_encoder.class_embedding', 'image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.0.1.weight', 'hyperformer_model.l2.tcn1.branches.2.0.bias', 'hyperformer_model.l3.vit1.attn.proj.bias', 'hyperformer_model.l7.tcn1.branches.2.0.weight', 'clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.l1.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l6.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l7.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'clip_text_encoder.ln_final.bias', 'image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'hyperformer_model.l5.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'hyperformer_model.l1.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'hyperformer_model.l4.vit1.attn.proj.weight', 'hyperformer_model.l2.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'hyperformer_model.l2.tcn1.branches.1.1.bias', 'hyperformer_model.l7.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.10.ln_2.bias', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'hyperformer_model.l5.tcn1.branches.0.1.weight', 'hyperformer_model.l6.vit1.attn.proj.bias', 'hyperformer_model.l10.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l7.vit1.attn.w1', 'hyperformer_model.l10.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'hyperformer_model.l6.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'hyperformer_model.l10.tcn1.branches.3.0.weight', 'image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.ln_2.weight', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l4.tcn1.branches.3.1.weight', 'hyperformer_model.l8.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'hyperformer_model.l7.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l7.tcn1.branches.1.1.weight', 'hyperformer_model.l10.tcn1.branches.1.0.bias', 'hyperformer_model.l4.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l6.tcn1.branches.0.1.bias', 'hyperformer_model.l2.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.5.ln_2.bias', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l8.vit1.attn.proj.weight', 'text_encoder.transformer.resblocks.5.ln_1.weight', 'hyperformer_model.l5.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'hyperformer_model.l7.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.10.ln_1.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'hyperformer_model.l10.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l2.tcn1.branches.2.1.bias', 'hyperformer_model.l8.residual.bn.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'hyperformer_model.l3.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l6.vit1.attn.outer', 'hyperformer_model.l9.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.3.ln_2.bias', 'hyperformer_model.l8.vit1.attn.rpe', 'hyperformer_model.l8.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l9.tcn1.branches.2.4.bias', 'hyperformer_model.l4.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'hyperformer_model.l5.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'hyperformer_model.l5.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'image_encoder.ln_post.bias', 'text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'hyperformer_model.l8.tcn1.branches.3.1.bias', 'text_encoder.transformer.resblocks.4.ln_2.weight', 'clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l3.tcn1.branches.0.0.bias', 'hyperformer_model.l3.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l3.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'hyperformer_model.l8.vit1.attn.outer', 'hyperformer_model.l7.tcn1.branches.2.4.weight', 'hyperformer_model.l10.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.0.3.conv.weight', 'image_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l2.tcn1.branches.0.3.conv.bias', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'hyperformer_model.l8.vit1.attn.alpha', 'hyperformer_model.l5.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.3.ln_1.weight', 'hyperformer_model.l6.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l9.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.1.0.bias', 'hyperformer_model.l2.tcn1.branches.0.3.bn.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'hyperformer_model.l10.tcn1.branches.2.0.bias', 'image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'text_encoder.transformer.resblocks.3.ln_2.weight', 'image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'image_encoder.transformer.resblocks.1.ln_2.weight', 'text_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l3.tcn1.branches.1.1.bias', 'image_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l4.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l3.tcn1.branches.0.1.weight', 'text_encoder.positional_embedding', 'hyperformer_model.l1.residual.bn.weight', 'hyperformer_model.l3.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.6.ln_1.bias', 'hyperformer_model.l2.tcn1.branches.0.0.bias', 'hyperformer_model.l2.vit1.attn.outer', 'hyperformer_model.l7.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l6.tcn1.branches.3.1.weight', 'hyperformer_model.l4.tcn1.branches.2.0.bias', 'hyperformer_model.l5.tcn1.branches.3.1.weight', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'hyperformer_model.l2.tcn1.branches.3.0.bias', 'hyperformer_model.l3.tcn1.branches.2.4.bias', 'hyperformer_model.l8.residual.bn.bias', 'image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.1.ln_2.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'hyperformer_model.l6.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l6.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l6.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'hyperformer_model.l4.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'hyperformer_model.l4.tcn1.branches.2.1.bias', 'hyperformer_model.l10.tcn1.branches.3.1.bias', 'hyperformer_model.l5.residual.conv.weight', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'hyperformer_model.l4.tcn1.branches.3.0.bias', 'hyperformer_model.l3.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l6.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'hyperformer_model.l6.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.9.ln_2.bias', 'hyperformer_model.l10.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l3.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'hyperformer_model.l1.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.10.ln_1.weight', 'hyperformer_model.l2.tcn1.branches.0.1.weight', 'hyperformer_model.l5.tcn1.branches.0.3.conv.bias', 'clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l5.vit1.attn.q.weight', 'hyperformer_model.l6.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.fc2.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l5.tcn1.branches.2.4.bias', 'hyperformer_model.l4.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'hyperformer_model.l2.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'hyperformer_model.l4.vit1.attn.outer', 'hyperformer_model.l8.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'hyperformer_model.l9.tcn1.branches.1.3.bn.weight', 'text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'hyperformer_model.l10.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.1.ln_1.weight', 'hyperformer_model.l3.tcn1.branches.2.0.weight', 'hyperformer_model.l10.tcn1.branches.3.1.weight', 'hyperformer_model.l1.tcn1.branches.0.3.conv.weight', 'image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'image_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l5.vit1.norm1.weight', 'hyperformer_model.l7.vit1.attn.outer', 'text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'text_encoder.ln_final.bias', 'image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'text_encoder.text_projection', 'image_encoder.transformer.resblocks.9.ln_2.bias', 'text_encoder.ln_final.weight', 'hyperformer_model.l5.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.11.ln_1.bias', 'image_encoder.transformer.resblocks.7.ln_1.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'hyperformer_model.l6.tcn1.branches.3.1.bias', 'text_encoder.transformer.resblocks.1.ln_1.weight', 'image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'hyperformer_model.l2.vit1.pe_proj.weight', 'hyperformer_model.l4.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.3.ln_2.bias', 'hyperformer_model.l1.tcn1.branches.2.0.bias', 'hyperformer_model.l1.tcn1.branches.3.1.bias', 'hyperformer_model.l8.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.0.0.weight', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'hyperformer_model.l5.tcn1.branches.3.1.bias', 'hyperformer_model.l7.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'image_encoder.transformer.resblocks.8.ln_1.weight', 'text_encoder.transformer.resblocks.6.ln_2.weight', 'image_encoder.proj', 'hyperformer_model.l3.vit1.pe_proj.weight', 'hyperformer_model.l4.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'hyperformer_model.l8.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l10.vit1.pe_proj.weight', 'hyperformer_model.l4.tcn1.branches.3.0.weight', 'image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'image_encoder.transformer.resblocks.10.ln_2.weight', 'hyperformer_model.l7.vit1.attn.proj.bias', 'hyperformer_model.l9.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'image_encoder.transformer.resblocks.5.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'hyperformer_model.l9.tcn1.branches.2.1.weight', 'clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'hyperformer_model.l4.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l2.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'hyperformer_model.l1.tcn1.branches.1.1.weight', 'hyperformer_model.l7.vit1.attn.kv.weight', 'hyperformer_model.l5.vit1.pe_proj.weight', 'hyperformer_model.l7.tcn1.branches.2.1.weight', 'hyperformer_model.l8.tcn1.branches.2.0.bias', 'hyperformer_model.l1.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.7.ln_2.bias', 'clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'hyperformer_model.l7.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.2.ln_2.weight', 'hyperformer_model.l2.tcn1.branches.2.4.weight', 'hyperformer_model.l10.tcn1.branches.2.4.bias', 'hyperformer_model.l7.vit1.norm1.bias', 'text_encoder.transformer.resblocks.11.ln_1.bias', 'image_encoder.transformer.resblocks.2.ln_1.weight', 'clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'image_encoder.transformer.resblocks.2.ln_2.weight', 'hyperformer_model.l7.tcn1.branches.3.0.bias', 'hyperformer_model.l9.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l1.vit1.attn.rpe', 'image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l7.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.4.ln_1.weight', 'image_encoder.transformer.resblocks.5.ln_1.bias', 'hyperformer_model.l1.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l9.vit1.attn.q.weight', 'text_encoder.transformer.resblocks.10.ln_2.weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.data_bn.weight', 'hyperformer_model.l3.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l9.tcn1.branches.1.1.weight', 'hyperformer_model.l2.vit1.attn.proj.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'hyperformer_model.l8.tcn1.branches.0.0.weight', 'hyperformer_model.l2.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'text_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l4.vit1.attn.kv.weight', 'hyperformer_model.l10.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l7.tcn1.branches.3.1.bias', 'hyperformer_model.l8.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'hyperformer_model.l9.vit1.attn.proj.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.7.ln_1.bias', 'image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'hyperformer_model.l1.vit1.norm1.weight', 'text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.8.ln_1.weight', 'hyperformer_model.l5.residual.bn.bias', 'clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'text_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l8.residual.conv.weight', 'hyperformer_model.l4.tcn1.branches.0.0.bias', 'image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'hyperformer_model.l9.vit1.attn.alpha', 'hyperformer_model.l10.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.11.ln_1.weight', 'hyperformer_model.l7.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l4.tcn1.branches.2.4.weight', 'hyperformer_model.l5.vit1.attn.outer', 'hyperformer_model.l3.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l5.vit1.attn.proj.weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'image_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l3.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l9.tcn1.branches.1.1.bias', 'hyperformer_model.l10.vit1.attn.w1', 'image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l10.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'hyperformer_model.l5.tcn1.branches.1.0.weight', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l3.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'hyperformer_model.l8.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'hyperformer_model.l4.tcn1.branches.2.4.bias', 'hyperformer_model.l4.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l5.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'image_encoder.transformer.resblocks.3.ln_2.weight', 'text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'hyperformer_model.l9.tcn1.branches.1.0.weight', 'hyperformer_model.l6.tcn1.branches.2.4.weight', 'hyperformer_model.l1.vit1.pe_proj.weight', 'hyperformer_model.l10.vit1.attn.proj.bias', 'hyperformer_model.l8.tcn1.branches.2.0.weight', 'hyperformer_model.l10.vit1.attn.rpe', 'image_encoder.transformer.resblocks.9.ln_1.weight', 'hyperformer_model.l5.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.l8.tcn1.branches.2.4.bias', 'clip_text_encoder.positional_embedding', 'text_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l9.vit1.norm1.weight', 'text_encoder.transformer.resblocks.8.ln_2.weight', 'hyperformer_model.l9.tcn1.branches.1.3.bn.bias', 'text_encoder.transformer.resblocks.9.ln_2.weight', 'image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l8.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.5.ln_2.bias', 'text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'hyperformer_model.l5.vit1.attn.w1', 'image_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l7.vit1.attn.proj.weight', 'image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'hyperformer_model.l2.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.2.ln_2.bias', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.4.ln_2.bias', 'hyperformer_model.l3.tcn1.branches.1.3.bn.weight', 'image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'hyperformer_model.fc2.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'hyperformer_model.l9.tcn1.branches.3.1.bias', 'hyperformer_model.l3.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'hyperformer_model.l9.vit1.pe_proj.weight', 'hyperformer_model.l9.tcn1.branches.0.0.weight', 'hyperformer_model.l6.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l8.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.1.ln_1.bias', 'text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'hyperformer_model.l4.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l3.vit1.attn.q.weight', 'text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'text_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l1.vit1.attn.alpha', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.0.1.weight', 'hyperformer_model.l1.tcn1.branches.0.1.bias', 'hyperformer_model.l8.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l6.vit1.attn.alpha', 'clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'hyperformer_model.l6.tcn1.branches.2.0.bias', 'image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'hyperformer_model.l10.vit1.attn.proj.weight', 'text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'hyperformer_model.l1.vit1.attn.outer', 'text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'hyperformer_model.l3.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'hyperformer_model.l7.tcn1.branches.2.0.bias', 'hyperformer_model.l1.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l5.tcn1.branches.1.1.weight', 'image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l6.tcn1.branches.0.3.conv.bias', 'text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'hyperformer_model.l2.vit1.attn.kv.weight', 'hyperformer_model.l3.tcn1.branches.3.0.bias', 'hyperformer_model.l3.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l6.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l2.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l8.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'hyperformer_model.l7.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'hyperformer_model.l3.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l9.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'hyperformer_model.l7.tcn1.branches.1.1.bias', 'image_encoder.ln_pre.bias', 'hyperformer_model.l5.tcn1.branches.0.0.bias', 'image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'text_encoder.transformer.resblocks.2.ln_1.weight', 'hyperformer_model.l6.tcn1.branches.2.4.bias', 'hyperformer_model.l8.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'hyperformer_model.l4.tcn1.branches.3.1.bias', 'text_encoder.transformer.resblocks.11.ln_2.bias', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'hyperformer_model.l7.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l10.vit1.norm1.weight', 'hyperformer_model.l1.tcn1.branches.2.4.weight', 'hyperformer_model.l6.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l10.vit1.attn.alpha', 'hyperformer_model.l4.vit1.attn.w1', 'text_encoder.transformer.resblocks.6.ln_2.bias', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.5.ln_1.bias', 'hyperformer_model.l5.residual.bn.weight', 'hyperformer_model.l6.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l7.vit1.pe_proj.weight', 'image_encoder.transformer.resblocks.6.ln_2.bias', 'image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'hyperformer_model.l1.residual.bn.bias', 'image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.8.ln_2.bias', 'image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'hyperformer_model.l7.tcn1.branches.2.1.bias', 'hyperformer_model.l6.vit1.attn.w1', 'text_encoder.transformer.resblocks.7.ln_2.bias', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'hyperformer_model.l10.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l10.tcn1.branches.1.1.bias', 'hyperformer_model.l3.vit1.norm1.weight', 'hyperformer_model.l2.tcn1.branches.2.1.weight', 'hyperformer_model.l10.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l5.tcn1.branches.2.4.weight', 'hyperformer_model.l9.tcn1.branches.3.0.weight', 'hyperformer_model.l10.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l3.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'hyperformer_model.l4.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.11.ln_2.weight', 'image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'hyperformer_model.l4.tcn1.branches.1.1.weight', 'hyperformer_model.l1.tcn1.branches.3.0.bias', 'hyperformer_model.l2.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l5.tcn1.branches.2.1.bias', 'text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'hyperformer_model.l4.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l2.tcn1.branches.2.0.weight', 'hyperformer_model.l3.tcn1.branches.2.0.bias', 'hyperformer_model.l6.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.9.ln_1.bias', 'text_encoder.transformer.resblocks.4.ln_2.bias', 'hyperformer_model.l8.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l6.vit1.attn.q.weight', 'hyperformer_model.l1.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l8.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.l10.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'hyperformer_model.l4.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'hyperformer_model.l10.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.4.ln_2.weight', 'hyperformer_model.l1.residual.conv.bias', 'hyperformer_model.l10.vit1.attn.outer', 'text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'hyperformer_model.l1.tcn1.branches.2.1.weight', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'clip_text_encoder.ln_final.weight', 'hyperformer_model.l8.vit1.attn.w1', 'hyperformer_model.l2.tcn1.branches.1.0.bias', 'hyperformer_model.l5.residual.conv.bias', 'hyperformer_model.l8.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight'}
[2024-12-24 21:36:09 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 316): INFO Total learnable items: 835
[2024-12-24 21:36:30 ViT-B/16] (tools.py 147): INFO ==============> Resuming from ./workdirs/TEST_P1_SKeletonCLIP_alltrn_HFinit_zs_48_17Dec24/ckpt_epoch_0.pth....................
[2024-12-24 21:36:30 ViT-B/16] (tools.py 172): INFO resume VIFICLIP model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.clip_text_encoder.positional_embedding', 'module.clip_text_encoder.text_projection', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'module.clip_text_encoder.ln_final.weight', 'module.clip_text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:36:30 ViT-B/16] (tools.py 176): INFO ==============> Resuming from /data/users/asinha13/projects/CLIP4ADL/model_chkpnts/ntu_CS_P1_HF_pretrain_frzn_txt_zs_48_AS_16Jan24/ckpt_epoch_99.pth....................
[2024-12-24 21:36:31 ViT-B/16] (tools.py 218): INFO resume Hyperformer model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.text_encoder.positional_embedding', 'module.text_encoder.text_projection', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_1.weight', 'module.text_encoder.transformer.resblocks.0.ln_1.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_2.weight', 'module.text_encoder.transformer.resblocks.0.ln_2.bias', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_1.weight', 'module.text_encoder.transformer.resblocks.1.ln_1.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_2.weight', 'module.text_encoder.transformer.resblocks.1.ln_2.bias', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_1.weight', 'module.text_encoder.transformer.resblocks.2.ln_1.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_2.weight', 'module.text_encoder.transformer.resblocks.2.ln_2.bias', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_1.weight', 'module.text_encoder.transformer.resblocks.3.ln_1.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_2.weight', 'module.text_encoder.transformer.resblocks.3.ln_2.bias', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_1.weight', 'module.text_encoder.transformer.resblocks.4.ln_1.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_2.weight', 'module.text_encoder.transformer.resblocks.4.ln_2.bias', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_1.weight', 'module.text_encoder.transformer.resblocks.5.ln_1.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_2.weight', 'module.text_encoder.transformer.resblocks.5.ln_2.bias', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_1.weight', 'module.text_encoder.transformer.resblocks.6.ln_1.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_2.weight', 'module.text_encoder.transformer.resblocks.6.ln_2.bias', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_1.weight', 'module.text_encoder.transformer.resblocks.7.ln_1.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_2.weight', 'module.text_encoder.transformer.resblocks.7.ln_2.bias', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_1.weight', 'module.text_encoder.transformer.resblocks.8.ln_1.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_2.weight', 'module.text_encoder.transformer.resblocks.8.ln_2.bias', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_1.weight', 'module.text_encoder.transformer.resblocks.9.ln_1.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_2.weight', 'module.text_encoder.transformer.resblocks.9.ln_2.bias', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_1.weight', 'module.text_encoder.transformer.resblocks.10.ln_1.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_2.weight', 'module.text_encoder.transformer.resblocks.10.ln_2.bias', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_1.weight', 'module.text_encoder.transformer.resblocks.11.ln_1.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_2.weight', 'module.text_encoder.transformer.resblocks.11.ln_2.bias', 'module.text_encoder.ln_final.weight', 'module.text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:36:36 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][0/11317]	eta 16:33:11 lr 0.000022000	time 5.2656 (5.2656)	dist_loss 0.4876 (0.4876)	image_text_loss 3.9011 (3.9011)	pose_text_loss 2.4215 (2.4215)	tot_loss 11.1982 (11.1982)	mem 29650MB
[2024-12-24 21:36:53 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][50/11317]	eta 1:23:00 lr 0.000021999	time 0.3562 (0.4420)	dist_loss 0.0088 (0.1624)	image_text_loss 3.8138 (3.8738)	pose_text_loss 3.5693 (3.6800)	tot_loss 7.4715 (9.1776)	mem 29650MB
[2024-12-24 21:37:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][100/11317]	eta 1:14:26 lr 0.000021996	time 0.3475 (0.3982)	dist_loss 0.0096 (0.0876)	image_text_loss 4.0065 (3.8693)	pose_text_loss 3.8602 (3.7088)	tot_loss 7.9626 (8.4543)	mem 29650MB
[2024-12-24 21:38:19 ViT-B/16] (CL_main_v2.py 442): INFO working dir: ./workdirs/TEST_P2_SKIViFiCLIP_zs_48_25Dec24/
[2024-12-24 21:40:08 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 261): INFO Loading CLIP (backbone: ViT-B/16)
[2024-12-24 21:40:12 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 265): INFO Building Model
[2024-12-24 21:40:12 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 282): INFO Turning on gradients for COMPLETE SKI_VLM model
[2024-12-24 21:40:12 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 315): INFO Parameters to be updated: {'hyperformer_model.l7.vit1.norm1.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'hyperformer_model.l9.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'hyperformer_model.l9.tcn1.branches.2.1.weight', 'hyperformer_model.l4.vit1.attn.proj.weight', 'hyperformer_model.l10.tcn1.branches.2.1.weight', 'hyperformer_model.l6.tcn1.branches.2.0.bias', 'hyperformer_model.l7.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.5.ln_1.bias', 'hyperformer_model.l9.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'text_encoder.transformer.resblocks.9.ln_1.bias', 'hyperformer_model.l2.vit1.attn.rpe', 'hyperformer_model.l4.vit1.attn.w1', 'hyperformer_model.l4.vit1.pe_proj.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'text_encoder.transformer.resblocks.3.ln_1.weight', 'image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'hyperformer_model.l2.tcn1.branches.1.1.bias', 'hyperformer_model.l5.tcn1.branches.2.0.bias', 'hyperformer_model.l3.vit1.norm1.bias', 'hyperformer_model.l8.tcn1.branches.0.1.weight', 'hyperformer_model.l10.vit1.attn.alpha', 'clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'image_encoder.transformer.resblocks.9.ln_2.weight', 'hyperformer_model.l7.vit1.attn.alpha', 'hyperformer_model.l1.residual.bn.bias', 'hyperformer_model.l4.tcn1.branches.2.1.weight', 'hyperformer_model.l6.vit1.norm1.bias', 'hyperformer_model.l6.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'text_encoder.transformer.resblocks.2.ln_2.bias', 'text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l4.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l8.tcn1.branches.1.0.weight', 'hyperformer_model.l5.residual.conv.weight', 'hyperformer_model.l7.vit1.attn.q.weight', 'hyperformer_model.l6.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'hyperformer_model.l5.tcn1.branches.0.1.bias', 'hyperformer_model.l6.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.9.ln_1.bias', 'text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'hyperformer_model.l8.vit1.attn.outer', 'hyperformer_model.l1.tcn1.branches.0.1.weight', 'hyperformer_model.l5.residual.conv.bias', 'image_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l1.tcn1.branches.2.4.bias', 'hyperformer_model.l9.vit1.attn.outer', 'clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l9.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.10.ln_2.bias', 'hyperformer_model.l10.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l7.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.3.ln_1.bias', 'text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'text_encoder.text_projection', 'text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'hyperformer_model.l2.vit1.norm1.weight', 'hyperformer_model.l6.vit1.attn.rpe', 'hyperformer_model.l1.tcn1.branches.1.3.conv.bias', 'image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l4.tcn1.branches.2.0.weight', 'hyperformer_model.l4.tcn1.branches.3.0.weight', 'hyperformer_model.l1.vit1.attn.w1', 'hyperformer_model.l2.vit1.attn.outer', 'hyperformer_model.l7.tcn1.branches.0.0.weight', 'hyperformer_model.l5.tcn1.branches.0.1.weight', 'hyperformer_model.l7.tcn1.branches.1.1.bias', 'hyperformer_model.l2.vit1.attn.alpha', 'text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'hyperformer_model.l2.tcn1.branches.0.1.bias', 'hyperformer_model.l1.tcn1.branches.3.1.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'image_encoder.conv1.weight', 'hyperformer_model.l8.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l9.tcn1.branches.2.0.bias', 'clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.0.3.bn.weight', 'image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'hyperformer_model.l2.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'hyperformer_model.l3.vit1.attn.outer', 'image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'hyperformer_model.l4.tcn1.branches.2.0.bias', 'hyperformer_model.l8.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l8.tcn1.branches.2.1.weight', 'hyperformer_model.l6.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'hyperformer_model.data_bn.weight', 'hyperformer_model.l10.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l7.vit1.attn.kv.weight', 'hyperformer_model.l6.vit1.norm1.weight', 'image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l5.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l10.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l4.vit1.attn.kv.weight', 'hyperformer_model.l4.tcn1.branches.3.1.bias', 'hyperformer_model.l4.vit1.attn.alpha', 'text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'hyperformer_model.l1.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'hyperformer_model.l8.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'hyperformer_model.l3.tcn1.branches.3.1.weight', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l7.vit1.attn.proj.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'hyperformer_model.l3.tcn1.branches.1.1.weight', 'hyperformer_model.l4.tcn1.branches.1.0.bias', 'hyperformer_model.l8.vit1.attn.w1', 'hyperformer_model.l10.vit1.attn.q.weight', 'hyperformer_model.l10.tcn1.branches.1.0.weight', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'image_encoder.transformer.resblocks.8.ln_1.bias', 'text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l5.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'hyperformer_model.l3.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'hyperformer_model.l4.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'hyperformer_model.l8.tcn1.branches.0.1.bias', 'hyperformer_model.l10.vit1.pe_proj.weight', 'image_encoder.class_embedding', 'hyperformer_model.l2.tcn1.branches.3.1.bias', 'text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'hyperformer_model.l10.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.4.ln_2.bias', 'hyperformer_model.l7.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'hyperformer_model.l2.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'hyperformer_model.l2.tcn1.branches.1.1.weight', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'hyperformer_model.l3.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'text_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l4.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.7.ln_1.bias', 'hyperformer_model.l1.vit1.attn.kv.weight', 'hyperformer_model.l8.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'hyperformer_model.l1.vit1.attn.proj.weight', 'image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'hyperformer_model.l2.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.0.ln_2.weight', 'text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'hyperformer_model.l5.vit1.attn.proj.bias', 'hyperformer_model.l2.tcn1.branches.1.3.bn.weight', 'image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'hyperformer_model.l2.tcn1.branches.3.0.weight', 'hyperformer_model.l5.tcn1.branches.1.1.weight', 'hyperformer_model.l9.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.l5.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l10.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.7.ln_1.weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l3.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'image_encoder.transformer.resblocks.1.ln_2.weight', 'hyperformer_model.l4.vit1.attn.rpe', 'hyperformer_model.l9.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l9.tcn1.branches.0.0.bias', 'hyperformer_model.fc2.weight', 'hyperformer_model.l5.vit1.attn.rpe', 'image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'hyperformer_model.l6.vit1.attn.alpha', 'image_encoder.transformer.resblocks.1.ln_1.bias', 'clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.l3.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'hyperformer_model.l6.tcn1.branches.1.1.weight', 'hyperformer_model.l9.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l6.tcn1.branches.3.1.bias', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.3.0.bias', 'hyperformer_model.l2.tcn1.branches.1.0.bias', 'hyperformer_model.l8.vit1.attn.proj.weight', 'text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'text_encoder.transformer.resblocks.7.ln_2.weight', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'hyperformer_model.l1.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l5.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l7.vit1.attn.w1', 'hyperformer_model.l3.vit1.attn.proj.bias', 'hyperformer_model.l10.vit1.attn.proj.weight', 'image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'text_encoder.transformer.resblocks.5.ln_1.weight', 'clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'hyperformer_model.l1.tcn1.branches.0.0.weight', 'hyperformer_model.l6.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.1.ln_1.bias', 'text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'hyperformer_model.l1.tcn1.branches.1.0.weight', 'hyperformer_model.l9.vit1.attn.w1', 'text_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l9.tcn1.branches.0.3.conv.bias', 'text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.8.ln_2.weight', 'hyperformer_model.l10.tcn1.branches.0.3.bn.bias', 'image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'hyperformer_model.l10.vit1.attn.outer', 'image_encoder.transformer.resblocks.7.ln_2.bias', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'hyperformer_model.l3.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'hyperformer_model.l7.tcn1.branches.2.1.weight', 'hyperformer_model.l5.vit1.attn.alpha', 'hyperformer_model.fc2.bias', 'image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'hyperformer_model.l4.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.0.ln_1.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'image_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l9.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'image_encoder.ln_post.weight', 'text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l2.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'hyperformer_model.l10.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'hyperformer_model.l3.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.7.ln_2.bias', 'text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'hyperformer_model.l7.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'hyperformer_model.l7.tcn1.branches.2.4.bias', 'text_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l5.vit1.attn.outer', 'hyperformer_model.l6.tcn1.branches.2.4.bias', 'hyperformer_model.l2.vit1.pe_proj.weight', 'hyperformer_model.l1.tcn1.branches.2.0.bias', 'hyperformer_model.l8.residual.bn.bias', 'text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'image_encoder.transformer.resblocks.5.ln_1.weight', 'hyperformer_model.l3.tcn1.branches.0.1.weight', 'hyperformer_model.l10.tcn1.branches.0.0.weight', 'hyperformer_model.l5.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l4.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l3.tcn1.branches.2.0.weight', 'hyperformer_model.l6.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'hyperformer_model.l2.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l4.vit1.attn.proj.bias', 'hyperformer_model.l10.tcn1.branches.2.1.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.weight', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'text_encoder.transformer.resblocks.2.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.0.ln_1.weight', 'text_encoder.transformer.resblocks.10.ln_2.bias', 'hyperformer_model.l3.vit1.attn.proj.weight', 'clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l3.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'hyperformer_model.l1.tcn1.branches.1.1.bias', 'hyperformer_model.l10.tcn1.branches.2.0.weight', 'hyperformer_model.l7.vit1.attn.outer', 'clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l10.tcn1.branches.0.1.bias', 'hyperformer_model.l2.tcn1.branches.2.1.weight', 'hyperformer_model.l1.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'image_encoder.transformer.resblocks.7.ln_2.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'hyperformer_model.l10.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.3.1.bias', 'hyperformer_model.l9.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'clip_text_encoder.text_projection', 'image_encoder.ln_pre.bias', 'hyperformer_model.l1.tcn1.branches.0.1.bias', 'hyperformer_model.l3.vit1.norm1.weight', 'image_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l8.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'hyperformer_model.l7.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'hyperformer_model.l8.vit1.attn.alpha', 'clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'image_encoder.transformer.resblocks.1.ln_1.weight', 'image_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l9.tcn1.branches.1.0.weight', 'hyperformer_model.l5.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'text_encoder.ln_final.weight', 'image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'hyperformer_model.l1.vit1.attn.alpha', 'hyperformer_model.l2.tcn1.branches.0.1.weight', 'hyperformer_model.l5.vit1.norm1.bias', 'image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'text_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l3.tcn1.branches.2.4.bias', 'hyperformer_model.l8.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.2.ln_1.bias', 'clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.11.ln_1.weight', 'hyperformer_model.l1.vit1.attn.proj.bias', 'clip_text_encoder.ln_final.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'hyperformer_model.l4.tcn1.branches.1.1.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'hyperformer_model.l6.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l6.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'image_encoder.ln_pre.weight', 'clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'clip_text_encoder.ln_final.weight', 'hyperformer_model.l5.tcn1.branches.1.1.bias', 'hyperformer_model.l3.tcn1.branches.2.4.weight', 'clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'hyperformer_model.l4.tcn1.branches.3.0.bias', 'hyperformer_model.l2.tcn1.branches.1.0.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'hyperformer_model.l8.vit1.norm1.bias', 'hyperformer_model.l7.tcn1.branches.1.3.bn.weight', 'text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'hyperformer_model.l6.tcn1.branches.0.1.weight', 'hyperformer_model.l8.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l6.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.4.ln_2.weight', 'text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'hyperformer_model.l7.tcn1.branches.2.1.bias', 'hyperformer_model.l3.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l5.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.4.ln_1.weight', 'image_encoder.positional_embedding', 'text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'hyperformer_model.l3.vit1.pe_proj.weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'hyperformer_model.l4.vit1.attn.outer', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'text_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l2.vit1.attn.proj.weight', 'image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'hyperformer_model.l3.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l5.vit1.pe_proj.weight', 'clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'hyperformer_model.l8.tcn1.branches.0.0.bias', 'image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'hyperformer_model.l9.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l1.residual.conv.weight', 'text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'hyperformer_model.l10.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'hyperformer_model.l1.tcn1.branches.3.0.weight', 'text_encoder.ln_final.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l10.vit1.attn.kv.weight', 'hyperformer_model.l1.residual.conv.bias', 'image_encoder.transformer.resblocks.2.ln_2.weight', 'hyperformer_model.l7.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l8.vit1.pe_proj.weight', 'hyperformer_model.l4.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l9.vit1.norm1.bias', 'hyperformer_model.l10.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'hyperformer_model.l4.tcn1.branches.1.3.conv.weight', 'clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'hyperformer_model.l2.tcn1.branches.2.4.weight', 'hyperformer_model.l10.tcn1.branches.1.1.weight', 'hyperformer_model.l7.tcn1.branches.2.0.bias', 'text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'text_encoder.transformer.resblocks.9.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l10.vit1.attn.rpe', 'hyperformer_model.l3.tcn1.branches.1.0.bias', 'text_encoder.positional_embedding', 'clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'hyperformer_model.l1.tcn1.branches.1.3.bn.bias', 'text_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l1.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l8.tcn1.branches.3.1.bias', 'hyperformer_model.l7.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.6.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l3.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l4.vit1.norm1.bias', 'hyperformer_model.l3.tcn1.branches.2.1.bias', 'text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'image_encoder.transformer.resblocks.6.ln_1.bias', 'text_encoder.transformer.resblocks.10.ln_1.weight', 'text_encoder.transformer.resblocks.4.ln_1.bias', 'image_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l8.residual.conv.bias', 'text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'hyperformer_model.data_bn.bias', 'image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'hyperformer_model.l4.vit1.attn.q.weight', 'text_encoder.transformer.resblocks.11.ln_2.bias', 'hyperformer_model.l8.tcn1.branches.2.0.bias', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'hyperformer_model.l8.vit1.attn.rpe', 'hyperformer_model.l1.tcn1.branches.2.0.weight', 'hyperformer_model.l1.vit1.skip_proj.weight', 'hyperformer_model.l10.tcn1.branches.3.1.weight', 'hyperformer_model.l2.tcn1.branches.2.0.bias', 'text_encoder.transformer.resblocks.4.ln_2.bias', 'text_encoder.transformer.resblocks.5.ln_1.bias', 'text_encoder.transformer.resblocks.7.ln_1.weight', 'hyperformer_model.l6.tcn1.branches.0.0.weight', 'hyperformer_model.l8.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'hyperformer_model.l8.tcn1.branches.2.0.weight', 'hyperformer_model.l7.vit1.norm1.weight', 'hyperformer_model.l6.vit1.pe_proj.weight', 'text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'hyperformer_model.l2.tcn1.branches.0.3.bn.weight', 'image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'image_encoder.transformer.resblocks.8.ln_2.weight', 'hyperformer_model.l3.tcn1.branches.0.3.conv.weight', 'image_encoder.transformer.resblocks.2.ln_2.bias', 'hyperformer_model.l7.vit1.pe_proj.weight', 'clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l1.tcn1.branches.1.1.weight', 'hyperformer_model.l5.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l2.vit1.attn.kv.weight', 'text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'hyperformer_model.l4.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'text_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l10.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'hyperformer_model.l1.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l5.tcn1.branches.2.1.bias', 'hyperformer_model.l8.residual.bn.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'hyperformer_model.l4.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.9.ln_2.bias', 'text_encoder.transformer.resblocks.6.ln_2.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.3.0.weight', 'hyperformer_model.l2.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'hyperformer_model.l8.residual.conv.weight', 'image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l6.vit1.attn.proj.bias', 'hyperformer_model.l9.tcn1.branches.3.1.weight', 'hyperformer_model.l10.vit1.norm1.weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.9.ln_1.weight', 'hyperformer_model.l5.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'hyperformer_model.l3.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.1.ln_2.weight', 'text_encoder.transformer.resblocks.4.ln_2.weight', 'hyperformer_model.l7.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l4.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l10.vit1.norm1.bias', 'image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'hyperformer_model.l3.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.4.ln_1.weight', 'hyperformer_model.l2.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'hyperformer_model.l7.tcn1.branches.0.1.weight', 'hyperformer_model.l9.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.10.ln_2.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'text_encoder.transformer.resblocks.10.ln_2.weight', 'hyperformer_model.l4.tcn1.branches.0.1.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.8.ln_1.weight', 'hyperformer_model.l5.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.1.ln_2.bias', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'hyperformer_model.l7.tcn1.branches.3.0.weight', 'hyperformer_model.l9.tcn1.branches.3.1.bias', 'hyperformer_model.l2.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l8.tcn1.branches.2.1.bias', 'hyperformer_model.l8.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l10.tcn1.branches.0.3.bn.weight', 'image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'hyperformer_model.l2.vit1.norm1.bias', 'image_encoder.ln_post.bias', 'hyperformer_model.l4.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'text_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l8.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l8.vit1.attn.kv.weight', 'hyperformer_model.l1.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'hyperformer_model.l7.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.0.ln_2.bias', 'hyperformer_model.l3.tcn1.branches.0.0.bias', 'hyperformer_model.l10.tcn1.branches.0.0.bias', 'image_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.l3.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l2.vit1.attn.proj.bias', 'hyperformer_model.l4.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'hyperformer_model.l9.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l5.tcn1.branches.3.0.weight', 'hyperformer_model.l1.vit1.norm1.bias', 'text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'hyperformer_model.l9.tcn1.branches.0.0.weight', 'hyperformer_model.l5.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l9.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'image_encoder.transformer.resblocks.11.ln_1.weight', 'image_encoder.transformer.resblocks.11.ln_2.bias', 'text_encoder.transformer.resblocks.8.ln_1.weight', 'image_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.l9.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l9.tcn1.branches.2.1.bias', 'hyperformer_model.l4.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l1.vit1.pe_proj.weight', 'hyperformer_model.l8.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l3.vit1.attn.q.weight', 'hyperformer_model.l6.vit1.attn.outer', 'image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'hyperformer_model.l9.vit1.attn.q.weight', 'hyperformer_model.l5.tcn1.branches.2.0.weight', 'text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'hyperformer_model.l3.vit1.attn.kv.weight', 'hyperformer_model.l5.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l6.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.2.4.bias', 'hyperformer_model.l6.vit1.attn.proj.weight', 'hyperformer_model.l8.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'image_encoder.transformer.resblocks.4.ln_1.bias', 'image_encoder.transformer.resblocks.3.ln_2.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'hyperformer_model.l5.residual.bn.bias', 'hyperformer_model.l1.vit1.attn.outer', 'hyperformer_model.l10.tcn1.branches.0.1.weight', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'text_encoder.transformer.resblocks.5.ln_2.bias', 'hyperformer_model.l3.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'hyperformer_model.l5.vit1.attn.kv.weight', 'hyperformer_model.l9.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.3.0.bias', 'hyperformer_model.l4.tcn1.branches.0.1.bias', 'hyperformer_model.l2.tcn1.branches.3.0.bias', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'hyperformer_model.l2.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l7.tcn1.branches.2.4.weight', 'hyperformer_model.l9.vit1.norm1.weight', 'hyperformer_model.l10.tcn1.branches.2.0.bias', 'hyperformer_model.l9.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.0.ln_2.bias', 'image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'hyperformer_model.l3.vit1.attn.alpha', 'hyperformer_model.l5.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l8.tcn1.branches.3.1.weight', 'hyperformer_model.l5.vit1.attn.proj.weight', 'hyperformer_model.l5.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.8.ln_2.bias', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.ln_1.weight', 'image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.1.1.bias', 'hyperformer_model.l9.vit1.attn.proj.weight', 'hyperformer_model.l6.tcn1.branches.2.1.weight', 'hyperformer_model.l4.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l7.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'hyperformer_model.l4.tcn1.branches.1.0.weight', 'hyperformer_model.l5.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l5.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l4.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l9.tcn1.branches.3.0.weight', 'clip_text_encoder.positional_embedding', 'hyperformer_model.l9.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'hyperformer_model.l6.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.11.ln_1.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l6.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.5.ln_2.weight', 'text_encoder.transformer.resblocks.6.ln_1.bias', 'hyperformer_model.l6.tcn1.branches.0.1.bias', 'hyperformer_model.l2.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.9.ln_2.weight', 'hyperformer_model.l1.residual.bn.weight', 'image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.l2.vit1.attn.w1', 'hyperformer_model.l8.tcn1.branches.1.1.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l5.residual.bn.weight', 'image_encoder.transformer.resblocks.10.ln_1.weight', 'hyperformer_model.l9.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.3.ln_2.bias', 'hyperformer_model.l3.tcn1.branches.2.0.bias', 'image_encoder.proj', 'image_encoder.transformer.resblocks.7.ln_1.bias', 'text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l1.vit1.attn.rpe', 'hyperformer_model.l3.tcn1.branches.3.0.bias', 'hyperformer_model.l7.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'hyperformer_model.l7.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.3.ln_1.weight', 'image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'hyperformer_model.l8.tcn1.branches.1.3.bn.bias', 'text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.2.ln_2.weight', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'text_encoder.transformer.resblocks.9.ln_1.weight', 'clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'hyperformer_model.l7.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l9.vit1.pe_proj.weight', 'hyperformer_model.l9.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'hyperformer_model.l2.tcn1.branches.2.0.weight', 'hyperformer_model.l9.vit1.attn.alpha', 'clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.2.4.weight', 'hyperformer_model.l7.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'hyperformer_model.l7.vit1.attn.rpe', 'text_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l5.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l1.tcn1.branches.2.4.weight', 'hyperformer_model.l6.tcn1.branches.1.1.bias', 'hyperformer_model.l1.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'hyperformer_model.l3.vit1.attn.w1', 'hyperformer_model.l10.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l2.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l7.tcn1.branches.2.0.weight', 'text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l3.vit1.attn.rpe', 'image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l9.tcn1.branches.0.1.bias', 'text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'hyperformer_model.l2.tcn1.branches.3.1.weight'}
[2024-12-24 21:40:12 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 316): INFO Total learnable items: 835
[2024-12-24 21:40:13 ViT-B/16] (tools.py 147): INFO ==============> Resuming from ./workdirs/TEST_P1_SKeletonCLIP_alltrn_HFinit_zs_48_17Dec24/ckpt_epoch_0.pth....................
[2024-12-24 21:40:14 ViT-B/16] (tools.py 172): INFO resume VIFICLIP model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.clip_text_encoder.positional_embedding', 'module.clip_text_encoder.text_projection', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'module.clip_text_encoder.ln_final.weight', 'module.clip_text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:40:14 ViT-B/16] (tools.py 176): INFO ==============> Resuming from /data/users/asinha13/projects/CLIP4ADL/model_chkpnts/ntu_CS_P1_HF_pretrain_frzn_txt_zs_48_AS_16Jan24/ckpt_epoch_99.pth....................
[2024-12-24 21:40:14 ViT-B/16] (tools.py 218): INFO resume Hyperformer model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.text_encoder.positional_embedding', 'module.text_encoder.text_projection', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_1.weight', 'module.text_encoder.transformer.resblocks.0.ln_1.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_2.weight', 'module.text_encoder.transformer.resblocks.0.ln_2.bias', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_1.weight', 'module.text_encoder.transformer.resblocks.1.ln_1.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_2.weight', 'module.text_encoder.transformer.resblocks.1.ln_2.bias', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_1.weight', 'module.text_encoder.transformer.resblocks.2.ln_1.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_2.weight', 'module.text_encoder.transformer.resblocks.2.ln_2.bias', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_1.weight', 'module.text_encoder.transformer.resblocks.3.ln_1.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_2.weight', 'module.text_encoder.transformer.resblocks.3.ln_2.bias', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_1.weight', 'module.text_encoder.transformer.resblocks.4.ln_1.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_2.weight', 'module.text_encoder.transformer.resblocks.4.ln_2.bias', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_1.weight', 'module.text_encoder.transformer.resblocks.5.ln_1.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_2.weight', 'module.text_encoder.transformer.resblocks.5.ln_2.bias', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_1.weight', 'module.text_encoder.transformer.resblocks.6.ln_1.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_2.weight', 'module.text_encoder.transformer.resblocks.6.ln_2.bias', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_1.weight', 'module.text_encoder.transformer.resblocks.7.ln_1.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_2.weight', 'module.text_encoder.transformer.resblocks.7.ln_2.bias', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_1.weight', 'module.text_encoder.transformer.resblocks.8.ln_1.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_2.weight', 'module.text_encoder.transformer.resblocks.8.ln_2.bias', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_1.weight', 'module.text_encoder.transformer.resblocks.9.ln_1.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_2.weight', 'module.text_encoder.transformer.resblocks.9.ln_2.bias', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_1.weight', 'module.text_encoder.transformer.resblocks.10.ln_1.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_2.weight', 'module.text_encoder.transformer.resblocks.10.ln_2.bias', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_1.weight', 'module.text_encoder.transformer.resblocks.11.ln_1.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_2.weight', 'module.text_encoder.transformer.resblocks.11.ln_2.bias', 'module.text_encoder.ln_final.weight', 'module.text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:40:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][0/11317]	eta 17:32:32 lr 0.000022000	time 5.5803 (5.5803)	dist_loss 0.4876 (0.4876)	image_text_loss 3.9011 (3.9011)	pose_text_loss 2.4215 (2.4215)	tot_loss 11.1982 (11.1982)	mem 29650MB
[2024-12-24 21:40:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][50/11317]	eta 1:26:46 lr 0.000021999	time 0.3752 (0.4621)	dist_loss 0.0086 (0.1625)	image_text_loss 3.8125 (3.8737)	pose_text_loss 3.5781 (3.6808)	tot_loss 7.4762 (9.1796)	mem 29650MB
[2024-12-24 21:40:56 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][100/11317]	eta 1:17:53 lr 0.000021996	time 0.3793 (0.4166)	dist_loss 0.0096 (0.0878)	image_text_loss 4.0038 (3.8690)	pose_text_loss 3.8541 (3.7097)	tot_loss 7.9543 (8.4570)	mem 29650MB
[2024-12-24 21:41:14 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][150/11317]	eta 1:14:26 lr 0.000021991	time 0.3790 (0.3999)	dist_loss 0.0090 (0.0637)	image_text_loss 3.8623 (3.8744)	pose_text_loss 3.8018 (3.7138)	tot_loss 7.7541 (8.2253)	mem 29650MB
[2024-12-24 21:41:32 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][200/11317]	eta 1:12:26 lr 0.000021983	time 0.3401 (0.3910)	dist_loss 0.0201 (0.0522)	image_text_loss 3.7221 (3.8760)	pose_text_loss 3.3205 (3.6961)	tot_loss 7.2434 (8.0945)	mem 29650MB
[2024-12-24 21:41:50 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][250/11317]	eta 1:10:47 lr 0.000021974	time 0.3566 (0.3838)	dist_loss 0.0246 (0.0455)	image_text_loss 3.7132 (3.8738)	pose_text_loss 3.4114 (3.6744)	tot_loss 7.3704 (8.0032)	mem 29650MB
[2024-12-24 21:42:08 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][300/11317]	eta 1:09:37 lr 0.000021962	time 0.3574 (0.3792)	dist_loss 0.0053 (0.0415)	image_text_loss 3.8549 (3.8770)	pose_text_loss 3.8216 (3.6648)	tot_loss 7.7299 (7.9565)	mem 29650MB
[2024-12-24 21:42:26 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][350/11317]	eta 1:08:45 lr 0.000021949	time 0.3651 (0.3762)	dist_loss 0.0150 (0.0378)	image_text_loss 3.9472 (3.8792)	pose_text_loss 3.7390 (3.6614)	tot_loss 7.8363 (7.9186)	mem 29650MB
[2024-12-24 21:42:44 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][400/11317]	eta 1:08:04 lr 0.000021933	time 0.3558 (0.3741)	dist_loss 0.0295 (0.0354)	image_text_loss 3.8720 (3.8786)	pose_text_loss 3.4427 (3.6463)	tot_loss 7.6097 (7.8785)	mem 29650MB
[2024-12-24 21:43:01 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][450/11317]	eta 1:07:18 lr 0.000021915	time 0.3475 (0.3716)	dist_loss 0.0225 (0.0339)	image_text_loss 3.9811 (3.8775)	pose_text_loss 3.8070 (3.6287)	tot_loss 8.0132 (7.8450)	mem 29650MB
[2024-12-24 21:43:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][500/11317]	eta 1:06:45 lr 0.000021895	time 0.3412 (0.3703)	dist_loss 0.0165 (0.0324)	image_text_loss 3.9432 (3.8774)	pose_text_loss 3.6372 (3.6163)	tot_loss 7.7458 (7.8177)	mem 29650MB
[2024-12-24 21:43:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][550/11317]	eta 1:06:05 lr 0.000021873	time 0.3466 (0.3683)	dist_loss 0.0251 (0.0314)	image_text_loss 3.8334 (3.8779)	pose_text_loss 3.2907 (3.6061)	tot_loss 7.3756 (7.7976)	mem 29650MB
[2024-12-24 21:43:54 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][600/11317]	eta 1:05:29 lr 0.000021849	time 0.3457 (0.3667)	dist_loss 0.0443 (0.0307)	image_text_loss 3.8996 (3.8772)	pose_text_loss 3.3616 (3.5914)	tot_loss 7.7045 (7.7756)	mem 29650MB
[2024-12-24 21:44:12 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][650/11317]	eta 1:05:04 lr 0.000021823	time 0.3671 (0.3661)	dist_loss 0.0483 (0.0301)	image_text_loss 3.9385 (3.8767)	pose_text_loss 3.3189 (3.5840)	tot_loss 7.7399 (7.7615)	mem 29650MB
[2024-12-24 21:44:30 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][700/11317]	eta 1:04:36 lr 0.000021795	time 0.3752 (0.3652)	dist_loss 0.0174 (0.0296)	image_text_loss 3.8241 (3.8778)	pose_text_loss 3.5303 (3.5744)	tot_loss 7.5283 (7.7485)	mem 29650MB
[2024-12-24 21:44:47 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][750/11317]	eta 1:04:08 lr 0.000021765	time 0.3525 (0.3642)	dist_loss 0.0556 (0.0291)	image_text_loss 3.7924 (3.8771)	pose_text_loss 2.6908 (3.5686)	tot_loss 7.0392 (7.7370)	mem 29650MB
[2024-12-24 21:45:05 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][800/11317]	eta 1:03:47 lr 0.000021733	time 0.3547 (0.3640)	dist_loss 0.0116 (0.0287)	image_text_loss 3.9159 (3.8763)	pose_text_loss 3.7050 (3.5599)	tot_loss 7.7367 (7.7231)	mem 29650MB
[2024-12-24 21:45:23 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][850/11317]	eta 1:03:24 lr 0.000021698	time 0.3477 (0.3635)	dist_loss 0.0254 (0.0285)	image_text_loss 3.9280 (3.8757)	pose_text_loss 3.6212 (3.5488)	tot_loss 7.8035 (7.7097)	mem 29650MB
[2024-12-24 21:45:41 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][900/11317]	eta 1:03:00 lr 0.000021662	time 0.3538 (0.3629)	dist_loss 0.0180 (0.0282)	image_text_loss 3.9584 (3.8753)	pose_text_loss 3.4963 (3.5408)	tot_loss 7.6347 (7.6982)	mem 29650MB
[2024-12-24 21:45:58 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][950/11317]	eta 1:02:38 lr 0.000021624	time 0.3512 (0.3625)	dist_loss 0.0133 (0.0283)	image_text_loss 3.8126 (3.8752)	pose_text_loss 3.7745 (3.5292)	tot_loss 7.7198 (7.6869)	mem 29650MB
[2024-12-24 21:46:16 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1000/11317]	eta 1:02:15 lr 0.000021583	time 0.3598 (0.3621)	dist_loss 0.0285 (0.0282)	image_text_loss 3.8641 (3.8749)	pose_text_loss 3.1771 (3.5190)	tot_loss 7.3258 (7.6756)	mem 29650MB
[2024-12-24 21:46:34 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1050/11317]	eta 1:01:52 lr 0.000021541	time 0.4293 (0.3616)	dist_loss 0.0430 (0.0281)	image_text_loss 3.8195 (3.8744)	pose_text_loss 2.7647 (3.5112)	tot_loss 7.0143 (7.6665)	mem 29650MB
[2024-12-24 21:46:52 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1100/11317]	eta 1:01:33 lr 0.000021496	time 0.3625 (0.3615)	dist_loss 0.0309 (0.0280)	image_text_loss 3.8739 (3.8743)	pose_text_loss 3.1760 (3.5023)	tot_loss 7.3594 (7.6568)	mem 29650MB
[2024-12-24 21:47:10 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1150/11317]	eta 1:01:13 lr 0.000021450	time 0.3533 (0.3613)	dist_loss 0.0222 (0.0281)	image_text_loss 3.8135 (3.8744)	pose_text_loss 3.3354 (3.4923)	tot_loss 7.3709 (7.6472)	mem 29650MB
[2024-12-24 21:47:27 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1200/11317]	eta 1:00:53 lr 0.000021401	time 0.3595 (0.3611)	dist_loss 0.0372 (0.0281)	image_text_loss 3.8216 (3.8742)	pose_text_loss 3.2920 (3.4834)	tot_loss 7.4855 (7.6386)	mem 29650MB
[2024-12-24 21:47:45 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1250/11317]	eta 1:00:33 lr 0.000021351	time 0.3403 (0.3609)	dist_loss 0.0307 (0.0281)	image_text_loss 3.9796 (3.8744)	pose_text_loss 3.6003 (3.4781)	tot_loss 7.8864 (7.6331)	mem 29650MB
[2024-12-24 21:48:03 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1300/11317]	eta 1:00:11 lr 0.000021299	time 0.3494 (0.3606)	dist_loss 0.0177 (0.0279)	image_text_loss 3.7940 (3.8734)	pose_text_loss 3.4433 (3.4752)	tot_loss 7.4146 (7.6275)	mem 29650MB
[2024-12-24 21:48:21 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1350/11317]	eta 0:59:53 lr 0.000021244	time 0.3567 (0.3605)	dist_loss 0.0131 (0.0280)	image_text_loss 3.8743 (3.8731)	pose_text_loss 3.6740 (3.4667)	tot_loss 7.6795 (7.6201)	mem 29650MB
[2024-12-24 21:48:39 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1400/11317]	eta 0:59:34 lr 0.000021188	time 0.3513 (0.3604)	dist_loss 0.0324 (0.0282)	image_text_loss 3.8577 (3.8727)	pose_text_loss 3.1907 (3.4571)	tot_loss 7.3721 (7.6115)	mem 29650MB
[2024-12-24 21:48:56 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1450/11317]	eta 0:59:13 lr 0.000021130	time 0.3372 (0.3601)	dist_loss 0.0308 (0.0283)	image_text_loss 3.9840 (3.8728)	pose_text_loss 3.2187 (3.4499)	tot_loss 7.5111 (7.6056)	mem 29650MB
[2024-12-24 21:49:14 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1500/11317]	eta 0:58:52 lr 0.000021069	time 0.4141 (0.3598)	dist_loss 0.0620 (0.0284)	image_text_loss 3.8611 (3.8725)	pose_text_loss 2.5486 (3.4417)	tot_loss 7.0299 (7.5984)	mem 29650MB
[2024-12-24 21:49:31 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1550/11317]	eta 0:58:32 lr 0.000021007	time 0.3822 (0.3597)	dist_loss 0.0706 (0.0286)	image_text_loss 3.8538 (3.8727)	pose_text_loss 2.3353 (3.4335)	tot_loss 6.8950 (7.5922)	mem 29650MB
[2024-12-24 21:49:49 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1600/11317]	eta 0:58:13 lr 0.000020943	time 0.3629 (0.3595)	dist_loss 0.0131 (0.0287)	image_text_loss 3.9732 (3.8726)	pose_text_loss 3.8257 (3.4257)	tot_loss 7.9297 (7.5858)	mem 29650MB
[2024-12-24 21:50:07 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1650/11317]	eta 0:57:55 lr 0.000020877	time 0.3542 (0.3595)	dist_loss 0.0357 (0.0289)	image_text_loss 3.8270 (3.8730)	pose_text_loss 2.8730 (3.4183)	tot_loss 7.0574 (7.5806)	mem 29650MB
[2024-12-24 21:50:25 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1700/11317]	eta 0:57:35 lr 0.000020810	time 0.3525 (0.3594)	dist_loss 0.0230 (0.0291)	image_text_loss 3.8887 (3.8734)	pose_text_loss 3.7277 (3.4110)	tot_loss 7.8468 (7.5749)	mem 29650MB
[2024-12-24 21:50:43 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1750/11317]	eta 0:57:16 lr 0.000020740	time 0.3456 (0.3592)	dist_loss 0.0360 (0.0292)	image_text_loss 3.8636 (3.8734)	pose_text_loss 3.0194 (3.4036)	tot_loss 7.2431 (7.5691)	mem 29650MB
[2024-12-24 21:51:00 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1800/11317]	eta 0:56:57 lr 0.000020669	time 0.4339 (0.3591)	dist_loss 0.0345 (0.0294)	image_text_loss 3.9126 (3.8734)	pose_text_loss 2.9880 (3.3947)	tot_loss 7.2460 (7.5624)	mem 29650MB
[2024-12-24 21:51:18 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1850/11317]	eta 0:56:38 lr 0.000020595	time 0.3690 (0.3590)	dist_loss 0.0423 (0.0296)	image_text_loss 3.8694 (3.8735)	pose_text_loss 2.8362 (3.3870)	tot_loss 7.1291 (7.5567)	mem 29650MB
[2024-12-24 21:51:36 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1900/11317]	eta 0:56:19 lr 0.000020520	time 0.3595 (0.3589)	dist_loss 0.0395 (0.0297)	image_text_loss 3.8661 (3.8734)	pose_text_loss 2.9514 (3.3807)	tot_loss 7.2126 (7.5516)	mem 29650MB
[2024-12-24 21:51:54 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1950/11317]	eta 0:56:01 lr 0.000020443	time 0.3619 (0.3588)	dist_loss 0.0538 (0.0299)	image_text_loss 3.8919 (3.8734)	pose_text_loss 2.7909 (3.3743)	tot_loss 7.2206 (7.5465)	mem 29650MB
[2024-12-24 21:52:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2000/11317]	eta 0:55:41 lr 0.000020364	time 0.3496 (0.3587)	dist_loss 0.0534 (0.0301)	image_text_loss 3.8650 (3.8734)	pose_text_loss 2.5915 (3.3666)	tot_loss 6.9908 (7.5410)	mem 29650MB
[2024-12-24 21:52:29 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2050/11317]	eta 0:55:22 lr 0.000020284	time 0.3587 (0.3585)	dist_loss 0.0420 (0.0303)	image_text_loss 3.8673 (3.8735)	pose_text_loss 2.8632 (3.3595)	tot_loss 7.1505 (7.5358)	mem 29650MB
[2024-12-24 21:52:47 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2100/11317]	eta 0:55:04 lr 0.000020201	time 0.3538 (0.3585)	dist_loss 0.0357 (0.0304)	image_text_loss 3.8834 (3.8735)	pose_text_loss 3.3639 (3.3542)	tot_loss 7.6041 (7.5319)	mem 29650MB
[2024-12-24 21:53:05 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2150/11317]	eta 0:54:45 lr 0.000020117	time 0.3530 (0.3584)	dist_loss 0.0263 (0.0305)	image_text_loss 3.8744 (3.8735)	pose_text_loss 3.2595 (3.3507)	tot_loss 7.3968 (7.5290)	mem 29650MB
[2024-12-24 21:53:22 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2200/11317]	eta 0:54:26 lr 0.000020031	time 0.3688 (0.3583)	dist_loss 0.0369 (0.0306)	image_text_loss 3.8704 (3.8735)	pose_text_loss 2.9717 (3.3449)	tot_loss 7.2115 (7.5246)	mem 29650MB
[2024-12-24 21:53:40 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2250/11317]	eta 0:54:07 lr 0.000019944	time 0.3593 (0.3582)	dist_loss 0.0226 (0.0308)	image_text_loss 3.8733 (3.8735)	pose_text_loss 3.3881 (3.3385)	tot_loss 7.4877 (7.5197)	mem 29650MB
[2024-12-24 21:53:58 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2300/11317]	eta 0:53:49 lr 0.000019855	time 0.3534 (0.3581)	dist_loss 0.0251 (0.0309)	image_text_loss 3.8759 (3.8734)	pose_text_loss 3.2627 (3.3324)	tot_loss 7.3895 (7.5153)	mem 29650MB
[2024-12-24 21:54:15 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2350/11317]	eta 0:53:29 lr 0.000019764	time 0.3470 (0.3580)	dist_loss 0.0296 (0.0312)	image_text_loss 3.9032 (3.8734)	pose_text_loss 3.0509 (3.3259)	tot_loss 7.2501 (7.5109)	mem 29650MB
[2024-12-24 21:54:33 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2400/11317]	eta 0:53:11 lr 0.000019671	time 0.3505 (0.3579)	dist_loss 0.0639 (0.0313)	image_text_loss 3.8856 (3.8736)	pose_text_loss 2.4595 (3.3208)	tot_loss 6.9845 (7.5078)	mem 29650MB
[2024-12-24 21:54:51 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2450/11317]	eta 0:52:53 lr 0.000019577	time 0.3487 (0.3579)	dist_loss 0.0281 (0.0316)	image_text_loss 3.8947 (3.8734)	pose_text_loss 3.1639 (3.3129)	tot_loss 7.3394 (7.5021)	mem 29650MB
[2024-12-24 21:55:08 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2500/11317]	eta 0:52:34 lr 0.000019481	time 0.3382 (0.3577)	dist_loss 0.0210 (0.0317)	image_text_loss 3.9332 (3.8734)	pose_text_loss 3.3208 (3.3078)	tot_loss 7.4640 (7.4985)	mem 29650MB
[2024-12-24 21:55:26 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2550/11317]	eta 0:52:15 lr 0.000019384	time 0.3446 (0.3577)	dist_loss 0.0530 (0.0319)	image_text_loss 3.8641 (3.8734)	pose_text_loss 2.8184 (3.3014)	tot_loss 7.2124 (7.4938)	mem 29650MB
[2024-12-24 21:55:44 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2600/11317]	eta 0:51:57 lr 0.000019285	time 0.3377 (0.3576)	dist_loss 0.0407 (0.0320)	image_text_loss 3.8580 (3.8733)	pose_text_loss 3.2755 (3.2963)	tot_loss 7.5407 (7.4901)	mem 29650MB
[2024-12-24 21:56:01 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2650/11317]	eta 0:51:38 lr 0.000019184	time 0.3387 (0.3575)	dist_loss 0.0781 (0.0322)	image_text_loss 3.8697 (3.8733)	pose_text_loss 2.2828 (3.2914)	tot_loss 6.9338 (7.4866)	mem 29650MB
[2024-12-24 21:56:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2700/11317]	eta 0:51:20 lr 0.000019082	time 0.3508 (0.3575)	dist_loss 0.0323 (0.0324)	image_text_loss 3.8831 (3.8733)	pose_text_loss 3.3727 (3.2855)	tot_loss 7.5786 (7.4826)	mem 29650MB
[2024-12-24 21:56:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2750/11317]	eta 0:51:02 lr 0.000018978	time 0.3608 (0.3575)	dist_loss 0.0289 (0.0325)	image_text_loss 3.9160 (3.8733)	pose_text_loss 3.1445 (3.2811)	tot_loss 7.3499 (7.4794)	mem 29650MB
[2024-12-24 21:56:55 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2800/11317]	eta 0:50:44 lr 0.000018873	time 0.3712 (0.3574)	dist_loss 0.0191 (0.0326)	image_text_loss 3.7874 (3.8733)	pose_text_loss 3.1823 (3.2779)	tot_loss 7.1604 (7.4772)	mem 29650MB
[2024-12-24 21:57:13 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2850/11317]	eta 0:50:26 lr 0.000018766	time 0.3613 (0.3575)	dist_loss 0.0500 (0.0328)	image_text_loss 3.8775 (3.8731)	pose_text_loss 2.8141 (3.2720)	tot_loss 7.1915 (7.4731)	mem 29650MB
[2024-12-24 21:57:31 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2900/11317]	eta 0:50:08 lr 0.000018658	time 0.3535 (0.3575)	dist_loss 0.0558 (0.0330)	image_text_loss 3.8800 (3.8732)	pose_text_loss 2.6057 (3.2669)	tot_loss 7.0435 (7.4696)	mem 29650MB
[2024-12-24 21:57:48 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2950/11317]	eta 0:49:50 lr 0.000018548	time 0.3565 (0.3574)	dist_loss 0.0543 (0.0331)	image_text_loss 3.8604 (3.8732)	pose_text_loss 2.5699 (3.2609)	tot_loss 6.9735 (7.4655)	mem 29650MB
[2024-12-24 21:58:06 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3000/11317]	eta 0:49:32 lr 0.000018437	time 0.3641 (0.3574)	dist_loss 0.0726 (0.0333)	image_text_loss 3.8671 (3.8732)	pose_text_loss 2.3642 (3.2558)	tot_loss 6.9576 (7.4620)	mem 29650MB
[2024-12-24 21:58:24 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3050/11317]	eta 0:49:14 lr 0.000018324	time 0.3535 (0.3574)	dist_loss 0.0590 (0.0335)	image_text_loss 3.8683 (3.8732)	pose_text_loss 2.6220 (3.2500)	tot_loss 7.0802 (7.4583)	mem 29650MB
[2024-12-24 21:58:42 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3100/11317]	eta 0:48:56 lr 0.000018210	time 0.3553 (0.3574)	dist_loss 0.0415 (0.0336)	image_text_loss 3.8701 (3.8732)	pose_text_loss 2.8647 (3.2462)	tot_loss 7.1502 (7.4554)	mem 29650MB
[2024-12-24 21:59:00 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3150/11317]	eta 0:48:38 lr 0.000018095	time 0.3607 (0.3574)	dist_loss 0.0470 (0.0338)	image_text_loss 3.8696 (3.8731)	pose_text_loss 3.0758 (3.2415)	tot_loss 7.4152 (7.4522)	mem 29650MB
[2024-12-24 21:59:18 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3200/11317]	eta 0:48:20 lr 0.000017979	time 0.3453 (0.3573)	dist_loss 0.0342 (0.0338)	image_text_loss 3.8703 (3.8731)	pose_text_loss 2.9408 (3.2388)	tot_loss 7.1535 (7.4501)	mem 29650MB
[2024-12-24 21:59:35 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3250/11317]	eta 0:48:02 lr 0.000017861	time 0.3659 (0.3573)	dist_loss 0.0244 (0.0339)	image_text_loss 3.8716 (3.8731)	pose_text_loss 3.7611 (3.2348)	tot_loss 7.8769 (7.4473)	mem 29650MB
[2024-12-24 21:59:53 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3300/11317]	eta 0:47:44 lr 0.000017741	time 0.3531 (0.3573)	dist_loss 0.0330 (0.0341)	image_text_loss 3.8727 (3.8731)	pose_text_loss 3.0965 (3.2301)	tot_loss 7.2996 (7.4441)	mem 29650MB
[2024-12-24 22:00:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3350/11317]	eta 0:47:26 lr 0.000017621	time 0.3544 (0.3572)	dist_loss 0.0359 (0.0342)	image_text_loss 3.8737 (3.8731)	pose_text_loss 2.9332 (3.2267)	tot_loss 7.1657 (7.4418)	mem 29650MB
[2024-12-24 22:00:28 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3400/11317]	eta 0:47:07 lr 0.000017499	time 0.3547 (0.3572)	dist_loss 0.0208 (0.0343)	image_text_loss 3.8728 (3.8731)	pose_text_loss 3.4056 (3.2230)	tot_loss 7.4866 (7.4393)	mem 29650MB
[2024-12-24 22:00:46 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3450/11317]	eta 0:46:50 lr 0.000017376	time 0.3531 (0.3572)	dist_loss 0.0595 (0.0345)	image_text_loss 3.8705 (3.8730)	pose_text_loss 2.5020 (3.2189)	tot_loss 6.9673 (7.4365)	mem 29650MB
[2024-12-24 22:01:04 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3500/11317]	eta 0:46:31 lr 0.000017252	time 0.3532 (0.3572)	dist_loss 0.0684 (0.0346)	image_text_loss 3.8720 (3.8730)	pose_text_loss 2.3782 (3.2148)	tot_loss 6.9337 (7.4337)	mem 29650MB
[2024-12-24 22:01:22 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3550/11317]	eta 0:46:13 lr 0.000017126	time 0.3482 (0.3571)	dist_loss 0.0319 (0.0347)	image_text_loss 3.8750 (3.8730)	pose_text_loss 3.5967 (3.2111)	tot_loss 7.7911 (7.4313)	mem 29650MB
[2024-12-24 22:01:40 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3600/11317]	eta 0:45:55 lr 0.000017000	time 0.3457 (0.3571)	dist_loss 0.0397 (0.0349)	image_text_loss 3.8828 (3.8729)	pose_text_loss 2.8384 (3.2057)	tot_loss 7.1178 (7.4276)	mem 29650MB
[2024-12-24 22:01:58 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3650/11317]	eta 0:45:38 lr 0.000016872	time 0.3560 (0.3571)	dist_loss 0.0746 (0.0350)	image_text_loss 3.8709 (3.8729)	pose_text_loss 2.3529 (3.2018)	tot_loss 6.9703 (7.4247)	mem 29650MB
[2024-12-24 22:02:15 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3700/11317]	eta 0:45:19 lr 0.000016743	time 0.3549 (0.3571)	dist_loss 0.0251 (0.0351)	image_text_loss 3.8481 (3.8729)	pose_text_loss 3.1527 (3.1986)	tot_loss 7.2515 (7.4225)	mem 29650MB
[2024-12-24 22:02:33 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3750/11317]	eta 0:45:02 lr 0.000016613	time 0.3487 (0.3571)	dist_loss 0.0466 (0.0351)	image_text_loss 3.8635 (3.8728)	pose_text_loss 2.7027 (3.1966)	tot_loss 7.0320 (7.4208)	mem 29650MB
[2024-12-24 22:02:51 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3800/11317]	eta 0:44:44 lr 0.000016482	time 0.3519 (0.3571)	dist_loss 0.0386 (0.0352)	image_text_loss 3.8715 (3.8728)	pose_text_loss 3.3609 (3.1932)	tot_loss 7.6182 (7.4185)	mem 29650MB
[2024-12-24 22:03:09 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3850/11317]	eta 0:44:26 lr 0.000016350	time 0.3473 (0.3570)	dist_loss 0.0418 (0.0353)	image_text_loss 3.8714 (3.8728)	pose_text_loss 3.1417 (3.1900)	tot_loss 7.4310 (7.4163)	mem 29650MB
[2024-12-24 22:03:27 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3900/11317]	eta 0:44:08 lr 0.000016217	time 0.3434 (0.3571)	dist_loss 0.0662 (0.0355)	image_text_loss 3.8778 (3.8728)	pose_text_loss 2.4082 (3.1857)	tot_loss 6.9483 (7.4133)	mem 29650MB
[2024-12-24 22:03:45 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3950/11317]	eta 0:43:50 lr 0.000016083	time 0.3534 (0.3571)	dist_loss 0.0389 (0.0356)	image_text_loss 3.8624 (3.8728)	pose_text_loss 2.9453 (3.1815)	tot_loss 7.1965 (7.4106)	mem 29650MB
[2024-12-24 22:04:02 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4000/11317]	eta 0:43:32 lr 0.000015948	time 0.3565 (0.3571)	dist_loss 0.0457 (0.0358)	image_text_loss 3.8697 (3.8727)	pose_text_loss 2.8488 (3.1787)	tot_loss 7.1751 (7.4090)	mem 29650MB
[2024-12-24 22:04:20 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4050/11317]	eta 0:43:14 lr 0.000015813	time 0.3510 (0.3571)	dist_loss 0.0221 (0.0359)	image_text_loss 3.8516 (3.8727)	pose_text_loss 3.5204 (3.1749)	tot_loss 7.5935 (7.4063)	mem 29650MB
[2024-12-24 22:04:38 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4100/11317]	eta 0:42:56 lr 0.000015676	time 0.3445 (0.3570)	dist_loss 0.0572 (0.0360)	image_text_loss 3.8703 (3.8727)	pose_text_loss 2.5412 (3.1715)	tot_loss 6.9833 (7.4042)	mem 29650MB
[2024-12-24 22:04:56 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4150/11317]	eta 0:42:38 lr 0.000015538	time 0.3556 (0.3570)	dist_loss 0.0634 (0.0361)	image_text_loss 3.8724 (3.8727)	pose_text_loss 2.4494 (3.1688)	tot_loss 6.9559 (7.4025)	mem 29650MB
[2024-12-24 22:05:13 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4200/11317]	eta 0:42:20 lr 0.000015400	time 0.3500 (0.3570)	dist_loss 0.0714 (0.0362)	image_text_loss 3.8734 (3.8726)	pose_text_loss 2.3411 (3.1648)	tot_loss 6.9285 (7.3997)	mem 29650MB
[2024-12-24 22:05:31 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4250/11317]	eta 0:42:02 lr 0.000015260	time 0.3492 (0.3569)	dist_loss 0.0271 (0.0363)	image_text_loss 3.8567 (3.8726)	pose_text_loss 3.2379 (3.1629)	tot_loss 7.3653 (7.3983)	mem 29650MB
[2024-12-24 22:05:49 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4300/11317]	eta 0:41:44 lr 0.000015120	time 0.3562 (0.3569)	dist_loss 0.0560 (0.0364)	image_text_loss 3.8432 (3.8726)	pose_text_loss 2.5645 (3.1594)	tot_loss 6.9674 (7.3959)	mem 29650MB
[2024-12-24 22:06:07 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4350/11317]	eta 0:41:26 lr 0.000014979	time 0.3700 (0.3569)	dist_loss 0.0719 (0.0365)	image_text_loss 3.8757 (3.8726)	pose_text_loss 2.3473 (3.1567)	tot_loss 6.9422 (7.3940)	mem 29650MB
[2024-12-24 22:06:25 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4400/11317]	eta 0:41:08 lr 0.000014838	time 0.3427 (0.3569)	dist_loss 0.0544 (0.0366)	image_text_loss 3.8208 (3.8725)	pose_text_loss 2.5119 (3.1543)	tot_loss 6.8767 (7.3923)	mem 29650MB
[2024-12-24 22:06:42 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4450/11317]	eta 0:40:51 lr 0.000014695	time 0.3541 (0.3569)	dist_loss 0.0348 (0.0367)	image_text_loss 3.8787 (3.8724)	pose_text_loss 3.3278 (3.1511)	tot_loss 7.5546 (7.3901)	mem 29650MB
[2024-12-24 22:07:00 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4500/11317]	eta 0:40:33 lr 0.000014552	time 0.4486 (0.3570)	dist_loss 0.0226 (0.0367)	image_text_loss 3.8757 (3.8724)	pose_text_loss 3.2813 (3.1486)	tot_loss 7.3825 (7.3884)	mem 29650MB
[2024-12-24 22:07:18 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4550/11317]	eta 0:40:15 lr 0.000014408	time 0.3552 (0.3569)	dist_loss 0.0353 (0.0368)	image_text_loss 3.8656 (3.8724)	pose_text_loss 2.8375 (3.1463)	tot_loss 7.0561 (7.3867)	mem 29650MB
[2024-12-24 22:07:36 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4600/11317]	eta 0:39:57 lr 0.000014264	time 0.3738 (0.3569)	dist_loss 0.0413 (0.0369)	image_text_loss 3.8736 (3.8724)	pose_text_loss 2.7970 (3.1432)	tot_loss 7.0832 (7.3845)	mem 29650MB
[2024-12-24 22:07:54 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4650/11317]	eta 0:39:39 lr 0.000014119	time 0.3458 (0.3569)	dist_loss 0.0455 (0.0370)	image_text_loss 3.8673 (3.8723)	pose_text_loss 2.6890 (3.1403)	tot_loss 7.0116 (7.3823)	mem 29650MB
[2024-12-24 22:08:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4700/11317]	eta 0:39:21 lr 0.000013974	time 0.3575 (0.3569)	dist_loss 0.0428 (0.0370)	image_text_loss 3.8713 (3.8723)	pose_text_loss 2.7153 (3.1377)	tot_loss 7.0149 (7.3803)	mem 29650MB
[2024-12-24 22:08:29 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4750/11317]	eta 0:39:03 lr 0.000013827	time 0.3596 (0.3568)	dist_loss 0.0761 (0.0371)	image_text_loss 3.8763 (3.8722)	pose_text_loss 2.3016 (3.1359)	tot_loss 6.9390 (7.3791)	mem 29650MB
[2024-12-24 22:08:47 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4800/11317]	eta 0:38:45 lr 0.000013681	time 0.3484 (0.3569)	dist_loss 0.0416 (0.0372)	image_text_loss 3.8986 (3.8722)	pose_text_loss 2.9078 (3.1339)	tot_loss 7.2225 (7.3778)	mem 29650MB
[2024-12-24 22:09:05 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4850/11317]	eta 0:38:27 lr 0.000013534	time 0.3535 (0.3569)	dist_loss 0.0309 (0.0373)	image_text_loss 3.8673 (3.8722)	pose_text_loss 3.4915 (3.1310)	tot_loss 7.6678 (7.3757)	mem 29650MB
[2024-12-24 22:09:22 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4900/11317]	eta 0:38:09 lr 0.000013386	time 0.3548 (0.3568)	dist_loss 0.0559 (0.0373)	image_text_loss 3.8701 (3.8722)	pose_text_loss 2.5607 (3.1293)	tot_loss 6.9899 (7.3745)	mem 29650MB
[2024-12-24 22:09:40 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4950/11317]	eta 0:37:51 lr 0.000013238	time 0.3563 (0.3568)	dist_loss 0.0431 (0.0374)	image_text_loss 3.8603 (3.8722)	pose_text_loss 2.7612 (3.1264)	tot_loss 7.0522 (7.3725)	mem 29650MB
[2024-12-24 22:09:58 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5000/11317]	eta 0:37:34 lr 0.000013090	time 0.3593 (0.3568)	dist_loss 0.0389 (0.0375)	image_text_loss 3.8684 (3.8723)	pose_text_loss 3.6026 (3.1236)	tot_loss 7.8595 (7.3707)	mem 29650MB
[2024-12-24 22:10:16 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5050/11317]	eta 0:37:16 lr 0.000012941	time 0.3572 (0.3568)	dist_loss 0.0510 (0.0376)	image_text_loss 3.8685 (3.8723)	pose_text_loss 2.6310 (3.1216)	tot_loss 7.0090 (7.3695)	mem 29650MB
[2024-12-24 22:10:34 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5100/11317]	eta 0:36:58 lr 0.000012792	time 0.3505 (0.3569)	dist_loss 0.0353 (0.0376)	image_text_loss 3.8958 (3.8723)	pose_text_loss 3.3907 (3.1199)	tot_loss 7.6398 (7.3682)	mem 29650MB
[2024-12-24 22:10:52 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5150/11317]	eta 0:36:40 lr 0.000012642	time 0.3590 (0.3569)	dist_loss 0.0149 (0.0377)	image_text_loss 3.8718 (3.8723)	pose_text_loss 3.7568 (3.1176)	tot_loss 7.7775 (7.3666)	mem 29650MB
[2024-12-24 22:11:10 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5200/11317]	eta 0:36:22 lr 0.000012492	time 0.3598 (0.3568)	dist_loss 0.0649 (0.0377)	image_text_loss 3.8707 (3.8723)	pose_text_loss 2.4204 (3.1158)	tot_loss 6.9397 (7.3652)	mem 29650MB
[2024-12-24 22:11:28 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5250/11317]	eta 0:36:05 lr 0.000012342	time 0.3466 (0.3569)	dist_loss 0.0323 (0.0378)	image_text_loss 3.8754 (3.8723)	pose_text_loss 3.6776 (3.1133)	tot_loss 7.8756 (7.3637)	mem 29650MB
[2024-12-24 22:11:46 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5300/11317]	eta 0:35:47 lr 0.000012192	time 0.3575 (0.3569)	dist_loss 0.0575 (0.0379)	image_text_loss 3.8716 (3.8723)	pose_text_loss 2.4912 (3.1113)	tot_loss 6.9373 (7.3622)	mem 29650MB
[2024-12-24 22:12:03 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5350/11317]	eta 0:35:29 lr 0.000012041	time 0.3594 (0.3569)	dist_loss 0.0589 (0.0379)	image_text_loss 3.8687 (3.8722)	pose_text_loss 2.5078 (3.1087)	tot_loss 6.9657 (7.3605)	mem 29650MB
[2024-12-24 22:12:22 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5400/11317]	eta 0:35:12 lr 0.000011891	time 0.3595 (0.3569)	dist_loss 0.0241 (0.0380)	image_text_loss 3.8600 (3.8722)	pose_text_loss 3.0817 (3.1069)	tot_loss 7.1826 (7.3591)	mem 29650MB
[2024-12-24 22:12:39 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5450/11317]	eta 0:34:54 lr 0.000011740	time 0.3562 (0.3569)	dist_loss 0.0605 (0.0380)	image_text_loss 3.8303 (3.8722)	pose_text_loss 2.4870 (3.1047)	tot_loss 6.9220 (7.3574)	mem 29650MB
[2024-12-24 22:12:57 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5500/11317]	eta 0:34:36 lr 0.000011589	time 0.3523 (0.3569)	dist_loss 0.0154 (0.0381)	image_text_loss 3.8790 (3.8722)	pose_text_loss 3.4383 (3.1024)	tot_loss 7.4714 (7.3558)	mem 29650MB
[2024-12-24 22:13:15 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5550/11317]	eta 0:34:18 lr 0.000011438	time 0.3501 (0.3570)	dist_loss 0.0468 (0.0382)	image_text_loss 3.8865 (3.8722)	pose_text_loss 2.7229 (3.1003)	tot_loss 7.0778 (7.3543)	mem 29650MB
[2024-12-24 22:13:33 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5600/11317]	eta 0:34:00 lr 0.000011287	time 0.3584 (0.3569)	dist_loss 0.0643 (0.0383)	image_text_loss 3.8723 (3.8721)	pose_text_loss 2.4314 (3.0981)	tot_loss 6.9466 (7.3528)	mem 29650MB
[2024-12-24 22:13:51 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5650/11317]	eta 0:33:42 lr 0.000011136	time 0.3466 (0.3569)	dist_loss 0.0599 (0.0383)	image_text_loss 3.8800 (3.8721)	pose_text_loss 2.5349 (3.0966)	tot_loss 7.0143 (7.3517)	mem 29650MB
[2024-12-24 22:14:09 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5700/11317]	eta 0:33:24 lr 0.000010985	time 0.3545 (0.3569)	dist_loss 0.0742 (0.0384)	image_text_loss 3.8658 (3.8721)	pose_text_loss 2.2895 (3.0945)	tot_loss 6.8974 (7.3503)	mem 29650MB
[2024-12-24 22:14:26 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5750/11317]	eta 0:33:07 lr 0.000010833	time 0.3594 (0.3569)	dist_loss 0.0507 (0.0384)	image_text_loss 3.8622 (3.8721)	pose_text_loss 2.5892 (3.0925)	tot_loss 6.9581 (7.3489)	mem 29650MB
[2024-12-24 22:14:44 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5800/11317]	eta 0:32:49 lr 0.000010682	time 0.3526 (0.3569)	dist_loss 0.0509 (0.0384)	image_text_loss 3.8716 (3.8721)	pose_text_loss 2.6585 (3.0918)	tot_loss 7.0390 (7.3483)	mem 29650MB
[2024-12-24 22:15:02 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5850/11317]	eta 0:32:31 lr 0.000010531	time 0.3648 (0.3569)	dist_loss 0.0393 (0.0385)	image_text_loss 3.8745 (3.8721)	pose_text_loss 3.1518 (3.0907)	tot_loss 7.4198 (7.3475)	mem 29650MB
[2024-12-24 22:15:20 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5900/11317]	eta 0:32:13 lr 0.000010380	time 0.3673 (0.3569)	dist_loss 0.0481 (0.0385)	image_text_loss 3.8768 (3.8720)	pose_text_loss 2.8044 (3.0894)	tot_loss 7.1625 (7.3464)	mem 29650MB
[2024-12-24 22:15:38 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5950/11317]	eta 0:31:55 lr 0.000010230	time 0.3642 (0.3569)	dist_loss 0.0314 (0.0386)	image_text_loss 3.8713 (3.8720)	pose_text_loss 3.4149 (3.0871)	tot_loss 7.5998 (7.3449)	mem 29650MB
[2024-12-24 22:15:56 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6000/11317]	eta 0:31:37 lr 0.000010079	time 0.3402 (0.3570)	dist_loss 0.0302 (0.0386)	image_text_loss 3.8718 (3.8720)	pose_text_loss 3.1172 (3.0855)	tot_loss 7.2913 (7.3437)	mem 29650MB
[2024-12-24 22:16:14 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6050/11317]	eta 0:31:20 lr 0.000009929	time 0.3576 (0.3569)	dist_loss 0.0761 (0.0387)	image_text_loss 3.8776 (3.8720)	pose_text_loss 2.3029 (3.0835)	tot_loss 6.9412 (7.3423)	mem 29650MB
[2024-12-24 22:16:31 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6100/11317]	eta 0:31:02 lr 0.000009779	time 0.3516 (0.3569)	dist_loss 0.0211 (0.0388)	image_text_loss 3.8523 (3.8720)	pose_text_loss 3.2722 (3.0811)	tot_loss 7.3351 (7.3407)	mem 29650MB
[2024-12-24 22:16:49 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6150/11317]	eta 0:30:44 lr 0.000009629	time 0.3626 (0.3570)	dist_loss 0.0334 (0.0388)	image_text_loss 3.8702 (3.8720)	pose_text_loss 3.1504 (3.0799)	tot_loss 7.3550 (7.3398)	mem 29650MB
[2024-12-24 22:17:07 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6200/11317]	eta 0:30:26 lr 0.000009479	time 0.3495 (0.3569)	dist_loss 0.0333 (0.0388)	image_text_loss 3.8644 (3.8719)	pose_text_loss 3.1770 (3.0784)	tot_loss 7.3746 (7.3387)	mem 29650MB
[2024-12-24 22:17:25 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6250/11317]	eta 0:30:08 lr 0.000009330	time 0.3542 (0.3569)	dist_loss 0.0311 (0.0389)	image_text_loss 3.8727 (3.8720)	pose_text_loss 3.2761 (3.0770)	tot_loss 7.4597 (7.3377)	mem 29650MB
[2024-12-24 22:17:43 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6300/11317]	eta 0:29:50 lr 0.000009181	time 0.3532 (0.3570)	dist_loss 0.0137 (0.0389)	image_text_loss 3.8720 (3.8719)	pose_text_loss 3.7865 (3.0755)	tot_loss 7.7950 (7.3367)	mem 29650MB
[2024-12-24 22:18:01 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6350/11317]	eta 0:29:33 lr 0.000009032	time 0.3560 (0.3570)	dist_loss 0.0498 (0.0390)	image_text_loss 3.8664 (3.8719)	pose_text_loss 2.7214 (3.0737)	tot_loss 7.0855 (7.3354)	mem 29650MB
[2024-12-24 22:18:18 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6400/11317]	eta 0:29:15 lr 0.000008884	time 0.3562 (0.3569)	dist_loss 0.0636 (0.0391)	image_text_loss 3.8751 (3.8719)	pose_text_loss 2.4335 (3.0712)	tot_loss 6.9447 (7.3338)	mem 29650MB
[2024-12-24 22:18:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6450/11317]	eta 0:28:57 lr 0.000008736	time 0.3596 (0.3570)	dist_loss 0.0426 (0.0391)	image_text_loss 3.8648 (3.8719)	pose_text_loss 2.7712 (3.0689)	tot_loss 7.0617 (7.3322)	mem 29650MB
[2024-12-24 22:18:54 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6500/11317]	eta 0:28:39 lr 0.000008589	time 0.3615 (0.3570)	dist_loss 0.0420 (0.0391)	image_text_loss 3.8523 (3.8719)	pose_text_loss 2.7565 (3.0684)	tot_loss 7.0293 (7.3317)	mem 29650MB
[2024-12-24 22:19:12 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6550/11317]	eta 0:28:21 lr 0.000008442	time 0.3532 (0.3570)	dist_loss 0.0799 (0.0392)	image_text_loss 3.8923 (3.8718)	pose_text_loss 2.2727 (3.0676)	tot_loss 6.9643 (7.3313)	mem 29650MB
[2024-12-24 22:19:30 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6600/11317]	eta 0:28:04 lr 0.000008296	time 0.3539 (0.3570)	dist_loss 0.0239 (0.0392)	image_text_loss 3.8556 (3.8718)	pose_text_loss 3.3057 (3.0657)	tot_loss 7.4000 (7.3299)	mem 29650MB
[2024-12-24 22:19:48 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6650/11317]	eta 0:27:46 lr 0.000008150	time 0.3582 (0.3570)	dist_loss 0.0210 (0.0393)	image_text_loss 3.8947 (3.8718)	pose_text_loss 3.2071 (3.0644)	tot_loss 7.3115 (7.3289)	mem 29650MB
[2024-12-24 22:20:06 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6700/11317]	eta 0:27:28 lr 0.000008005	time 0.3633 (0.3570)	dist_loss 0.0815 (0.0393)	image_text_loss 3.8583 (3.8718)	pose_text_loss 2.2134 (3.0626)	tot_loss 6.8867 (7.3276)	mem 29650MB
[2024-12-24 22:20:23 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6750/11317]	eta 0:27:10 lr 0.000007861	time 0.3417 (0.3570)	dist_loss 0.0673 (0.0394)	image_text_loss 3.8849 (3.8719)	pose_text_loss 2.4126 (3.0611)	tot_loss 6.9708 (7.3267)	mem 29650MB
[2024-12-24 22:20:41 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6800/11317]	eta 0:26:52 lr 0.000007717	time 0.3471 (0.3569)	dist_loss 0.0501 (0.0394)	image_text_loss 3.8627 (3.8719)	pose_text_loss 2.5779 (3.0597)	tot_loss 6.9413 (7.3257)	mem 29650MB
[2024-12-24 22:20:59 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6850/11317]	eta 0:26:34 lr 0.000007573	time 0.3586 (0.3569)	dist_loss 0.0228 (0.0394)	image_text_loss 3.8751 (3.8718)	pose_text_loss 3.1332 (3.0585)	tot_loss 7.2365 (7.3247)	mem 29650MB
[2024-12-24 22:21:17 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6900/11317]	eta 0:26:16 lr 0.000007431	time 0.3498 (0.3569)	dist_loss 0.0410 (0.0395)	image_text_loss 3.8726 (3.8718)	pose_text_loss 3.2501 (3.0568)	tot_loss 7.5331 (7.3236)	mem 29650MB
[2024-12-24 22:21:35 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6950/11317]	eta 0:25:58 lr 0.000007289	time 0.3565 (0.3569)	dist_loss 0.0445 (0.0395)	image_text_loss 3.8724 (3.8718)	pose_text_loss 2.7687 (3.0551)	tot_loss 7.0862 (7.3224)	mem 29650MB
[2024-12-24 22:21:52 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7000/11317]	eta 0:25:40 lr 0.000007148	time 0.3650 (0.3569)	dist_loss 0.0616 (0.0396)	image_text_loss 3.8693 (3.8718)	pose_text_loss 2.4520 (3.0535)	tot_loss 6.9373 (7.3212)	mem 29650MB
[2024-12-24 22:22:10 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7050/11317]	eta 0:25:22 lr 0.000007007	time 0.3589 (0.3569)	dist_loss 0.0431 (0.0397)	image_text_loss 3.8697 (3.8718)	pose_text_loss 2.8080 (3.0514)	tot_loss 7.1083 (7.3198)	mem 29650MB
[2024-12-24 22:22:27 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7100/11317]	eta 0:25:04 lr 0.000006868	time 0.3541 (0.3568)	dist_loss 0.0491 (0.0397)	image_text_loss 3.8784 (3.8718)	pose_text_loss 2.6345 (3.0504)	tot_loss 7.0034 (7.3190)	mem 29650MB
[2024-12-24 22:22:45 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7150/11317]	eta 0:24:46 lr 0.000006729	time 0.3524 (0.3568)	dist_loss 0.0571 (0.0397)	image_text_loss 3.8728 (3.8718)	pose_text_loss 2.5433 (3.0491)	tot_loss 6.9874 (7.3181)	mem 29650MB
[2024-12-24 22:23:03 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7200/11317]	eta 0:24:28 lr 0.000006591	time 0.3457 (0.3568)	dist_loss 0.0609 (0.0398)	image_text_loss 3.8699 (3.8718)	pose_text_loss 2.4700 (3.0482)	tot_loss 6.9489 (7.3174)	mem 29650MB
[2024-12-24 22:23:21 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7250/11317]	eta 0:24:11 lr 0.000006454	time 0.3535 (0.3568)	dist_loss 0.0754 (0.0398)	image_text_loss 3.8513 (3.8717)	pose_text_loss 2.2645 (3.0460)	tot_loss 6.8699 (7.3160)	mem 29650MB
[2024-12-24 22:23:38 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7300/11317]	eta 0:23:53 lr 0.000006318	time 0.3645 (0.3568)	dist_loss 0.0168 (0.0399)	image_text_loss 3.8624 (3.8717)	pose_text_loss 3.9617 (3.0448)	tot_loss 7.9921 (7.3152)	mem 29650MB
[2024-12-24 22:23:57 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7350/11317]	eta 0:23:35 lr 0.000006182	time 0.3498 (0.3568)	dist_loss 0.0315 (0.0399)	image_text_loss 3.8658 (3.8717)	pose_text_loss 2.9572 (3.0436)	tot_loss 7.1385 (7.3143)	mem 29650MB
[2024-12-24 22:24:15 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7400/11317]	eta 0:23:17 lr 0.000006048	time 0.3587 (0.3568)	dist_loss 0.0941 (0.0399)	image_text_loss 3.8710 (3.8717)	pose_text_loss 2.1103 (3.0425)	tot_loss 6.9224 (7.3137)	mem 29650MB
[2024-12-24 22:24:32 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7450/11317]	eta 0:22:59 lr 0.000005915	time 0.3495 (0.3568)	dist_loss 0.0263 (0.0400)	image_text_loss 3.8796 (3.8717)	pose_text_loss 3.1143 (3.0414)	tot_loss 7.2571 (7.3128)	mem 29650MB
[2024-12-24 22:24:51 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7500/11317]	eta 0:22:42 lr 0.000005782	time 0.3635 (0.3569)	dist_loss 0.0698 (0.0400)	image_text_loss 3.8809 (3.8717)	pose_text_loss 2.3620 (3.0395)	tot_loss 6.9414 (7.3115)	mem 29650MB
[2024-12-24 22:25:08 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7550/11317]	eta 0:22:24 lr 0.000005651	time 0.3503 (0.3569)	dist_loss 0.0521 (0.0401)	image_text_loss 3.8322 (3.8717)	pose_text_loss 2.5901 (3.0384)	tot_loss 6.9429 (7.3107)	mem 29650MB
[2024-12-24 22:25:26 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7600/11317]	eta 0:22:06 lr 0.000005521	time 0.3538 (0.3569)	dist_loss 0.0655 (0.0401)	image_text_loss 3.8568 (3.8717)	pose_text_loss 2.4111 (3.0374)	tot_loss 6.9225 (7.3101)	mem 29650MB
[2024-12-24 22:25:44 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7650/11317]	eta 0:21:48 lr 0.000005392	time 0.3656 (0.3569)	dist_loss 0.0480 (0.0402)	image_text_loss 3.8711 (3.8717)	pose_text_loss 2.7884 (3.0356)	tot_loss 7.1391 (7.3090)	mem 29650MB
[2024-12-24 22:26:02 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7700/11317]	eta 0:21:30 lr 0.000005264	time 0.3445 (0.3569)	dist_loss 0.0153 (0.0402)	image_text_loss 3.8667 (3.8717)	pose_text_loss 3.5285 (3.0341)	tot_loss 7.5487 (7.3080)	mem 29650MB
[2024-12-24 22:26:20 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7750/11317]	eta 0:21:12 lr 0.000005137	time 0.3525 (0.3569)	dist_loss 0.0571 (0.0403)	image_text_loss 3.8556 (3.8717)	pose_text_loss 2.4813 (3.0319)	tot_loss 6.9074 (7.3066)	mem 29650MB
[2024-12-24 22:26:38 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7800/11317]	eta 0:20:55 lr 0.000005011	time 0.3530 (0.3569)	dist_loss 0.0286 (0.0403)	image_text_loss 3.8712 (3.8717)	pose_text_loss 3.3030 (3.0311)	tot_loss 7.4604 (7.3062)	mem 29650MB
[2024-12-24 22:26:55 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7850/11317]	eta 0:20:37 lr 0.000004886	time 0.3564 (0.3569)	dist_loss 0.0435 (0.0404)	image_text_loss 3.8664 (3.8717)	pose_text_loss 2.7277 (3.0295)	tot_loss 7.0289 (7.3052)	mem 29650MB
[2024-12-24 22:27:13 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7900/11317]	eta 0:20:19 lr 0.000004763	time 0.3531 (0.3569)	dist_loss 0.0756 (0.0405)	image_text_loss 3.8865 (3.8717)	pose_text_loss 2.2882 (3.0277)	tot_loss 6.9309 (7.3040)	mem 29650MB
[2024-12-24 22:27:31 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7950/11317]	eta 0:20:01 lr 0.000004640	time 0.3551 (0.3569)	dist_loss 0.0760 (0.0405)	image_text_loss 3.8599 (3.8716)	pose_text_loss 2.2650 (3.0262)	tot_loss 6.8847 (7.3029)	mem 29650MB
[2024-12-24 22:27:49 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8000/11317]	eta 0:19:43 lr 0.000004520	time 0.3626 (0.3569)	dist_loss 0.0323 (0.0406)	image_text_loss 3.8895 (3.8716)	pose_text_loss 3.0248 (3.0246)	tot_loss 7.2375 (7.3019)	mem 29650MB
[2024-12-24 22:28:07 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8050/11317]	eta 0:19:25 lr 0.000004400	time 0.3466 (0.3569)	dist_loss 0.0507 (0.0406)	image_text_loss 3.8863 (3.8716)	pose_text_loss 2.7654 (3.0231)	tot_loss 7.1588 (7.3008)	mem 29650MB
[2024-12-24 22:28:25 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8100/11317]	eta 0:19:08 lr 0.000004281	time 0.3545 (0.3569)	dist_loss 0.0179 (0.0407)	image_text_loss 3.8743 (3.8716)	pose_text_loss 3.4528 (3.0214)	tot_loss 7.5059 (7.2996)	mem 29650MB
[2024-12-24 22:28:43 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8150/11317]	eta 0:18:50 lr 0.000004164	time 0.3726 (0.3569)	dist_loss 0.0571 (0.0407)	image_text_loss 3.8723 (3.8716)	pose_text_loss 2.6182 (3.0202)	tot_loss 7.0617 (7.2987)	mem 29650MB
[2024-12-24 22:29:01 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8200/11317]	eta 0:18:32 lr 0.000004049	time 0.3566 (0.3569)	dist_loss 0.0347 (0.0407)	image_text_loss 3.8689 (3.8716)	pose_text_loss 2.9008 (3.0196)	tot_loss 7.1172 (7.2982)	mem 29650MB
[2024-12-24 22:29:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8250/11317]	eta 0:18:14 lr 0.000003934	time 0.3598 (0.3569)	dist_loss 0.0281 (0.0407)	image_text_loss 3.8257 (3.8716)	pose_text_loss 2.9897 (3.0184)	tot_loss 7.0962 (7.2974)	mem 29650MB
[2024-12-24 22:29:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8300/11317]	eta 0:17:56 lr 0.000003821	time 0.3506 (0.3569)	dist_loss 0.0487 (0.0408)	image_text_loss 3.8574 (3.8715)	pose_text_loss 2.6692 (3.0166)	tot_loss 7.0136 (7.2962)	mem 29650MB
[2024-12-24 22:29:54 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8350/11317]	eta 0:17:38 lr 0.000003710	time 0.3634 (0.3569)	dist_loss 0.0730 (0.0409)	image_text_loss 3.8893 (3.8715)	pose_text_loss 2.3191 (3.0153)	tot_loss 6.9386 (7.2954)	mem 29650MB
[2024-12-24 22:30:12 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8400/11317]	eta 0:17:21 lr 0.000003599	time 0.3530 (0.3569)	dist_loss 0.0629 (0.0409)	image_text_loss 3.8749 (3.8716)	pose_text_loss 2.4319 (3.0147)	tot_loss 6.9358 (7.2949)	mem 29650MB
[2024-12-24 22:30:30 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8450/11317]	eta 0:17:03 lr 0.000003491	time 0.3445 (0.3570)	dist_loss 0.0211 (0.0409)	image_text_loss 3.8697 (3.8715)	pose_text_loss 3.5063 (3.0135)	tot_loss 7.5873 (7.2941)	mem 29650MB
[2024-12-24 22:30:48 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8500/11317]	eta 0:16:45 lr 0.000003383	time 0.3543 (0.3569)	dist_loss 0.0794 (0.0410)	image_text_loss 3.8682 (3.8715)	pose_text_loss 2.2316 (3.0121)	tot_loss 6.8937 (7.2931)	mem 29650MB
[2024-12-24 22:31:06 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8550/11317]	eta 0:16:27 lr 0.000003278	time 0.3507 (0.3570)	dist_loss 0.0258 (0.0410)	image_text_loss 3.8782 (3.8715)	pose_text_loss 3.4854 (3.0112)	tot_loss 7.6220 (7.2926)	mem 29650MB
[2024-12-24 22:31:24 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8600/11317]	eta 0:16:09 lr 0.000003173	time 0.3581 (0.3570)	dist_loss 0.0398 (0.0410)	image_text_loss 3.8604 (3.8715)	pose_text_loss 2.7289 (3.0097)	tot_loss 6.9878 (7.2917)	mem 29650MB
[2024-12-24 22:31:42 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8650/11317]	eta 0:15:51 lr 0.000003071	time 0.3464 (0.3570)	dist_loss 0.0562 (0.0411)	image_text_loss 3.8640 (3.8715)	pose_text_loss 2.5176 (3.0080)	tot_loss 6.9440 (7.2906)	mem 29650MB
[2024-12-24 22:32:00 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8700/11317]	eta 0:15:34 lr 0.000002970	time 0.3582 (0.3570)	dist_loss 0.0554 (0.0412)	image_text_loss 3.8556 (3.8715)	pose_text_loss 2.5406 (3.0058)	tot_loss 6.9503 (7.2893)	mem 29650MB
[2024-12-24 22:32:17 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8750/11317]	eta 0:15:16 lr 0.000002870	time 0.3532 (0.3570)	dist_loss 0.0289 (0.0412)	image_text_loss 3.8608 (3.8715)	pose_text_loss 3.2494 (3.0054)	tot_loss 7.3994 (7.2889)	mem 29650MB
[2024-12-24 22:32:35 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8800/11317]	eta 0:14:58 lr 0.000002772	time 0.3446 (0.3569)	dist_loss 0.0409 (0.0412)	image_text_loss 3.8636 (3.8716)	pose_text_loss 2.8368 (3.0042)	tot_loss 7.1098 (7.2881)	mem 29650MB
[2024-12-24 22:32:53 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8850/11317]	eta 0:14:40 lr 0.000002675	time 0.3514 (0.3569)	dist_loss 0.0707 (0.0412)	image_text_loss 3.8891 (3.8716)	pose_text_loss 2.4154 (3.0035)	tot_loss 7.0116 (7.2875)	mem 29650MB
[2024-12-24 22:33:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8900/11317]	eta 0:14:22 lr 0.000002581	time 0.3569 (0.3569)	dist_loss 0.0671 (0.0413)	image_text_loss 3.8799 (3.8716)	pose_text_loss 2.3750 (3.0022)	tot_loss 6.9262 (7.2867)	mem 29650MB
[2024-12-24 22:33:29 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8950/11317]	eta 0:14:04 lr 0.000002488	time 0.3527 (0.3569)	dist_loss 0.0252 (0.0413)	image_text_loss 3.8915 (3.8715)	pose_text_loss 3.3883 (3.0015)	tot_loss 7.5318 (7.2861)	mem 29650MB
[2024-12-24 22:33:47 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9000/11317]	eta 0:13:47 lr 0.000002396	time 0.3481 (0.3569)	dist_loss 0.0450 (0.0414)	image_text_loss 3.9335 (3.8715)	pose_text_loss 2.8880 (3.0000)	tot_loss 7.2713 (7.2851)	mem 29650MB
[2024-12-24 22:34:04 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9050/11317]	eta 0:13:29 lr 0.000002306	time 0.3563 (0.3569)	dist_loss 0.0324 (0.0414)	image_text_loss 3.8636 (3.8715)	pose_text_loss 2.9304 (2.9988)	tot_loss 7.1179 (7.2843)	mem 29650MB
[2024-12-24 22:34:22 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9100/11317]	eta 0:13:11 lr 0.000002218	time 0.3503 (0.3569)	dist_loss 0.0442 (0.0414)	image_text_loss 3.8693 (3.8715)	pose_text_loss 2.7860 (2.9979)	tot_loss 7.0973 (7.2835)	mem 29650MB
[2024-12-24 22:34:40 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9150/11317]	eta 0:12:53 lr 0.000002132	time 0.3570 (0.3569)	dist_loss 0.0254 (0.0414)	image_text_loss 3.8668 (3.8715)	pose_text_loss 3.3791 (2.9970)	tot_loss 7.4999 (7.2829)	mem 29650MB
[2024-12-24 22:34:58 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9200/11317]	eta 0:12:35 lr 0.000002047	time 0.3628 (0.3569)	dist_loss 0.0356 (0.0414)	image_text_loss 3.8582 (3.8715)	pose_text_loss 3.0584 (2.9964)	tot_loss 7.2725 (7.2823)	mem 29650MB
[2024-12-24 22:35:16 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9250/11317]	eta 0:12:17 lr 0.000001964	time 0.3464 (0.3569)	dist_loss 0.0380 (0.0415)	image_text_loss 3.9127 (3.8715)	pose_text_loss 2.9599 (2.9950)	tot_loss 7.2526 (7.2813)	mem 29650MB
[2024-12-24 22:35:33 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9300/11317]	eta 0:11:59 lr 0.000001883	time 0.3361 (0.3569)	dist_loss 0.0478 (0.0415)	image_text_loss 3.8687 (3.8715)	pose_text_loss 2.6925 (2.9939)	tot_loss 7.0394 (7.2807)	mem 29650MB
[2024-12-24 22:35:51 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9350/11317]	eta 0:11:42 lr 0.000001804	time 0.3525 (0.3569)	dist_loss 0.0341 (0.0416)	image_text_loss 3.8849 (3.8715)	pose_text_loss 3.0762 (2.9927)	tot_loss 7.3023 (7.2798)	mem 29650MB
[2024-12-24 22:36:09 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9400/11317]	eta 0:11:24 lr 0.000001726	time 0.3511 (0.3569)	dist_loss 0.0378 (0.0416)	image_text_loss 3.8702 (3.8715)	pose_text_loss 3.0029 (2.9921)	tot_loss 7.2506 (7.2795)	mem 29650MB
[2024-12-24 22:36:27 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9450/11317]	eta 0:11:06 lr 0.000001650	time 0.3458 (0.3569)	dist_loss 0.0324 (0.0416)	image_text_loss 3.8626 (3.8715)	pose_text_loss 3.1708 (2.9915)	tot_loss 7.3571 (7.2789)	mem 29650MB
[2024-12-24 22:36:44 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9500/11317]	eta 0:10:48 lr 0.000001576	time 0.3504 (0.3569)	dist_loss 0.0685 (0.0416)	image_text_loss 3.8605 (3.8715)	pose_text_loss 2.3433 (2.9905)	tot_loss 6.8885 (7.2782)	mem 29650MB
[2024-12-24 22:37:02 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9550/11317]	eta 0:10:30 lr 0.000001504	time 0.3662 (0.3569)	dist_loss 0.0586 (0.0417)	image_text_loss 3.8705 (3.8715)	pose_text_loss 2.4959 (2.9892)	tot_loss 6.9529 (7.2773)	mem 29650MB
[2024-12-24 22:37:20 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9600/11317]	eta 0:10:12 lr 0.000001434	time 0.3672 (0.3569)	dist_loss 0.0220 (0.0417)	image_text_loss 3.8646 (3.8714)	pose_text_loss 3.3033 (2.9882)	tot_loss 7.3881 (7.2765)	mem 29650MB
[2024-12-24 22:37:38 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9650/11317]	eta 0:09:54 lr 0.000001365	time 0.3524 (0.3569)	dist_loss 0.0146 (0.0417)	image_text_loss 3.8663 (3.8714)	pose_text_loss 3.4628 (2.9874)	tot_loss 7.4754 (7.2759)	mem 29650MB
[2024-12-24 22:37:56 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9700/11317]	eta 0:09:37 lr 0.000001299	time 0.3509 (0.3569)	dist_loss 0.0209 (0.0417)	image_text_loss 3.8634 (3.8714)	pose_text_loss 3.5283 (2.9867)	tot_loss 7.6007 (7.2754)	mem 29650MB
[2024-12-24 22:38:14 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9750/11317]	eta 0:09:19 lr 0.000001234	time 0.3582 (0.3569)	dist_loss 0.0351 (0.0418)	image_text_loss 3.8652 (3.8714)	pose_text_loss 2.8527 (2.9857)	tot_loss 7.0693 (7.2747)	mem 29650MB
[2024-12-24 22:38:31 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9800/11317]	eta 0:09:01 lr 0.000001171	time 0.3540 (0.3569)	dist_loss 0.0875 (0.0418)	image_text_loss 3.8537 (3.8714)	pose_text_loss 2.1479 (2.9846)	tot_loss 6.8767 (7.2739)	mem 29650MB
[2024-12-24 22:38:49 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9850/11317]	eta 0:08:43 lr 0.000001111	time 0.3571 (0.3569)	dist_loss 0.0497 (0.0418)	image_text_loss 3.8734 (3.8714)	pose_text_loss 2.6155 (2.9842)	tot_loss 6.9857 (7.2736)	mem 29650MB
[2024-12-24 22:39:07 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9900/11317]	eta 0:08:25 lr 0.000001052	time 0.3715 (0.3569)	dist_loss 0.0603 (0.0418)	image_text_loss 3.8862 (3.8714)	pose_text_loss 2.4926 (2.9834)	tot_loss 6.9816 (7.2731)	mem 29650MB
[2024-12-24 22:39:25 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9950/11317]	eta 0:08:07 lr 0.000000995	time 0.3473 (0.3569)	dist_loss 0.0464 (0.0418)	image_text_loss 3.8704 (3.8714)	pose_text_loss 2.7627 (2.9830)	tot_loss 7.0970 (7.2728)	mem 29650MB
[2024-12-24 22:39:43 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10000/11317]	eta 0:07:50 lr 0.000000940	time 0.3544 (0.3569)	dist_loss 0.0599 (0.0419)	image_text_loss 3.8741 (3.8714)	pose_text_loss 2.5165 (2.9822)	tot_loss 6.9892 (7.2723)	mem 29650MB
[2024-12-24 22:40:01 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10050/11317]	eta 0:07:32 lr 0.000000887	time 0.3624 (0.3569)	dist_loss 0.0306 (0.0419)	image_text_loss 3.8707 (3.8714)	pose_text_loss 3.0507 (2.9810)	tot_loss 7.2273 (7.2715)	mem 29650MB
[2024-12-24 22:40:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10100/11317]	eta 0:07:14 lr 0.000000836	time 0.3494 (0.3569)	dist_loss 0.0366 (0.0419)	image_text_loss 3.8788 (3.8714)	pose_text_loss 2.8796 (2.9806)	tot_loss 7.1246 (7.2711)	mem 29650MB
[2024-12-24 22:40:36 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10150/11317]	eta 0:06:56 lr 0.000000786	time 0.3543 (0.3569)	dist_loss 0.0568 (0.0420)	image_text_loss 3.8710 (3.8713)	pose_text_loss 2.5721 (2.9795)	tot_loss 7.0109 (7.2704)	mem 29650MB
[2024-12-24 22:40:54 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10200/11317]	eta 0:06:38 lr 0.000000739	time 0.3609 (0.3569)	dist_loss 0.0361 (0.0420)	image_text_loss 3.8269 (3.8713)	pose_text_loss 2.7870 (2.9786)	tot_loss 6.9750 (7.2697)	mem 29650MB
[2024-12-24 22:41:12 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10250/11317]	eta 0:06:20 lr 0.000000694	time 0.3690 (0.3569)	dist_loss 0.0653 (0.0420)	image_text_loss 3.9019 (3.8713)	pose_text_loss 2.4285 (2.9775)	tot_loss 6.9836 (7.2689)	mem 29650MB
[2024-12-24 22:41:30 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10300/11317]	eta 0:06:02 lr 0.000000651	time 0.3624 (0.3569)	dist_loss 0.0819 (0.0420)	image_text_loss 3.8640 (3.8713)	pose_text_loss 2.2060 (2.9765)	tot_loss 6.8887 (7.2683)	mem 29650MB
[2024-12-24 22:41:48 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10350/11317]	eta 0:05:45 lr 0.000000610	time 0.3541 (0.3569)	dist_loss 0.0628 (0.0421)	image_text_loss 3.8786 (3.8713)	pose_text_loss 2.4538 (2.9758)	tot_loss 6.9605 (7.2678)	mem 29650MB
[2024-12-24 22:42:05 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10400/11317]	eta 0:05:27 lr 0.000000571	time 0.3642 (0.3569)	dist_loss 0.0202 (0.0421)	image_text_loss 3.8687 (3.8713)	pose_text_loss 3.4967 (2.9753)	tot_loss 7.5673 (7.2674)	mem 29650MB
[2024-12-24 22:42:23 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10450/11317]	eta 0:05:09 lr 0.000000534	time 0.3531 (0.3569)	dist_loss 0.0269 (0.0421)	image_text_loss 3.8690 (3.8713)	pose_text_loss 3.5060 (2.9742)	tot_loss 7.6438 (7.2667)	mem 29650MB
[2024-12-24 22:42:41 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10500/11317]	eta 0:04:51 lr 0.000000499	time 0.3544 (0.3569)	dist_loss 0.0174 (0.0421)	image_text_loss 3.8684 (3.8713)	pose_text_loss 3.6442 (2.9734)	tot_loss 7.6867 (7.2661)	mem 29650MB
[2024-12-24 22:42:59 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10550/11317]	eta 0:04:33 lr 0.000000466	time 0.3550 (0.3569)	dist_loss 0.0246 (0.0422)	image_text_loss 3.8593 (3.8713)	pose_text_loss 3.6590 (2.9722)	tot_loss 7.7646 (7.2653)	mem 29650MB
[2024-12-24 22:43:17 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10600/11317]	eta 0:04:15 lr 0.000000435	time 0.3580 (0.3569)	dist_loss 0.0235 (0.0422)	image_text_loss 3.8632 (3.8713)	pose_text_loss 3.2910 (2.9718)	tot_loss 7.3889 (7.2650)	mem 29650MB
[2024-12-24 22:43:35 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10650/11317]	eta 0:03:58 lr 0.000000406	time 0.3592 (0.3569)	dist_loss 0.0628 (0.0422)	image_text_loss 3.8696 (3.8712)	pose_text_loss 2.5634 (2.9709)	tot_loss 7.0614 (7.2643)	mem 29650MB
[2024-12-24 22:43:53 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10700/11317]	eta 0:03:40 lr 0.000000379	time 0.3548 (0.3569)	dist_loss 0.0180 (0.0422)	image_text_loss 3.8694 (3.8713)	pose_text_loss 3.4798 (2.9703)	tot_loss 7.5290 (7.2638)	mem 29650MB
[2024-12-24 22:44:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10750/11317]	eta 0:03:22 lr 0.000000355	time 0.3515 (0.3569)	dist_loss 0.0115 (0.0422)	image_text_loss 3.8703 (3.8712)	pose_text_loss 3.8557 (2.9700)	tot_loss 7.8411 (7.2635)	mem 29650MB
[2024-12-24 22:44:29 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10800/11317]	eta 0:03:04 lr 0.000000332	time 0.3556 (0.3569)	dist_loss 0.0357 (0.0422)	image_text_loss 3.8640 (3.8712)	pose_text_loss 3.3319 (2.9694)	tot_loss 7.5527 (7.2630)	mem 29650MB
[2024-12-24 22:44:47 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10850/11317]	eta 0:02:46 lr 0.000000311	time 0.3467 (0.3569)	dist_loss 0.0695 (0.0423)	image_text_loss 3.8610 (3.8712)	pose_text_loss 2.3166 (2.9686)	tot_loss 6.8728 (7.2623)	mem 29650MB
[2024-12-24 22:45:04 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10900/11317]	eta 0:02:28 lr 0.000000293	time 0.3519 (0.3569)	dist_loss 0.0753 (0.0423)	image_text_loss 3.8722 (3.8712)	pose_text_loss 2.2981 (2.9677)	tot_loss 6.9234 (7.2617)	mem 29650MB
[2024-12-24 22:45:22 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10950/11317]	eta 0:02:10 lr 0.000000276	time 0.3611 (0.3569)	dist_loss 0.0474 (0.0423)	image_text_loss 3.8654 (3.8712)	pose_text_loss 2.8083 (2.9667)	tot_loss 7.1480 (7.2610)	mem 29650MB
[2024-12-24 22:45:40 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11000/11317]	eta 0:01:53 lr 0.000000262	time 0.3533 (0.3569)	dist_loss 0.0477 (0.0423)	image_text_loss 3.8649 (3.8712)	pose_text_loss 2.7490 (2.9662)	tot_loss 7.0907 (7.2606)	mem 29650MB
[2024-12-24 22:45:58 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11050/11317]	eta 0:01:35 lr 0.000000250	time 0.4308 (0.3569)	dist_loss 0.0635 (0.0424)	image_text_loss 3.8640 (3.8712)	pose_text_loss 2.3986 (2.9652)	tot_loss 6.8975 (7.2599)	mem 29650MB
[2024-12-24 22:46:16 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11100/11317]	eta 0:01:17 lr 0.000000240	time 0.3592 (0.3570)	dist_loss 0.0261 (0.0424)	image_text_loss 3.8685 (3.8712)	pose_text_loss 3.1754 (2.9643)	tot_loss 7.3046 (7.2593)	mem 29650MB
[2024-12-24 22:46:34 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11150/11317]	eta 0:00:59 lr 0.000000232	time 0.3438 (0.3570)	dist_loss 0.0287 (0.0424)	image_text_loss 3.8713 (3.8712)	pose_text_loss 3.1312 (2.9631)	tot_loss 7.2895 (7.2584)	mem 29650MB
[2024-12-24 22:46:52 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11200/11317]	eta 0:00:41 lr 0.000000226	time 0.3560 (0.3570)	dist_loss 0.0787 (0.0425)	image_text_loss 3.8868 (3.8712)	pose_text_loss 2.2531 (2.9620)	tot_loss 6.9266 (7.2577)	mem 29650MB
[2024-12-24 22:47:10 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11250/11317]	eta 0:00:23 lr 0.000000222	time 0.3532 (0.3570)	dist_loss 0.0126 (0.0425)	image_text_loss 3.8667 (3.8712)	pose_text_loss 3.6165 (2.9613)	tot_loss 7.6089 (7.2571)	mem 29650MB
[2024-12-24 22:47:28 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11300/11317]	eta 0:00:06 lr 0.000000220	time 0.3475 (0.3569)	dist_loss 0.0318 (0.0425)	image_text_loss 3.8640 (3.8712)	pose_text_loss 3.4647 (2.9608)	tot_loss 7.6463 (7.2567)	mem 29650MB
[2024-12-24 22:47:33 ViT-B/16] (CL_main_v2.py 290): INFO EPOCH 0 training takes 1:07:19
[2024-12-24 22:47:33 ViT-B/16] (CL_main_v2.py 307): INFO 1 views inference
[2024-12-24 22:47:35 ViT-B/16] (CL_main_v2.py 379): INFO Test: [0/250]	Acc@1 for Image-Text: 0.000	mCA for Image-Text: 0.000	
[2024-12-24 22:47:35 ViT-B/16] (CL_main_v2.py 379): INFO Test: [0/250]	Acc@1 for Text-Pose: 50.000	mCA for Text-Pose: 2.083	
[2024-12-24 22:47:35 ViT-B/16] (CL_main_v2.py 379): INFO Test: [0/250]	Acc@1 for Image-Text-Pose: 50.000	mCA for Image-Text-Pose: 2.083	
[2024-12-24 22:47:42 ViT-B/16] (CL_main_v2.py 379): INFO Test: [50/250]	Acc@1 for Image-Text: 0.980	mCA for Image-Text: 2.083	
[2024-12-24 22:47:42 ViT-B/16] (CL_main_v2.py 379): INFO Test: [50/250]	Acc@1 for Text-Pose: 63.725	mCA for Text-Pose: 54.306	
[2024-12-24 22:47:42 ViT-B/16] (CL_main_v2.py 379): INFO Test: [50/250]	Acc@1 for Image-Text-Pose: 63.725	mCA for Image-Text-Pose: 54.306	
[2024-12-24 22:47:49 ViT-B/16] (CL_main_v2.py 379): INFO Test: [100/250]	Acc@1 for Image-Text: 1.980	mCA for Image-Text: 1.667	
[2024-12-24 22:47:49 ViT-B/16] (CL_main_v2.py 379): INFO Test: [100/250]	Acc@1 for Text-Pose: 63.861	mCA for Text-Pose: 65.129	
[2024-12-24 22:47:49 ViT-B/16] (CL_main_v2.py 379): INFO Test: [100/250]	Acc@1 for Image-Text-Pose: 63.861	mCA for Image-Text-Pose: 65.129	
[2024-12-24 22:47:56 ViT-B/16] (CL_main_v2.py 379): INFO Test: [150/250]	Acc@1 for Image-Text: 2.318	mCA for Image-Text: 2.202	
[2024-12-24 22:47:56 ViT-B/16] (CL_main_v2.py 379): INFO Test: [150/250]	Acc@1 for Text-Pose: 66.225	mCA for Text-Pose: 69.580	
[2024-12-24 22:47:56 ViT-B/16] (CL_main_v2.py 379): INFO Test: [150/250]	Acc@1 for Image-Text-Pose: 66.225	mCA for Image-Text-Pose: 69.580	
[2024-12-24 22:48:03 ViT-B/16] (CL_main_v2.py 379): INFO Test: [200/250]	Acc@1 for Image-Text: 1.990	mCA for Image-Text: 2.037	
[2024-12-24 22:48:03 ViT-B/16] (CL_main_v2.py 379): INFO Test: [200/250]	Acc@1 for Text-Pose: 66.667	mCA for Text-Pose: 68.258	
[2024-12-24 22:48:03 ViT-B/16] (CL_main_v2.py 379): INFO Test: [200/250]	Acc@1 for Image-Text-Pose: 66.667	mCA for Image-Text-Pose: 68.258	
[2024-12-24 22:48:10 ViT-B/16] (CL_main_v2.py 406): INFO  * Acc@1 for Image-Text: 3.150 Acc@5 for Image-Text: 12.600 mCA for Image-Text: 2.885
[2024-12-24 22:48:10 ViT-B/16] (CL_main_v2.py 406): INFO  * Acc@1 for Text-Pose: 70.550 Acc@5 for Text-Pose: 86.350 mCA for Text-Pose: 71.699
[2024-12-24 22:48:10 ViT-B/16] (CL_main_v2.py 406): INFO  * Acc@1 for Image-Text-Pose: 70.550 Acc@5 for Image-Text-Pose: 86.400 mCA for Image-Text-Pose: 71.696
[2024-12-24 22:48:10 ViT-B/16] (CL_main_v2.py 157): INFO Accuracy of the network on the 2004 test videos on Image-Text: 3.1%. mCA: 2.9
[2024-12-24 22:48:10 ViT-B/16] (CL_main_v2.py 165): INFO Max accuracy: 3.15%
