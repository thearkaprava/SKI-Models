[2024-12-24 21:35:50 ViT-B/16] (CL_main_v2.py 442): INFO working dir: ./workdirs/TEST_P2_SKIViFiCLIP_zs_48_25Dec24/
[2024-12-24 21:36:05 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 261): INFO Loading CLIP (backbone: ViT-B/16)
[2024-12-24 21:36:09 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 265): INFO Building Model
[2024-12-24 21:36:09 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 282): INFO Turning on gradients for COMPLETE SKI_VLM model
[2024-12-24 21:36:09 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 315): INFO Parameters to be updated: {'text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'hyperformer_model.l4.tcn1.branches.0.0.weight', 'hyperformer_model.l7.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.2.ln_2.bias', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'clip_text_encoder.text_projection', 'clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'hyperformer_model.l2.tcn1.branches.3.1.bias', 'hyperformer_model.l9.vit1.attn.outer', 'image_encoder.positional_embedding', 'clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.8.ln_2.weight', 'image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'hyperformer_model.l9.tcn1.branches.2.0.weight', 'hyperformer_model.l8.tcn1.branches.0.3.conv.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'hyperformer_model.l2.tcn1.branches.3.0.weight', 'image_encoder.transformer.resblocks.9.ln_2.weight', 'hyperformer_model.l8.vit1.pe_proj.weight', 'hyperformer_model.l9.tcn1.branches.3.0.bias', 'hyperformer_model.l5.tcn1.branches.3.0.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.10.ln_2.bias', 'hyperformer_model.l2.tcn1.branches.1.1.weight', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'text_encoder.transformer.resblocks.7.ln_1.bias', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'hyperformer_model.l4.vit1.pe_proj.weight', 'image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'image_encoder.ln_post.weight', 'image_encoder.transformer.resblocks.6.ln_1.bias', 'text_encoder.transformer.resblocks.7.ln_1.weight', 'hyperformer_model.l3.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l6.tcn1.branches.0.1.weight', 'hyperformer_model.l7.tcn1.branches.3.1.weight', 'hyperformer_model.l9.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'hyperformer_model.l2.tcn1.branches.0.1.bias', 'hyperformer_model.l6.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l10.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'hyperformer_model.l8.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.2.1.weight', 'hyperformer_model.l9.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l2.tcn1.branches.1.0.weight', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'text_encoder.transformer.resblocks.4.ln_1.bias', 'hyperformer_model.l2.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l4.tcn1.branches.1.1.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'hyperformer_model.l6.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'hyperformer_model.l10.tcn1.branches.1.3.bn.bias', 'text_encoder.transformer.resblocks.0.ln_2.bias', 'hyperformer_model.l1.vit1.attn.proj.weight', 'hyperformer_model.l1.vit1.skip_proj.weight', 'hyperformer_model.l8.residual.conv.bias', 'hyperformer_model.l10.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l6.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l8.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l8.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'hyperformer_model.l5.tcn1.branches.2.0.weight', 'text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.2.ln_1.bias', 'clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.2.0.bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.3.ln_1.weight', 'hyperformer_model.l6.vit1.pe_proj.weight', 'image_encoder.transformer.resblocks.0.ln_1.weight', 'image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'text_encoder.transformer.resblocks.1.ln_1.bias', 'text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l3.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'hyperformer_model.l5.vit1.attn.rpe', 'text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'hyperformer_model.l7.vit1.norm1.weight', 'text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'image_encoder.conv1.weight', 'hyperformer_model.l2.tcn1.branches.3.1.weight', 'hyperformer_model.l5.tcn1.branches.1.3.conv.weight', 'image_encoder.ln_pre.weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l3.tcn1.branches.0.0.weight', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'hyperformer_model.l10.tcn1.branches.1.0.weight', 'hyperformer_model.l1.tcn1.branches.3.1.weight', 'hyperformer_model.l2.tcn1.branches.0.0.weight', 'hyperformer_model.l1.vit1.attn.q.weight', 'text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.2.0.bias', 'hyperformer_model.l8.tcn1.branches.2.1.bias', 'hyperformer_model.l8.tcn1.branches.2.4.weight', 'hyperformer_model.l10.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'hyperformer_model.l1.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.0.ln_2.bias', 'hyperformer_model.l1.vit1.attn.proj.bias', 'hyperformer_model.l8.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l3.vit1.attn.w1', 'text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'hyperformer_model.l4.vit1.norm1.bias', 'hyperformer_model.l7.vit1.attn.rpe', 'text_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.l6.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.3.0.weight', 'image_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.l7.vit1.attn.alpha', 'image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'hyperformer_model.l5.vit1.attn.kv.weight', 'hyperformer_model.l4.vit1.attn.proj.bias', 'hyperformer_model.l2.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l7.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l3.tcn1.branches.0.3.bn.weight', 'image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l8.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'hyperformer_model.l2.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l1.residual.conv.weight', 'text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.10.ln_1.weight', 'text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l9.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l8.tcn1.branches.0.1.bias', 'hyperformer_model.l3.vit1.norm1.bias', 'image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'hyperformer_model.l3.vit1.attn.outer', 'hyperformer_model.l2.vit1.norm1.weight', 'hyperformer_model.l4.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'hyperformer_model.l3.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l10.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'hyperformer_model.l6.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.9.ln_1.weight', 'hyperformer_model.l7.tcn1.branches.0.3.conv.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.4.ln_1.weight', 'image_encoder.transformer.resblocks.9.ln_1.bias', 'clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'hyperformer_model.l10.tcn1.branches.1.1.weight', 'hyperformer_model.l1.vit1.norm1.bias', 'hyperformer_model.l1.tcn1.branches.0.0.bias', 'hyperformer_model.l1.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'hyperformer_model.l5.vit1.attn.alpha', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.data_bn.bias', 'hyperformer_model.l9.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l6.vit1.attn.proj.weight', 'hyperformer_model.l9.tcn1.branches.0.3.conv.bias', 'clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'hyperformer_model.l4.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l3.vit1.attn.proj.weight', 'hyperformer_model.l10.tcn1.branches.0.0.bias', 'hyperformer_model.l9.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'hyperformer_model.l2.vit1.attn.w1', 'image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'text_encoder.transformer.resblocks.11.ln_1.weight', 'clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'hyperformer_model.l8.tcn1.branches.1.0.weight', 'hyperformer_model.l7.tcn1.branches.0.0.bias', 'hyperformer_model.l2.vit1.attn.alpha', 'hyperformer_model.l4.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l6.tcn1.branches.2.0.weight', 'hyperformer_model.l5.tcn1.branches.1.1.bias', 'hyperformer_model.l9.tcn1.branches.0.1.bias', 'hyperformer_model.l9.vit1.attn.kv.weight', 'hyperformer_model.l1.tcn1.branches.2.0.weight', 'hyperformer_model.l3.vit1.attn.alpha', 'image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'hyperformer_model.l6.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.11.ln_2.bias', 'hyperformer_model.l9.vit1.attn.rpe', 'image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'hyperformer_model.l4.vit1.attn.alpha', 'image_encoder.transformer.resblocks.4.ln_1.bias', 'image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l9.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'image_encoder.class_embedding', 'image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.0.1.weight', 'hyperformer_model.l2.tcn1.branches.2.0.bias', 'hyperformer_model.l3.vit1.attn.proj.bias', 'hyperformer_model.l7.tcn1.branches.2.0.weight', 'clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.l1.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l6.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l7.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'clip_text_encoder.ln_final.bias', 'image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'hyperformer_model.l5.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'hyperformer_model.l1.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'hyperformer_model.l4.vit1.attn.proj.weight', 'hyperformer_model.l2.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'hyperformer_model.l2.tcn1.branches.1.1.bias', 'hyperformer_model.l7.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.10.ln_2.bias', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'hyperformer_model.l5.tcn1.branches.0.1.weight', 'hyperformer_model.l6.vit1.attn.proj.bias', 'hyperformer_model.l10.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l7.vit1.attn.w1', 'hyperformer_model.l10.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'hyperformer_model.l6.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'hyperformer_model.l10.tcn1.branches.3.0.weight', 'image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.ln_2.weight', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l4.tcn1.branches.3.1.weight', 'hyperformer_model.l8.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'hyperformer_model.l7.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l7.tcn1.branches.1.1.weight', 'hyperformer_model.l10.tcn1.branches.1.0.bias', 'hyperformer_model.l4.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l6.tcn1.branches.0.1.bias', 'hyperformer_model.l2.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.5.ln_2.bias', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l8.vit1.attn.proj.weight', 'text_encoder.transformer.resblocks.5.ln_1.weight', 'hyperformer_model.l5.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'hyperformer_model.l7.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.10.ln_1.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'hyperformer_model.l10.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l2.tcn1.branches.2.1.bias', 'hyperformer_model.l8.residual.bn.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'hyperformer_model.l3.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l6.vit1.attn.outer', 'hyperformer_model.l9.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.3.ln_2.bias', 'hyperformer_model.l8.vit1.attn.rpe', 'hyperformer_model.l8.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l9.tcn1.branches.2.4.bias', 'hyperformer_model.l4.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'hyperformer_model.l5.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'hyperformer_model.l5.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'image_encoder.ln_post.bias', 'text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'hyperformer_model.l8.tcn1.branches.3.1.bias', 'text_encoder.transformer.resblocks.4.ln_2.weight', 'clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l3.tcn1.branches.0.0.bias', 'hyperformer_model.l3.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l3.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'hyperformer_model.l8.vit1.attn.outer', 'hyperformer_model.l7.tcn1.branches.2.4.weight', 'hyperformer_model.l10.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.0.3.conv.weight', 'image_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l2.tcn1.branches.0.3.conv.bias', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'hyperformer_model.l8.vit1.attn.alpha', 'hyperformer_model.l5.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.3.ln_1.weight', 'hyperformer_model.l6.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l9.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.1.0.bias', 'hyperformer_model.l2.tcn1.branches.0.3.bn.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'hyperformer_model.l10.tcn1.branches.2.0.bias', 'image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'text_encoder.transformer.resblocks.3.ln_2.weight', 'image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'image_encoder.transformer.resblocks.1.ln_2.weight', 'text_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l3.tcn1.branches.1.1.bias', 'image_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l4.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l3.tcn1.branches.0.1.weight', 'text_encoder.positional_embedding', 'hyperformer_model.l1.residual.bn.weight', 'hyperformer_model.l3.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.6.ln_1.bias', 'hyperformer_model.l2.tcn1.branches.0.0.bias', 'hyperformer_model.l2.vit1.attn.outer', 'hyperformer_model.l7.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l6.tcn1.branches.3.1.weight', 'hyperformer_model.l4.tcn1.branches.2.0.bias', 'hyperformer_model.l5.tcn1.branches.3.1.weight', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'hyperformer_model.l2.tcn1.branches.3.0.bias', 'hyperformer_model.l3.tcn1.branches.2.4.bias', 'hyperformer_model.l8.residual.bn.bias', 'image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.1.ln_2.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'hyperformer_model.l6.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l6.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l6.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'hyperformer_model.l4.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'hyperformer_model.l4.tcn1.branches.2.1.bias', 'hyperformer_model.l10.tcn1.branches.3.1.bias', 'hyperformer_model.l5.residual.conv.weight', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'hyperformer_model.l4.tcn1.branches.3.0.bias', 'hyperformer_model.l3.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l6.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'hyperformer_model.l6.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.9.ln_2.bias', 'hyperformer_model.l10.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l3.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'hyperformer_model.l1.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.10.ln_1.weight', 'hyperformer_model.l2.tcn1.branches.0.1.weight', 'hyperformer_model.l5.tcn1.branches.0.3.conv.bias', 'clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l5.vit1.attn.q.weight', 'hyperformer_model.l6.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.fc2.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l5.tcn1.branches.2.4.bias', 'hyperformer_model.l4.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'hyperformer_model.l2.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'hyperformer_model.l4.vit1.attn.outer', 'hyperformer_model.l8.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'hyperformer_model.l9.tcn1.branches.1.3.bn.weight', 'text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'hyperformer_model.l10.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.1.ln_1.weight', 'hyperformer_model.l3.tcn1.branches.2.0.weight', 'hyperformer_model.l10.tcn1.branches.3.1.weight', 'hyperformer_model.l1.tcn1.branches.0.3.conv.weight', 'image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'image_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l5.vit1.norm1.weight', 'hyperformer_model.l7.vit1.attn.outer', 'text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'text_encoder.ln_final.bias', 'image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'text_encoder.text_projection', 'image_encoder.transformer.resblocks.9.ln_2.bias', 'text_encoder.ln_final.weight', 'hyperformer_model.l5.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.11.ln_1.bias', 'image_encoder.transformer.resblocks.7.ln_1.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'hyperformer_model.l6.tcn1.branches.3.1.bias', 'text_encoder.transformer.resblocks.1.ln_1.weight', 'image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'hyperformer_model.l2.vit1.pe_proj.weight', 'hyperformer_model.l4.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.3.ln_2.bias', 'hyperformer_model.l1.tcn1.branches.2.0.bias', 'hyperformer_model.l1.tcn1.branches.3.1.bias', 'hyperformer_model.l8.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.0.0.weight', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'hyperformer_model.l5.tcn1.branches.3.1.bias', 'hyperformer_model.l7.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'image_encoder.transformer.resblocks.8.ln_1.weight', 'text_encoder.transformer.resblocks.6.ln_2.weight', 'image_encoder.proj', 'hyperformer_model.l3.vit1.pe_proj.weight', 'hyperformer_model.l4.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'hyperformer_model.l8.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l10.vit1.pe_proj.weight', 'hyperformer_model.l4.tcn1.branches.3.0.weight', 'image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'image_encoder.transformer.resblocks.10.ln_2.weight', 'hyperformer_model.l7.vit1.attn.proj.bias', 'hyperformer_model.l9.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'image_encoder.transformer.resblocks.5.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'hyperformer_model.l9.tcn1.branches.2.1.weight', 'clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'hyperformer_model.l4.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l2.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'hyperformer_model.l1.tcn1.branches.1.1.weight', 'hyperformer_model.l7.vit1.attn.kv.weight', 'hyperformer_model.l5.vit1.pe_proj.weight', 'hyperformer_model.l7.tcn1.branches.2.1.weight', 'hyperformer_model.l8.tcn1.branches.2.0.bias', 'hyperformer_model.l1.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.7.ln_2.bias', 'clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'hyperformer_model.l7.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.2.ln_2.weight', 'hyperformer_model.l2.tcn1.branches.2.4.weight', 'hyperformer_model.l10.tcn1.branches.2.4.bias', 'hyperformer_model.l7.vit1.norm1.bias', 'text_encoder.transformer.resblocks.11.ln_1.bias', 'image_encoder.transformer.resblocks.2.ln_1.weight', 'clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'image_encoder.transformer.resblocks.2.ln_2.weight', 'hyperformer_model.l7.tcn1.branches.3.0.bias', 'hyperformer_model.l9.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l1.vit1.attn.rpe', 'image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l7.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.4.ln_1.weight', 'image_encoder.transformer.resblocks.5.ln_1.bias', 'hyperformer_model.l1.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l9.vit1.attn.q.weight', 'text_encoder.transformer.resblocks.10.ln_2.weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.data_bn.weight', 'hyperformer_model.l3.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l9.tcn1.branches.1.1.weight', 'hyperformer_model.l2.vit1.attn.proj.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'hyperformer_model.l8.tcn1.branches.0.0.weight', 'hyperformer_model.l2.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'text_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l4.vit1.attn.kv.weight', 'hyperformer_model.l10.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l7.tcn1.branches.3.1.bias', 'hyperformer_model.l8.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'hyperformer_model.l9.vit1.attn.proj.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.7.ln_1.bias', 'image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'hyperformer_model.l1.vit1.norm1.weight', 'text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.8.ln_1.weight', 'hyperformer_model.l5.residual.bn.bias', 'clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'text_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l8.residual.conv.weight', 'hyperformer_model.l4.tcn1.branches.0.0.bias', 'image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'hyperformer_model.l9.vit1.attn.alpha', 'hyperformer_model.l10.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.11.ln_1.weight', 'hyperformer_model.l7.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l4.tcn1.branches.2.4.weight', 'hyperformer_model.l5.vit1.attn.outer', 'hyperformer_model.l3.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l5.vit1.attn.proj.weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'image_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l3.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l9.tcn1.branches.1.1.bias', 'hyperformer_model.l10.vit1.attn.w1', 'image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l10.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'hyperformer_model.l5.tcn1.branches.1.0.weight', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l3.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'hyperformer_model.l8.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'hyperformer_model.l4.tcn1.branches.2.4.bias', 'hyperformer_model.l4.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l5.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'image_encoder.transformer.resblocks.3.ln_2.weight', 'text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'hyperformer_model.l9.tcn1.branches.1.0.weight', 'hyperformer_model.l6.tcn1.branches.2.4.weight', 'hyperformer_model.l1.vit1.pe_proj.weight', 'hyperformer_model.l10.vit1.attn.proj.bias', 'hyperformer_model.l8.tcn1.branches.2.0.weight', 'hyperformer_model.l10.vit1.attn.rpe', 'image_encoder.transformer.resblocks.9.ln_1.weight', 'hyperformer_model.l5.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.l8.tcn1.branches.2.4.bias', 'clip_text_encoder.positional_embedding', 'text_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l9.vit1.norm1.weight', 'text_encoder.transformer.resblocks.8.ln_2.weight', 'hyperformer_model.l9.tcn1.branches.1.3.bn.bias', 'text_encoder.transformer.resblocks.9.ln_2.weight', 'image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l8.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.5.ln_2.bias', 'text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'hyperformer_model.l5.vit1.attn.w1', 'image_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l7.vit1.attn.proj.weight', 'image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'hyperformer_model.l2.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.2.ln_2.bias', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.4.ln_2.bias', 'hyperformer_model.l3.tcn1.branches.1.3.bn.weight', 'image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'hyperformer_model.fc2.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'hyperformer_model.l9.tcn1.branches.3.1.bias', 'hyperformer_model.l3.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'hyperformer_model.l9.vit1.pe_proj.weight', 'hyperformer_model.l9.tcn1.branches.0.0.weight', 'hyperformer_model.l6.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l8.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.1.ln_1.bias', 'text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'hyperformer_model.l4.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l3.vit1.attn.q.weight', 'text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'text_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l1.vit1.attn.alpha', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.0.1.weight', 'hyperformer_model.l1.tcn1.branches.0.1.bias', 'hyperformer_model.l8.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l6.vit1.attn.alpha', 'clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'hyperformer_model.l6.tcn1.branches.2.0.bias', 'image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'hyperformer_model.l10.vit1.attn.proj.weight', 'text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'hyperformer_model.l1.vit1.attn.outer', 'text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'hyperformer_model.l3.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'hyperformer_model.l7.tcn1.branches.2.0.bias', 'hyperformer_model.l1.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l5.tcn1.branches.1.1.weight', 'image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l6.tcn1.branches.0.3.conv.bias', 'text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'hyperformer_model.l2.vit1.attn.kv.weight', 'hyperformer_model.l3.tcn1.branches.3.0.bias', 'hyperformer_model.l3.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l6.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l2.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l8.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'hyperformer_model.l7.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'hyperformer_model.l3.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l9.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'hyperformer_model.l7.tcn1.branches.1.1.bias', 'image_encoder.ln_pre.bias', 'hyperformer_model.l5.tcn1.branches.0.0.bias', 'image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'text_encoder.transformer.resblocks.2.ln_1.weight', 'hyperformer_model.l6.tcn1.branches.2.4.bias', 'hyperformer_model.l8.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'hyperformer_model.l4.tcn1.branches.3.1.bias', 'text_encoder.transformer.resblocks.11.ln_2.bias', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'hyperformer_model.l7.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l10.vit1.norm1.weight', 'hyperformer_model.l1.tcn1.branches.2.4.weight', 'hyperformer_model.l6.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l10.vit1.attn.alpha', 'hyperformer_model.l4.vit1.attn.w1', 'text_encoder.transformer.resblocks.6.ln_2.bias', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.5.ln_1.bias', 'hyperformer_model.l5.residual.bn.weight', 'hyperformer_model.l6.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l7.vit1.pe_proj.weight', 'image_encoder.transformer.resblocks.6.ln_2.bias', 'image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'hyperformer_model.l1.residual.bn.bias', 'image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.8.ln_2.bias', 'image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'hyperformer_model.l7.tcn1.branches.2.1.bias', 'hyperformer_model.l6.vit1.attn.w1', 'text_encoder.transformer.resblocks.7.ln_2.bias', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'hyperformer_model.l10.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l10.tcn1.branches.1.1.bias', 'hyperformer_model.l3.vit1.norm1.weight', 'hyperformer_model.l2.tcn1.branches.2.1.weight', 'hyperformer_model.l10.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l5.tcn1.branches.2.4.weight', 'hyperformer_model.l9.tcn1.branches.3.0.weight', 'hyperformer_model.l10.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l3.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'hyperformer_model.l4.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.11.ln_2.weight', 'image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'hyperformer_model.l4.tcn1.branches.1.1.weight', 'hyperformer_model.l1.tcn1.branches.3.0.bias', 'hyperformer_model.l2.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l5.tcn1.branches.2.1.bias', 'text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'hyperformer_model.l4.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l2.tcn1.branches.2.0.weight', 'hyperformer_model.l3.tcn1.branches.2.0.bias', 'hyperformer_model.l6.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.9.ln_1.bias', 'text_encoder.transformer.resblocks.4.ln_2.bias', 'hyperformer_model.l8.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l6.vit1.attn.q.weight', 'hyperformer_model.l1.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l8.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.l10.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'hyperformer_model.l4.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'hyperformer_model.l10.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.4.ln_2.weight', 'hyperformer_model.l1.residual.conv.bias', 'hyperformer_model.l10.vit1.attn.outer', 'text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'hyperformer_model.l1.tcn1.branches.2.1.weight', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'clip_text_encoder.ln_final.weight', 'hyperformer_model.l8.vit1.attn.w1', 'hyperformer_model.l2.tcn1.branches.1.0.bias', 'hyperformer_model.l5.residual.conv.bias', 'hyperformer_model.l8.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight'}
[2024-12-24 21:36:09 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 316): INFO Total learnable items: 835
[2024-12-24 21:36:30 ViT-B/16] (tools.py 147): INFO ==============> Resuming from ./workdirs/TEST_P1_SKeletonCLIP_alltrn_HFinit_zs_48_17Dec24/ckpt_epoch_0.pth....................
[2024-12-24 21:36:30 ViT-B/16] (tools.py 172): INFO resume VIFICLIP model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.clip_text_encoder.positional_embedding', 'module.clip_text_encoder.text_projection', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'module.clip_text_encoder.ln_final.weight', 'module.clip_text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:36:30 ViT-B/16] (tools.py 176): INFO ==============> Resuming from /data/users/asinha13/projects/CLIP4ADL/model_chkpnts/ntu_CS_P1_HF_pretrain_frzn_txt_zs_48_AS_16Jan24/ckpt_epoch_99.pth....................
[2024-12-24 21:36:31 ViT-B/16] (tools.py 218): INFO resume Hyperformer model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.text_encoder.positional_embedding', 'module.text_encoder.text_projection', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_1.weight', 'module.text_encoder.transformer.resblocks.0.ln_1.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_2.weight', 'module.text_encoder.transformer.resblocks.0.ln_2.bias', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_1.weight', 'module.text_encoder.transformer.resblocks.1.ln_1.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_2.weight', 'module.text_encoder.transformer.resblocks.1.ln_2.bias', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_1.weight', 'module.text_encoder.transformer.resblocks.2.ln_1.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_2.weight', 'module.text_encoder.transformer.resblocks.2.ln_2.bias', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_1.weight', 'module.text_encoder.transformer.resblocks.3.ln_1.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_2.weight', 'module.text_encoder.transformer.resblocks.3.ln_2.bias', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_1.weight', 'module.text_encoder.transformer.resblocks.4.ln_1.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_2.weight', 'module.text_encoder.transformer.resblocks.4.ln_2.bias', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_1.weight', 'module.text_encoder.transformer.resblocks.5.ln_1.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_2.weight', 'module.text_encoder.transformer.resblocks.5.ln_2.bias', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_1.weight', 'module.text_encoder.transformer.resblocks.6.ln_1.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_2.weight', 'module.text_encoder.transformer.resblocks.6.ln_2.bias', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_1.weight', 'module.text_encoder.transformer.resblocks.7.ln_1.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_2.weight', 'module.text_encoder.transformer.resblocks.7.ln_2.bias', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_1.weight', 'module.text_encoder.transformer.resblocks.8.ln_1.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_2.weight', 'module.text_encoder.transformer.resblocks.8.ln_2.bias', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_1.weight', 'module.text_encoder.transformer.resblocks.9.ln_1.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_2.weight', 'module.text_encoder.transformer.resblocks.9.ln_2.bias', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_1.weight', 'module.text_encoder.transformer.resblocks.10.ln_1.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_2.weight', 'module.text_encoder.transformer.resblocks.10.ln_2.bias', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_1.weight', 'module.text_encoder.transformer.resblocks.11.ln_1.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_2.weight', 'module.text_encoder.transformer.resblocks.11.ln_2.bias', 'module.text_encoder.ln_final.weight', 'module.text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:36:36 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][0/11317]	eta 16:33:11 lr 0.000022000	time 5.2656 (5.2656)	dist_loss 0.4876 (0.4876)	image_text_loss 3.9011 (3.9011)	pose_text_loss 2.4215 (2.4215)	tot_loss 11.1982 (11.1982)	mem 29650MB
[2024-12-24 21:36:53 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][50/11317]	eta 1:23:00 lr 0.000021999	time 0.3562 (0.4420)	dist_loss 0.0088 (0.1624)	image_text_loss 3.8138 (3.8738)	pose_text_loss 3.5693 (3.6800)	tot_loss 7.4715 (9.1776)	mem 29650MB
[2024-12-24 21:37:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][100/11317]	eta 1:14:26 lr 0.000021996	time 0.3475 (0.3982)	dist_loss 0.0096 (0.0876)	image_text_loss 4.0065 (3.8693)	pose_text_loss 3.8602 (3.7088)	tot_loss 7.9626 (8.4543)	mem 29650MB
[2024-12-24 21:38:19 ViT-B/16] (CL_main_v2.py 442): INFO working dir: ./workdirs/TEST_P2_SKIViFiCLIP_zs_48_25Dec24/
[2024-12-24 21:40:08 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 261): INFO Loading CLIP (backbone: ViT-B/16)
[2024-12-24 21:40:12 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 265): INFO Building Model
[2024-12-24 21:40:12 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 282): INFO Turning on gradients for COMPLETE SKI_VLM model
[2024-12-24 21:40:12 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 315): INFO Parameters to be updated: {'hyperformer_model.l7.vit1.norm1.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'hyperformer_model.l9.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'hyperformer_model.l9.tcn1.branches.2.1.weight', 'hyperformer_model.l4.vit1.attn.proj.weight', 'hyperformer_model.l10.tcn1.branches.2.1.weight', 'hyperformer_model.l6.tcn1.branches.2.0.bias', 'hyperformer_model.l7.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.5.ln_1.bias', 'hyperformer_model.l9.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'text_encoder.transformer.resblocks.9.ln_1.bias', 'hyperformer_model.l2.vit1.attn.rpe', 'hyperformer_model.l4.vit1.attn.w1', 'hyperformer_model.l4.vit1.pe_proj.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'text_encoder.transformer.resblocks.3.ln_1.weight', 'image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'hyperformer_model.l2.tcn1.branches.1.1.bias', 'hyperformer_model.l5.tcn1.branches.2.0.bias', 'hyperformer_model.l3.vit1.norm1.bias', 'hyperformer_model.l8.tcn1.branches.0.1.weight', 'hyperformer_model.l10.vit1.attn.alpha', 'clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'image_encoder.transformer.resblocks.9.ln_2.weight', 'hyperformer_model.l7.vit1.attn.alpha', 'hyperformer_model.l1.residual.bn.bias', 'hyperformer_model.l4.tcn1.branches.2.1.weight', 'hyperformer_model.l6.vit1.norm1.bias', 'hyperformer_model.l6.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'text_encoder.transformer.resblocks.2.ln_2.bias', 'text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l4.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l8.tcn1.branches.1.0.weight', 'hyperformer_model.l5.residual.conv.weight', 'hyperformer_model.l7.vit1.attn.q.weight', 'hyperformer_model.l6.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'hyperformer_model.l5.tcn1.branches.0.1.bias', 'hyperformer_model.l6.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.9.ln_1.bias', 'text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'hyperformer_model.l8.vit1.attn.outer', 'hyperformer_model.l1.tcn1.branches.0.1.weight', 'hyperformer_model.l5.residual.conv.bias', 'image_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l1.tcn1.branches.2.4.bias', 'hyperformer_model.l9.vit1.attn.outer', 'clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l9.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.10.ln_2.bias', 'hyperformer_model.l10.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l7.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.3.ln_1.bias', 'text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'text_encoder.text_projection', 'text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'hyperformer_model.l2.vit1.norm1.weight', 'hyperformer_model.l6.vit1.attn.rpe', 'hyperformer_model.l1.tcn1.branches.1.3.conv.bias', 'image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l4.tcn1.branches.2.0.weight', 'hyperformer_model.l4.tcn1.branches.3.0.weight', 'hyperformer_model.l1.vit1.attn.w1', 'hyperformer_model.l2.vit1.attn.outer', 'hyperformer_model.l7.tcn1.branches.0.0.weight', 'hyperformer_model.l5.tcn1.branches.0.1.weight', 'hyperformer_model.l7.tcn1.branches.1.1.bias', 'hyperformer_model.l2.vit1.attn.alpha', 'text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'hyperformer_model.l2.tcn1.branches.0.1.bias', 'hyperformer_model.l1.tcn1.branches.3.1.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'image_encoder.conv1.weight', 'hyperformer_model.l8.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l9.tcn1.branches.2.0.bias', 'clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.0.3.bn.weight', 'image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'hyperformer_model.l2.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'hyperformer_model.l3.vit1.attn.outer', 'image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'hyperformer_model.l4.tcn1.branches.2.0.bias', 'hyperformer_model.l8.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l8.tcn1.branches.2.1.weight', 'hyperformer_model.l6.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'hyperformer_model.data_bn.weight', 'hyperformer_model.l10.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l7.vit1.attn.kv.weight', 'hyperformer_model.l6.vit1.norm1.weight', 'image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l5.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l10.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l4.vit1.attn.kv.weight', 'hyperformer_model.l4.tcn1.branches.3.1.bias', 'hyperformer_model.l4.vit1.attn.alpha', 'text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'hyperformer_model.l1.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'hyperformer_model.l8.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'hyperformer_model.l3.tcn1.branches.3.1.weight', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l7.vit1.attn.proj.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'hyperformer_model.l3.tcn1.branches.1.1.weight', 'hyperformer_model.l4.tcn1.branches.1.0.bias', 'hyperformer_model.l8.vit1.attn.w1', 'hyperformer_model.l10.vit1.attn.q.weight', 'hyperformer_model.l10.tcn1.branches.1.0.weight', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'image_encoder.transformer.resblocks.8.ln_1.bias', 'text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l5.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'hyperformer_model.l3.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'hyperformer_model.l4.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'hyperformer_model.l8.tcn1.branches.0.1.bias', 'hyperformer_model.l10.vit1.pe_proj.weight', 'image_encoder.class_embedding', 'hyperformer_model.l2.tcn1.branches.3.1.bias', 'text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'hyperformer_model.l10.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.4.ln_2.bias', 'hyperformer_model.l7.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'hyperformer_model.l2.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'hyperformer_model.l2.tcn1.branches.1.1.weight', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'hyperformer_model.l3.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'text_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l4.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.7.ln_1.bias', 'hyperformer_model.l1.vit1.attn.kv.weight', 'hyperformer_model.l8.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'hyperformer_model.l1.vit1.attn.proj.weight', 'image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'hyperformer_model.l2.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.0.ln_2.weight', 'text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'hyperformer_model.l5.vit1.attn.proj.bias', 'hyperformer_model.l2.tcn1.branches.1.3.bn.weight', 'image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'hyperformer_model.l2.tcn1.branches.3.0.weight', 'hyperformer_model.l5.tcn1.branches.1.1.weight', 'hyperformer_model.l9.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.l5.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l10.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.7.ln_1.weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l3.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'image_encoder.transformer.resblocks.1.ln_2.weight', 'hyperformer_model.l4.vit1.attn.rpe', 'hyperformer_model.l9.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l9.tcn1.branches.0.0.bias', 'hyperformer_model.fc2.weight', 'hyperformer_model.l5.vit1.attn.rpe', 'image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'hyperformer_model.l6.vit1.attn.alpha', 'image_encoder.transformer.resblocks.1.ln_1.bias', 'clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.l3.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'hyperformer_model.l6.tcn1.branches.1.1.weight', 'hyperformer_model.l9.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l6.tcn1.branches.3.1.bias', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.3.0.bias', 'hyperformer_model.l2.tcn1.branches.1.0.bias', 'hyperformer_model.l8.vit1.attn.proj.weight', 'text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'text_encoder.transformer.resblocks.7.ln_2.weight', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'hyperformer_model.l1.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l5.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l7.vit1.attn.w1', 'hyperformer_model.l3.vit1.attn.proj.bias', 'hyperformer_model.l10.vit1.attn.proj.weight', 'image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'text_encoder.transformer.resblocks.5.ln_1.weight', 'clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'hyperformer_model.l1.tcn1.branches.0.0.weight', 'hyperformer_model.l6.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.1.ln_1.bias', 'text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'hyperformer_model.l1.tcn1.branches.1.0.weight', 'hyperformer_model.l9.vit1.attn.w1', 'text_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l9.tcn1.branches.0.3.conv.bias', 'text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.8.ln_2.weight', 'hyperformer_model.l10.tcn1.branches.0.3.bn.bias', 'image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'hyperformer_model.l10.vit1.attn.outer', 'image_encoder.transformer.resblocks.7.ln_2.bias', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'hyperformer_model.l3.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'hyperformer_model.l7.tcn1.branches.2.1.weight', 'hyperformer_model.l5.vit1.attn.alpha', 'hyperformer_model.fc2.bias', 'image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'hyperformer_model.l4.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.0.ln_1.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'image_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l9.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'image_encoder.ln_post.weight', 'text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l2.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'hyperformer_model.l10.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'hyperformer_model.l3.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.7.ln_2.bias', 'text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'hyperformer_model.l7.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'hyperformer_model.l7.tcn1.branches.2.4.bias', 'text_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l5.vit1.attn.outer', 'hyperformer_model.l6.tcn1.branches.2.4.bias', 'hyperformer_model.l2.vit1.pe_proj.weight', 'hyperformer_model.l1.tcn1.branches.2.0.bias', 'hyperformer_model.l8.residual.bn.bias', 'text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'image_encoder.transformer.resblocks.5.ln_1.weight', 'hyperformer_model.l3.tcn1.branches.0.1.weight', 'hyperformer_model.l10.tcn1.branches.0.0.weight', 'hyperformer_model.l5.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l4.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l3.tcn1.branches.2.0.weight', 'hyperformer_model.l6.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'hyperformer_model.l2.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l4.vit1.attn.proj.bias', 'hyperformer_model.l10.tcn1.branches.2.1.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.weight', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'text_encoder.transformer.resblocks.2.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.0.ln_1.weight', 'text_encoder.transformer.resblocks.10.ln_2.bias', 'hyperformer_model.l3.vit1.attn.proj.weight', 'clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l3.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'hyperformer_model.l1.tcn1.branches.1.1.bias', 'hyperformer_model.l10.tcn1.branches.2.0.weight', 'hyperformer_model.l7.vit1.attn.outer', 'clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l10.tcn1.branches.0.1.bias', 'hyperformer_model.l2.tcn1.branches.2.1.weight', 'hyperformer_model.l1.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'image_encoder.transformer.resblocks.7.ln_2.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'hyperformer_model.l10.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.3.1.bias', 'hyperformer_model.l9.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'clip_text_encoder.text_projection', 'image_encoder.ln_pre.bias', 'hyperformer_model.l1.tcn1.branches.0.1.bias', 'hyperformer_model.l3.vit1.norm1.weight', 'image_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l8.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'hyperformer_model.l7.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'hyperformer_model.l8.vit1.attn.alpha', 'clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'image_encoder.transformer.resblocks.1.ln_1.weight', 'image_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l9.tcn1.branches.1.0.weight', 'hyperformer_model.l5.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'text_encoder.ln_final.weight', 'image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'hyperformer_model.l1.vit1.attn.alpha', 'hyperformer_model.l2.tcn1.branches.0.1.weight', 'hyperformer_model.l5.vit1.norm1.bias', 'image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'text_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l3.tcn1.branches.2.4.bias', 'hyperformer_model.l8.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.2.ln_1.bias', 'clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.11.ln_1.weight', 'hyperformer_model.l1.vit1.attn.proj.bias', 'clip_text_encoder.ln_final.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'hyperformer_model.l4.tcn1.branches.1.1.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'hyperformer_model.l6.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l6.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'image_encoder.ln_pre.weight', 'clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'clip_text_encoder.ln_final.weight', 'hyperformer_model.l5.tcn1.branches.1.1.bias', 'hyperformer_model.l3.tcn1.branches.2.4.weight', 'clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'hyperformer_model.l4.tcn1.branches.3.0.bias', 'hyperformer_model.l2.tcn1.branches.1.0.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'hyperformer_model.l8.vit1.norm1.bias', 'hyperformer_model.l7.tcn1.branches.1.3.bn.weight', 'text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'hyperformer_model.l6.tcn1.branches.0.1.weight', 'hyperformer_model.l8.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l6.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.4.ln_2.weight', 'text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'hyperformer_model.l7.tcn1.branches.2.1.bias', 'hyperformer_model.l3.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l5.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.4.ln_1.weight', 'image_encoder.positional_embedding', 'text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'hyperformer_model.l3.vit1.pe_proj.weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'hyperformer_model.l4.vit1.attn.outer', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'text_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l2.vit1.attn.proj.weight', 'image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'hyperformer_model.l3.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l5.vit1.pe_proj.weight', 'clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'hyperformer_model.l8.tcn1.branches.0.0.bias', 'image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'hyperformer_model.l9.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l1.residual.conv.weight', 'text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'hyperformer_model.l10.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'hyperformer_model.l1.tcn1.branches.3.0.weight', 'text_encoder.ln_final.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l10.vit1.attn.kv.weight', 'hyperformer_model.l1.residual.conv.bias', 'image_encoder.transformer.resblocks.2.ln_2.weight', 'hyperformer_model.l7.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l8.vit1.pe_proj.weight', 'hyperformer_model.l4.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l9.vit1.norm1.bias', 'hyperformer_model.l10.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'hyperformer_model.l4.tcn1.branches.1.3.conv.weight', 'clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'hyperformer_model.l2.tcn1.branches.2.4.weight', 'hyperformer_model.l10.tcn1.branches.1.1.weight', 'hyperformer_model.l7.tcn1.branches.2.0.bias', 'text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'text_encoder.transformer.resblocks.9.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l10.vit1.attn.rpe', 'hyperformer_model.l3.tcn1.branches.1.0.bias', 'text_encoder.positional_embedding', 'clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'hyperformer_model.l1.tcn1.branches.1.3.bn.bias', 'text_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l1.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l8.tcn1.branches.3.1.bias', 'hyperformer_model.l7.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.6.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l3.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l4.vit1.norm1.bias', 'hyperformer_model.l3.tcn1.branches.2.1.bias', 'text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'image_encoder.transformer.resblocks.6.ln_1.bias', 'text_encoder.transformer.resblocks.10.ln_1.weight', 'text_encoder.transformer.resblocks.4.ln_1.bias', 'image_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l8.residual.conv.bias', 'text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'hyperformer_model.data_bn.bias', 'image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'hyperformer_model.l4.vit1.attn.q.weight', 'text_encoder.transformer.resblocks.11.ln_2.bias', 'hyperformer_model.l8.tcn1.branches.2.0.bias', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'hyperformer_model.l8.vit1.attn.rpe', 'hyperformer_model.l1.tcn1.branches.2.0.weight', 'hyperformer_model.l1.vit1.skip_proj.weight', 'hyperformer_model.l10.tcn1.branches.3.1.weight', 'hyperformer_model.l2.tcn1.branches.2.0.bias', 'text_encoder.transformer.resblocks.4.ln_2.bias', 'text_encoder.transformer.resblocks.5.ln_1.bias', 'text_encoder.transformer.resblocks.7.ln_1.weight', 'hyperformer_model.l6.tcn1.branches.0.0.weight', 'hyperformer_model.l8.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'hyperformer_model.l8.tcn1.branches.2.0.weight', 'hyperformer_model.l7.vit1.norm1.weight', 'hyperformer_model.l6.vit1.pe_proj.weight', 'text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'hyperformer_model.l2.tcn1.branches.0.3.bn.weight', 'image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'image_encoder.transformer.resblocks.8.ln_2.weight', 'hyperformer_model.l3.tcn1.branches.0.3.conv.weight', 'image_encoder.transformer.resblocks.2.ln_2.bias', 'hyperformer_model.l7.vit1.pe_proj.weight', 'clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l1.tcn1.branches.1.1.weight', 'hyperformer_model.l5.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l2.vit1.attn.kv.weight', 'text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'hyperformer_model.l4.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'text_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l10.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'hyperformer_model.l1.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l5.tcn1.branches.2.1.bias', 'hyperformer_model.l8.residual.bn.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'hyperformer_model.l4.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.9.ln_2.bias', 'text_encoder.transformer.resblocks.6.ln_2.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.3.0.weight', 'hyperformer_model.l2.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'hyperformer_model.l8.residual.conv.weight', 'image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l6.vit1.attn.proj.bias', 'hyperformer_model.l9.tcn1.branches.3.1.weight', 'hyperformer_model.l10.vit1.norm1.weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.9.ln_1.weight', 'hyperformer_model.l5.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'hyperformer_model.l3.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.1.ln_2.weight', 'text_encoder.transformer.resblocks.4.ln_2.weight', 'hyperformer_model.l7.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l4.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l10.vit1.norm1.bias', 'image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'hyperformer_model.l3.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.4.ln_1.weight', 'hyperformer_model.l2.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'hyperformer_model.l7.tcn1.branches.0.1.weight', 'hyperformer_model.l9.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.10.ln_2.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'text_encoder.transformer.resblocks.10.ln_2.weight', 'hyperformer_model.l4.tcn1.branches.0.1.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.8.ln_1.weight', 'hyperformer_model.l5.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.1.ln_2.bias', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'hyperformer_model.l7.tcn1.branches.3.0.weight', 'hyperformer_model.l9.tcn1.branches.3.1.bias', 'hyperformer_model.l2.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l8.tcn1.branches.2.1.bias', 'hyperformer_model.l8.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l10.tcn1.branches.0.3.bn.weight', 'image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'hyperformer_model.l2.vit1.norm1.bias', 'image_encoder.ln_post.bias', 'hyperformer_model.l4.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'text_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l8.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l8.vit1.attn.kv.weight', 'hyperformer_model.l1.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'hyperformer_model.l7.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.0.ln_2.bias', 'hyperformer_model.l3.tcn1.branches.0.0.bias', 'hyperformer_model.l10.tcn1.branches.0.0.bias', 'image_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.l3.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l2.vit1.attn.proj.bias', 'hyperformer_model.l4.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'hyperformer_model.l9.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l5.tcn1.branches.3.0.weight', 'hyperformer_model.l1.vit1.norm1.bias', 'text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'hyperformer_model.l9.tcn1.branches.0.0.weight', 'hyperformer_model.l5.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l9.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'image_encoder.transformer.resblocks.11.ln_1.weight', 'image_encoder.transformer.resblocks.11.ln_2.bias', 'text_encoder.transformer.resblocks.8.ln_1.weight', 'image_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.l9.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l9.tcn1.branches.2.1.bias', 'hyperformer_model.l4.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l1.vit1.pe_proj.weight', 'hyperformer_model.l8.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l3.vit1.attn.q.weight', 'hyperformer_model.l6.vit1.attn.outer', 'image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'hyperformer_model.l9.vit1.attn.q.weight', 'hyperformer_model.l5.tcn1.branches.2.0.weight', 'text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'hyperformer_model.l3.vit1.attn.kv.weight', 'hyperformer_model.l5.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l6.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.2.4.bias', 'hyperformer_model.l6.vit1.attn.proj.weight', 'hyperformer_model.l8.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'image_encoder.transformer.resblocks.4.ln_1.bias', 'image_encoder.transformer.resblocks.3.ln_2.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'hyperformer_model.l5.residual.bn.bias', 'hyperformer_model.l1.vit1.attn.outer', 'hyperformer_model.l10.tcn1.branches.0.1.weight', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'text_encoder.transformer.resblocks.5.ln_2.bias', 'hyperformer_model.l3.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'hyperformer_model.l5.vit1.attn.kv.weight', 'hyperformer_model.l9.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.3.0.bias', 'hyperformer_model.l4.tcn1.branches.0.1.bias', 'hyperformer_model.l2.tcn1.branches.3.0.bias', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'hyperformer_model.l2.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l7.tcn1.branches.2.4.weight', 'hyperformer_model.l9.vit1.norm1.weight', 'hyperformer_model.l10.tcn1.branches.2.0.bias', 'hyperformer_model.l9.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.0.ln_2.bias', 'image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'hyperformer_model.l3.vit1.attn.alpha', 'hyperformer_model.l5.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l8.tcn1.branches.3.1.weight', 'hyperformer_model.l5.vit1.attn.proj.weight', 'hyperformer_model.l5.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.8.ln_2.bias', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.ln_1.weight', 'image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.1.1.bias', 'hyperformer_model.l9.vit1.attn.proj.weight', 'hyperformer_model.l6.tcn1.branches.2.1.weight', 'hyperformer_model.l4.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l7.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'hyperformer_model.l4.tcn1.branches.1.0.weight', 'hyperformer_model.l5.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l5.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l4.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l9.tcn1.branches.3.0.weight', 'clip_text_encoder.positional_embedding', 'hyperformer_model.l9.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'hyperformer_model.l6.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.11.ln_1.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l6.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.5.ln_2.weight', 'text_encoder.transformer.resblocks.6.ln_1.bias', 'hyperformer_model.l6.tcn1.branches.0.1.bias', 'hyperformer_model.l2.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.9.ln_2.weight', 'hyperformer_model.l1.residual.bn.weight', 'image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.l2.vit1.attn.w1', 'hyperformer_model.l8.tcn1.branches.1.1.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l5.residual.bn.weight', 'image_encoder.transformer.resblocks.10.ln_1.weight', 'hyperformer_model.l9.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.3.ln_2.bias', 'hyperformer_model.l3.tcn1.branches.2.0.bias', 'image_encoder.proj', 'image_encoder.transformer.resblocks.7.ln_1.bias', 'text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l1.vit1.attn.rpe', 'hyperformer_model.l3.tcn1.branches.3.0.bias', 'hyperformer_model.l7.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'hyperformer_model.l7.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.3.ln_1.weight', 'image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'hyperformer_model.l8.tcn1.branches.1.3.bn.bias', 'text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.2.ln_2.weight', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'text_encoder.transformer.resblocks.9.ln_1.weight', 'clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'hyperformer_model.l7.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l9.vit1.pe_proj.weight', 'hyperformer_model.l9.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'hyperformer_model.l2.tcn1.branches.2.0.weight', 'hyperformer_model.l9.vit1.attn.alpha', 'clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.2.4.weight', 'hyperformer_model.l7.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'hyperformer_model.l7.vit1.attn.rpe', 'text_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l5.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l1.tcn1.branches.2.4.weight', 'hyperformer_model.l6.tcn1.branches.1.1.bias', 'hyperformer_model.l1.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'hyperformer_model.l3.vit1.attn.w1', 'hyperformer_model.l10.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l2.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l7.tcn1.branches.2.0.weight', 'text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l3.vit1.attn.rpe', 'image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l9.tcn1.branches.0.1.bias', 'text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'hyperformer_model.l2.tcn1.branches.3.1.weight'}
[2024-12-24 21:40:12 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 316): INFO Total learnable items: 835
[2024-12-24 21:40:13 ViT-B/16] (tools.py 147): INFO ==============> Resuming from ./workdirs/TEST_P1_SKeletonCLIP_alltrn_HFinit_zs_48_17Dec24/ckpt_epoch_0.pth....................
[2024-12-24 21:40:14 ViT-B/16] (tools.py 172): INFO resume VIFICLIP model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.clip_text_encoder.positional_embedding', 'module.clip_text_encoder.text_projection', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'module.clip_text_encoder.ln_final.weight', 'module.clip_text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:40:14 ViT-B/16] (tools.py 176): INFO ==============> Resuming from /data/users/asinha13/projects/CLIP4ADL/model_chkpnts/ntu_CS_P1_HF_pretrain_frzn_txt_zs_48_AS_16Jan24/ckpt_epoch_99.pth....................
[2024-12-24 21:40:14 ViT-B/16] (tools.py 218): INFO resume Hyperformer model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.text_encoder.positional_embedding', 'module.text_encoder.text_projection', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_1.weight', 'module.text_encoder.transformer.resblocks.0.ln_1.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_2.weight', 'module.text_encoder.transformer.resblocks.0.ln_2.bias', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_1.weight', 'module.text_encoder.transformer.resblocks.1.ln_1.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_2.weight', 'module.text_encoder.transformer.resblocks.1.ln_2.bias', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_1.weight', 'module.text_encoder.transformer.resblocks.2.ln_1.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_2.weight', 'module.text_encoder.transformer.resblocks.2.ln_2.bias', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_1.weight', 'module.text_encoder.transformer.resblocks.3.ln_1.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_2.weight', 'module.text_encoder.transformer.resblocks.3.ln_2.bias', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_1.weight', 'module.text_encoder.transformer.resblocks.4.ln_1.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_2.weight', 'module.text_encoder.transformer.resblocks.4.ln_2.bias', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_1.weight', 'module.text_encoder.transformer.resblocks.5.ln_1.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_2.weight', 'module.text_encoder.transformer.resblocks.5.ln_2.bias', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_1.weight', 'module.text_encoder.transformer.resblocks.6.ln_1.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_2.weight', 'module.text_encoder.transformer.resblocks.6.ln_2.bias', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_1.weight', 'module.text_encoder.transformer.resblocks.7.ln_1.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_2.weight', 'module.text_encoder.transformer.resblocks.7.ln_2.bias', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_1.weight', 'module.text_encoder.transformer.resblocks.8.ln_1.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_2.weight', 'module.text_encoder.transformer.resblocks.8.ln_2.bias', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_1.weight', 'module.text_encoder.transformer.resblocks.9.ln_1.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_2.weight', 'module.text_encoder.transformer.resblocks.9.ln_2.bias', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_1.weight', 'module.text_encoder.transformer.resblocks.10.ln_1.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_2.weight', 'module.text_encoder.transformer.resblocks.10.ln_2.bias', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_1.weight', 'module.text_encoder.transformer.resblocks.11.ln_1.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_2.weight', 'module.text_encoder.transformer.resblocks.11.ln_2.bias', 'module.text_encoder.ln_final.weight', 'module.text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:40:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][0/11317]	eta 17:32:32 lr 0.000022000	time 5.5803 (5.5803)	dist_loss 0.4876 (0.4876)	image_text_loss 3.9011 (3.9011)	pose_text_loss 2.4215 (2.4215)	tot_loss 11.1982 (11.1982)	mem 29650MB
[2024-12-24 21:40:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][50/11317]	eta 1:26:46 lr 0.000021999	time 0.3752 (0.4621)	dist_loss 0.0086 (0.1625)	image_text_loss 3.8125 (3.8737)	pose_text_loss 3.5781 (3.6808)	tot_loss 7.4762 (9.1796)	mem 29650MB
[2024-12-24 21:40:56 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][100/11317]	eta 1:17:53 lr 0.000021996	time 0.3793 (0.4166)	dist_loss 0.0096 (0.0878)	image_text_loss 4.0038 (3.8690)	pose_text_loss 3.8541 (3.7097)	tot_loss 7.9543 (8.4570)	mem 29650MB
[2024-12-24 21:41:14 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][150/11317]	eta 1:14:26 lr 0.000021991	time 0.3790 (0.3999)	dist_loss 0.0090 (0.0637)	image_text_loss 3.8623 (3.8744)	pose_text_loss 3.8018 (3.7138)	tot_loss 7.7541 (8.2253)	mem 29650MB
[2024-12-24 21:41:32 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][200/11317]	eta 1:12:26 lr 0.000021983	time 0.3401 (0.3910)	dist_loss 0.0201 (0.0522)	image_text_loss 3.7221 (3.8760)	pose_text_loss 3.3205 (3.6961)	tot_loss 7.2434 (8.0945)	mem 29650MB
[2024-12-24 21:41:50 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][250/11317]	eta 1:10:47 lr 0.000021974	time 0.3566 (0.3838)	dist_loss 0.0246 (0.0455)	image_text_loss 3.7132 (3.8738)	pose_text_loss 3.4114 (3.6744)	tot_loss 7.3704 (8.0032)	mem 29650MB
[2024-12-24 21:42:08 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][300/11317]	eta 1:09:37 lr 0.000021962	time 0.3574 (0.3792)	dist_loss 0.0053 (0.0415)	image_text_loss 3.8549 (3.8770)	pose_text_loss 3.8216 (3.6648)	tot_loss 7.7299 (7.9565)	mem 29650MB
[2024-12-24 21:42:26 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][350/11317]	eta 1:08:45 lr 0.000021949	time 0.3651 (0.3762)	dist_loss 0.0150 (0.0378)	image_text_loss 3.9472 (3.8792)	pose_text_loss 3.7390 (3.6614)	tot_loss 7.8363 (7.9186)	mem 29650MB
