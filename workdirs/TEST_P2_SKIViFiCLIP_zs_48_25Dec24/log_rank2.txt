[2024-12-24 21:35:50 ViT-B/16] (CL_main_v2.py 442): INFO working dir: ./workdirs/TEST_P2_SKIViFiCLIP_zs_48_25Dec24/
[2024-12-24 21:36:05 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 261): INFO Loading CLIP (backbone: ViT-B/16)
[2024-12-24 21:36:09 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 265): INFO Building Model
[2024-12-24 21:36:09 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 282): INFO Turning on gradients for COMPLETE SKI_VLM model
[2024-12-24 21:36:09 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 315): INFO Parameters to be updated: {'text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'clip_text_encoder.ln_final.bias', 'hyperformer_model.l8.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.8.ln_2.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.11.ln_1.weight', 'hyperformer_model.l5.tcn1.branches.0.3.conv.bias', 'hyperformer_model.data_bn.bias', 'hyperformer_model.l7.vit1.attn.proj.bias', 'hyperformer_model.l5.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l9.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'hyperformer_model.l1.vit1.norm1.bias', 'hyperformer_model.l6.vit1.attn.w1', 'hyperformer_model.l4.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'hyperformer_model.l1.tcn1.branches.2.1.bias', 'hyperformer_model.l5.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'hyperformer_model.l3.vit1.attn.w1', 'hyperformer_model.l8.tcn1.branches.2.0.bias', 'clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'hyperformer_model.l4.vit1.attn.outer', 'text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'hyperformer_model.l5.vit1.attn.w1', 'text_encoder.transformer.resblocks.3.ln_2.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'hyperformer_model.l5.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l8.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l8.tcn1.branches.2.0.weight', 'hyperformer_model.l9.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l6.vit1.attn.outer', 'text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.7.ln_1.bias', 'image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.9.ln_2.bias', 'hyperformer_model.l4.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'hyperformer_model.l4.vit1.attn.proj.bias', 'hyperformer_model.l5.tcn1.branches.2.0.weight', 'hyperformer_model.l3.vit1.pe_proj.weight', 'hyperformer_model.l1.vit1.attn.q.weight', 'hyperformer_model.l6.tcn1.branches.1.3.conv.weight', 'clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.l8.tcn1.branches.1.1.bias', 'hyperformer_model.l6.tcn1.branches.1.3.bn.weight', 'image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'hyperformer_model.l1.vit1.attn.w1', 'image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'hyperformer_model.l9.vit1.attn.outer', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'hyperformer_model.l3.tcn1.branches.1.1.weight', 'hyperformer_model.l9.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'hyperformer_model.l1.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.5.ln_1.weight', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'hyperformer_model.l3.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.7.ln_1.bias', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'hyperformer_model.l8.residual.bn.bias', 'hyperformer_model.l1.tcn1.branches.1.1.weight', 'hyperformer_model.l3.tcn1.branches.0.3.bn.weight', 'hyperformer_model.data_bn.weight', 'hyperformer_model.l5.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l6.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l3.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'hyperformer_model.l3.tcn1.branches.2.0.bias', 'image_encoder.transformer.resblocks.3.ln_1.weight', 'hyperformer_model.l7.tcn1.branches.0.1.bias', 'hyperformer_model.l8.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.9.ln_2.weight', 'hyperformer_model.l7.vit1.norm1.weight', 'hyperformer_model.l9.vit1.attn.rpe', 'image_encoder.transformer.resblocks.0.ln_2.bias', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'text_encoder.ln_final.bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'image_encoder.transformer.resblocks.10.ln_2.weight', 'text_encoder.transformer.resblocks.10.ln_1.weight', 'image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.0.ln_2.weight', 'image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.6.ln_2.weight', 'clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'hyperformer_model.l9.vit1.attn.proj.weight', 'hyperformer_model.l10.tcn1.branches.2.0.bias', 'hyperformer_model.l2.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'hyperformer_model.l9.vit1.attn.alpha', 'hyperformer_model.l2.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l2.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l2.tcn1.branches.3.1.weight', 'hyperformer_model.l5.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.4.ln_1.weight', 'text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'hyperformer_model.l1.vit1.skip_proj.weight', 'hyperformer_model.l10.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'hyperformer_model.l4.tcn1.branches.1.1.bias', 'image_encoder.positional_embedding', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'image_encoder.transformer.resblocks.3.ln_1.bias', 'text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'hyperformer_model.l4.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.2.ln_1.weight', 'image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'hyperformer_model.l4.vit1.attn.alpha', 'hyperformer_model.l10.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l7.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l9.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.1.1.weight', 'hyperformer_model.l6.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'hyperformer_model.l2.vit1.attn.q.weight', 'hyperformer_model.l5.vit1.attn.alpha', 'hyperformer_model.l6.vit1.attn.alpha', 'image_encoder.transformer.resblocks.3.ln_2.bias', 'image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'hyperformer_model.l8.residual.conv.bias', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'text_encoder.transformer.resblocks.7.ln_1.weight', 'image_encoder.transformer.resblocks.7.ln_2.weight', 'image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'image_encoder.transformer.resblocks.10.ln_2.bias', 'hyperformer_model.l7.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.0.ln_2.bias', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'hyperformer_model.l2.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'hyperformer_model.l8.tcn1.branches.0.1.weight', 'hyperformer_model.l8.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l4.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'hyperformer_model.l3.tcn1.branches.0.0.weight', 'image_encoder.proj', 'hyperformer_model.l10.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l8.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.1.3.conv.weight', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'hyperformer_model.l6.vit1.attn.kv.weight', 'hyperformer_model.l1.residual.bn.weight', 'hyperformer_model.l1.tcn1.branches.2.0.bias', 'text_encoder.transformer.resblocks.1.ln_2.weight', 'image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l6.tcn1.branches.2.0.bias', 'hyperformer_model.l5.vit1.attn.proj.weight', 'image_encoder.transformer.resblocks.8.ln_1.weight', 'text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'hyperformer_model.l9.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.3.0.bias', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'hyperformer_model.l5.vit1.norm1.bias', 'image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'hyperformer_model.l9.tcn1.branches.2.4.bias', 'hyperformer_model.l7.tcn1.branches.2.1.weight', 'image_encoder.ln_pre.bias', 'image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'hyperformer_model.l1.vit1.attn.proj.weight', 'hyperformer_model.l2.tcn1.branches.3.0.weight', 'hyperformer_model.l3.tcn1.branches.3.0.weight', 'hyperformer_model.l4.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l7.tcn1.branches.2.4.weight', 'hyperformer_model.l7.vit1.pe_proj.weight', 'hyperformer_model.l3.vit1.attn.rpe', 'hyperformer_model.l2.vit1.attn.outer', 'text_encoder.transformer.resblocks.5.ln_2.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'hyperformer_model.l8.vit1.pe_proj.weight', 'image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'hyperformer_model.l9.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'hyperformer_model.l10.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'text_encoder.transformer.resblocks.6.ln_2.bias', 'hyperformer_model.l9.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'hyperformer_model.l7.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.3.0.bias', 'hyperformer_model.l3.vit1.norm1.weight', 'text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.11.ln_1.bias', 'text_encoder.transformer.resblocks.11.ln_1.bias', 'clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l9.tcn1.branches.1.1.bias', 'hyperformer_model.l4.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l6.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l8.vit1.attn.proj.weight', 'text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'text_encoder.transformer.resblocks.11.ln_2.weight', 'image_encoder.ln_post.weight', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'hyperformer_model.l3.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'text_encoder.ln_final.weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'hyperformer_model.l8.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l4.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'hyperformer_model.l3.tcn1.branches.2.1.weight', 'hyperformer_model.l4.tcn1.branches.2.0.bias', 'text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'hyperformer_model.l7.vit1.attn.outer', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'hyperformer_model.l3.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'hyperformer_model.l2.tcn1.branches.2.4.bias', 'hyperformer_model.l4.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'hyperformer_model.l9.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'hyperformer_model.l5.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'hyperformer_model.l4.tcn1.branches.2.4.bias', 'hyperformer_model.l10.tcn1.branches.3.0.bias', 'hyperformer_model.l3.tcn1.branches.0.1.weight', 'hyperformer_model.l10.tcn1.branches.0.1.weight', 'hyperformer_model.l6.tcn1.branches.3.1.bias', 'hyperformer_model.l7.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l5.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'hyperformer_model.l1.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'hyperformer_model.l7.vit1.attn.alpha', 'hyperformer_model.l8.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'hyperformer_model.l9.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'hyperformer_model.l6.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.10.ln_1.weight', 'clip_text_encoder.ln_final.weight', 'clip_text_encoder.text_projection', 'hyperformer_model.l8.vit1.attn.rpe', 'text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'hyperformer_model.l6.tcn1.branches.1.1.bias', 'hyperformer_model.l8.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l6.tcn1.branches.1.0.weight', 'hyperformer_model.l1.tcn1.branches.2.4.bias', 'hyperformer_model.l9.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.5.ln_2.weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'hyperformer_model.l10.vit1.attn.kv.weight', 'hyperformer_model.l1.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'text_encoder.transformer.resblocks.8.ln_1.weight', 'text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'hyperformer_model.l2.vit1.pe_proj.weight', 'hyperformer_model.l4.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l7.tcn1.branches.3.1.bias', 'hyperformer_model.l8.tcn1.branches.1.1.weight', 'hyperformer_model.l5.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l2.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l9.tcn1.branches.1.1.weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'hyperformer_model.l2.vit1.norm1.bias', 'text_encoder.transformer.resblocks.10.ln_2.bias', 'hyperformer_model.l10.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'hyperformer_model.l2.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l8.vit1.attn.kv.weight', 'hyperformer_model.l8.tcn1.branches.3.0.bias', 'hyperformer_model.l9.tcn1.branches.2.1.bias', 'text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'hyperformer_model.l1.vit1.norm1.weight', 'hyperformer_model.l1.tcn1.branches.3.1.weight', 'hyperformer_model.l10.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'hyperformer_model.l10.vit1.attn.alpha', 'hyperformer_model.l3.tcn1.branches.1.3.bn.weight', 'text_encoder.transformer.resblocks.0.ln_1.bias', 'text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'text_encoder.transformer.resblocks.2.ln_2.weight', 'image_encoder.transformer.resblocks.8.ln_2.bias', 'clip_text_encoder.positional_embedding', 'hyperformer_model.l5.tcn1.branches.2.0.bias', 'text_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l3.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'image_encoder.ln_post.bias', 'image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'hyperformer_model.l9.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'hyperformer_model.l7.tcn1.branches.2.4.bias', 'hyperformer_model.l10.vit1.attn.q.weight', 'hyperformer_model.l5.residual.conv.weight', 'text_encoder.transformer.resblocks.9.ln_1.weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'hyperformer_model.l1.residual.conv.bias', 'text_encoder.transformer.resblocks.2.ln_2.bias', 'image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.7.ln_2.bias', 'hyperformer_model.l8.vit1.norm1.weight', 'image_encoder.transformer.resblocks.1.ln_1.bias', 'text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'text_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l1.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.ln_2.weight', 'hyperformer_model.l2.vit1.attn.alpha', 'text_encoder.transformer.resblocks.3.ln_1.bias', 'image_encoder.ln_pre.weight', 'image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'hyperformer_model.l10.tcn1.branches.2.0.weight', 'hyperformer_model.l1.vit1.attn.outer', 'image_encoder.conv1.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'hyperformer_model.l8.tcn1.branches.1.0.bias', 'hyperformer_model.l1.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'image_encoder.transformer.resblocks.1.ln_2.weight', 'image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'image_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l6.vit1.norm1.bias', 'text_encoder.transformer.resblocks.8.ln_2.weight', 'hyperformer_model.l3.tcn1.branches.2.4.weight', 'hyperformer_model.l7.tcn1.branches.0.1.weight', 'clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'hyperformer_model.l2.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.l4.vit1.norm1.weight', 'hyperformer_model.l6.tcn1.branches.3.1.weight', 'hyperformer_model.l5.residual.bn.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'hyperformer_model.l1.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'hyperformer_model.l4.tcn1.branches.3.1.bias', 'hyperformer_model.l6.tcn1.branches.2.1.weight', 'hyperformer_model.l6.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'hyperformer_model.l5.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.4.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.3.0.weight', 'hyperformer_model.l7.tcn1.branches.1.0.weight', 'hyperformer_model.l8.vit1.norm1.bias', 'text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l6.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l5.tcn1.branches.3.1.bias', 'text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l1.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.1.ln_1.weight', 'hyperformer_model.l6.tcn1.branches.3.0.bias', 'hyperformer_model.l10.vit1.attn.outer', 'hyperformer_model.l7.tcn1.branches.1.0.bias', 'hyperformer_model.l2.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l4.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'hyperformer_model.l5.vit1.attn.outer', 'hyperformer_model.l10.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.4.ln_2.weight', 'image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.11.ln_2.bias', 'text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'hyperformer_model.l6.vit1.norm1.weight', 'image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'hyperformer_model.l5.vit1.attn.kv.weight', 'hyperformer_model.l9.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'text_encoder.transformer.resblocks.3.ln_2.bias', 'image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'hyperformer_model.l9.vit1.pe_proj.weight', 'text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'hyperformer_model.l7.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l2.tcn1.branches.1.1.weight', 'hyperformer_model.l8.tcn1.branches.0.0.weight', 'hyperformer_model.l1.vit1.attn.alpha', 'hyperformer_model.l10.vit1.attn.proj.weight', 'hyperformer_model.l4.vit1.attn.q.weight', 'text_encoder.transformer.resblocks.6.ln_1.bias', 'hyperformer_model.l6.vit1.attn.rpe', 'hyperformer_model.l10.tcn1.branches.3.1.weight', 'clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'hyperformer_model.l5.tcn1.branches.3.0.weight', 'hyperformer_model.l3.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l8.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'hyperformer_model.l8.vit1.attn.alpha', 'hyperformer_model.l2.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'hyperformer_model.l2.vit1.attn.proj.weight', 'hyperformer_model.l10.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'hyperformer_model.l2.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'hyperformer_model.l9.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.5.ln_2.bias', 'text_encoder.transformer.resblocks.11.ln_2.bias', 'hyperformer_model.l2.tcn1.branches.3.0.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l10.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.0.ln_1.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'image_encoder.transformer.resblocks.4.ln_1.bias', 'hyperformer_model.l7.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.l3.vit1.attn.kv.weight', 'hyperformer_model.l7.tcn1.branches.0.0.bias', 'hyperformer_model.l4.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l10.tcn1.branches.1.1.bias', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l9.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'hyperformer_model.l4.tcn1.branches.3.0.weight', 'hyperformer_model.l8.residual.bn.weight', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'text_encoder.text_projection', 'image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l9.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l7.tcn1.branches.3.0.bias', 'hyperformer_model.l1.tcn1.branches.1.0.weight', 'hyperformer_model.l8.vit1.attn.proj.bias', 'hyperformer_model.l6.tcn1.branches.1.0.bias', 'hyperformer_model.l7.vit1.attn.w1', 'text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.0.0.bias', 'hyperformer_model.l8.tcn1.branches.1.0.weight', 'hyperformer_model.l7.vit1.attn.proj.weight', 'hyperformer_model.l10.tcn1.branches.0.3.conv.bias', 'clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l10.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l6.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'hyperformer_model.l6.vit1.pe_proj.weight', 'hyperformer_model.l2.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.7.ln_2.bias', 'hyperformer_model.l2.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l2.tcn1.branches.0.0.weight', 'hyperformer_model.l7.tcn1.branches.2.1.bias', 'hyperformer_model.l9.vit1.attn.w1', 'hyperformer_model.l6.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'image_encoder.transformer.resblocks.11.ln_1.weight', 'hyperformer_model.l4.vit1.pe_proj.weight', 'hyperformer_model.l3.vit1.attn.q.weight', 'hyperformer_model.l7.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'hyperformer_model.l5.tcn1.branches.0.1.weight', 'hyperformer_model.l1.tcn1.branches.2.0.weight', 'text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'text_encoder.transformer.resblocks.3.ln_1.weight', 'hyperformer_model.l7.tcn1.branches.2.0.bias', 'hyperformer_model.l1.tcn1.branches.0.3.conv.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'image_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l3.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.2.ln_1.bias', 'image_encoder.transformer.resblocks.9.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.2.4.weight', 'hyperformer_model.l8.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'text_encoder.transformer.resblocks.7.ln_2.weight', 'image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.4.ln_2.weight', 'image_encoder.transformer.resblocks.2.ln_2.bias', 'hyperformer_model.l7.tcn1.branches.1.1.bias', 'hyperformer_model.l8.tcn1.branches.2.4.weight', 'hyperformer_model.l3.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.5.ln_1.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'hyperformer_model.l7.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'text_encoder.transformer.resblocks.4.ln_1.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.1.ln_2.bias', 'clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l2.tcn1.branches.2.0.bias', 'image_encoder.class_embedding', 'hyperformer_model.l6.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'hyperformer_model.l6.tcn1.branches.2.4.bias', 'hyperformer_model.l10.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'hyperformer_model.l5.tcn1.branches.1.1.bias', 'hyperformer_model.l8.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'hyperformer_model.l4.vit1.norm1.bias', 'hyperformer_model.l5.tcn1.branches.0.0.weight', 'hyperformer_model.l10.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'hyperformer_model.l9.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.6.ln_1.bias', 'hyperformer_model.l1.tcn1.branches.1.3.bn.weight', 'image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l1.vit1.pe_proj.weight', 'image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'hyperformer_model.l10.tcn1.branches.3.1.bias', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'hyperformer_model.l5.vit1.pe_proj.weight', 'hyperformer_model.l1.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'hyperformer_model.l3.vit1.attn.outer', 'hyperformer_model.l4.vit1.attn.proj.weight', 'hyperformer_model.l9.tcn1.branches.3.1.bias', 'hyperformer_model.l3.tcn1.branches.1.0.weight', 'hyperformer_model.l2.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l3.tcn1.branches.3.1.weight', 'hyperformer_model.l3.tcn1.branches.2.0.weight', 'hyperformer_model.l4.tcn1.branches.0.1.weight', 'hyperformer_model.l4.tcn1.branches.2.1.bias', 'text_encoder.transformer.resblocks.4.ln_1.bias', 'image_encoder.transformer.resblocks.7.ln_1.weight', 'hyperformer_model.l5.vit1.attn.proj.bias', 'hyperformer_model.l4.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.3.0.bias', 'hyperformer_model.l1.residual.conv.weight', 'hyperformer_model.l1.tcn1.branches.0.0.weight', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'hyperformer_model.l10.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l1.tcn1.branches.3.0.weight', 'image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l3.vit1.attn.alpha', 'text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'hyperformer_model.l2.tcn1.branches.1.1.bias', 'hyperformer_model.l3.vit1.attn.proj.weight', 'hyperformer_model.l7.tcn1.branches.1.1.weight', 'hyperformer_model.l7.tcn1.branches.3.1.weight', 'hyperformer_model.l1.residual.bn.bias', 'text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l2.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'hyperformer_model.l6.tcn1.branches.0.1.bias', 'hyperformer_model.l2.vit1.norm1.weight', 'text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'hyperformer_model.l2.tcn1.branches.0.1.weight', 'image_encoder.transformer.resblocks.9.ln_2.weight', 'text_encoder.positional_embedding', 'text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'hyperformer_model.l3.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l6.tcn1.branches.1.1.weight', 'hyperformer_model.l9.tcn1.branches.2.0.weight', 'hyperformer_model.l2.tcn1.branches.2.4.weight', 'hyperformer_model.l2.tcn1.branches.2.0.weight', 'text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'hyperformer_model.l1.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l9.tcn1.branches.3.0.weight', 'image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'hyperformer_model.l5.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'hyperformer_model.l6.tcn1.branches.0.3.bn.bias', 'image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l3.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'hyperformer_model.l8.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l1.tcn1.branches.3.1.bias', 'hyperformer_model.l1.tcn1.branches.0.1.weight', 'image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'hyperformer_model.l1.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'text_encoder.transformer.resblocks.9.ln_1.bias', 'text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'text_encoder.transformer.resblocks.2.ln_1.weight', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'hyperformer_model.l7.vit1.attn.kv.weight', 'hyperformer_model.fc2.bias', 'text_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l8.residual.conv.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'hyperformer_model.l6.vit1.attn.proj.weight', 'hyperformer_model.l10.vit1.attn.rpe', 'hyperformer_model.l7.vit1.norm1.bias', 'text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'hyperformer_model.l8.vit1.attn.outer', 'text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.l4.vit1.attn.rpe', 'hyperformer_model.l9.vit1.norm1.bias', 'image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'image_encoder.transformer.resblocks.4.ln_2.bias', 'hyperformer_model.l2.tcn1.branches.1.0.weight', 'hyperformer_model.l5.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'hyperformer_model.l9.tcn1.branches.2.0.bias', 'image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'hyperformer_model.l7.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'hyperformer_model.l3.vit1.attn.proj.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l3.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.fc2.weight', 'text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'hyperformer_model.l8.vit1.attn.w1', 'hyperformer_model.l3.tcn1.branches.0.1.bias', 'hyperformer_model.l10.vit1.pe_proj.weight', 'hyperformer_model.l7.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l4.tcn1.branches.3.1.weight', 'hyperformer_model.l6.tcn1.branches.0.0.bias', 'hyperformer_model.l1.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'hyperformer_model.l9.vit1.norm1.weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'hyperformer_model.l2.tcn1.branches.2.1.bias', 'hyperformer_model.l8.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l9.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'hyperformer_model.l10.vit1.attn.w1', 'image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'hyperformer_model.l4.tcn1.branches.1.0.weight', 'hyperformer_model.l10.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l1.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'hyperformer_model.l3.tcn1.branches.1.1.bias', 'hyperformer_model.l4.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l5.residual.conv.bias', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'image_encoder.transformer.resblocks.9.ln_2.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l6.tcn1.branches.2.0.weight', 'hyperformer_model.l9.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'hyperformer_model.l8.tcn1.branches.2.4.bias', 'hyperformer_model.l3.vit1.norm1.bias', 'hyperformer_model.l5.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l4.tcn1.branches.0.3.conv.bias', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'text_encoder.transformer.resblocks.5.ln_1.bias', 'hyperformer_model.l10.tcn1.branches.1.0.bias', 'hyperformer_model.l2.tcn1.branches.0.1.bias', 'text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'image_encoder.transformer.resblocks.6.ln_2.bias', 'clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'text_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l4.vit1.attn.w1', 'hyperformer_model.l4.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.1.ln_1.bias', 'text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'hyperformer_model.l10.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'hyperformer_model.l8.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'hyperformer_model.l2.vit1.attn.rpe', 'hyperformer_model.l8.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.1.0.bias', 'hyperformer_model.l3.tcn1.branches.3.1.bias', 'hyperformer_model.l9.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'hyperformer_model.l5.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.3.ln_2.weight', 'image_encoder.transformer.resblocks.9.ln_1.weight', 'text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'text_encoder.transformer.resblocks.10.ln_1.bias', 'image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'hyperformer_model.l5.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l10.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.5.ln_1.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'hyperformer_model.l7.tcn1.branches.0.3.conv.weight', 'image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'hyperformer_model.l4.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l5.residual.bn.bias', 'hyperformer_model.l2.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l5.tcn1.branches.2.1.weight', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'hyperformer_model.l6.vit1.attn.proj.bias', 'hyperformer_model.l6.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'hyperformer_model.l8.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.10.ln_2.weight', 'hyperformer_model.l10.tcn1.branches.2.1.weight', 'hyperformer_model.l10.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l9.tcn1.branches.0.1.weight', 'hyperformer_model.l1.tcn1.branches.2.1.weight'}
[2024-12-24 21:36:09 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 316): INFO Total learnable items: 835
[2024-12-24 21:36:30 ViT-B/16] (tools.py 147): INFO ==============> Resuming from ./workdirs/TEST_P1_SKeletonCLIP_alltrn_HFinit_zs_48_17Dec24/ckpt_epoch_0.pth....................
[2024-12-24 21:36:30 ViT-B/16] (tools.py 172): INFO resume VIFICLIP model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.clip_text_encoder.positional_embedding', 'module.clip_text_encoder.text_projection', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'module.clip_text_encoder.ln_final.weight', 'module.clip_text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:36:30 ViT-B/16] (tools.py 176): INFO ==============> Resuming from /data/users/asinha13/projects/CLIP4ADL/model_chkpnts/ntu_CS_P1_HF_pretrain_frzn_txt_zs_48_AS_16Jan24/ckpt_epoch_99.pth....................
[2024-12-24 21:36:31 ViT-B/16] (tools.py 218): INFO resume Hyperformer model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.text_encoder.positional_embedding', 'module.text_encoder.text_projection', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_1.weight', 'module.text_encoder.transformer.resblocks.0.ln_1.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_2.weight', 'module.text_encoder.transformer.resblocks.0.ln_2.bias', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_1.weight', 'module.text_encoder.transformer.resblocks.1.ln_1.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_2.weight', 'module.text_encoder.transformer.resblocks.1.ln_2.bias', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_1.weight', 'module.text_encoder.transformer.resblocks.2.ln_1.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_2.weight', 'module.text_encoder.transformer.resblocks.2.ln_2.bias', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_1.weight', 'module.text_encoder.transformer.resblocks.3.ln_1.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_2.weight', 'module.text_encoder.transformer.resblocks.3.ln_2.bias', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_1.weight', 'module.text_encoder.transformer.resblocks.4.ln_1.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_2.weight', 'module.text_encoder.transformer.resblocks.4.ln_2.bias', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_1.weight', 'module.text_encoder.transformer.resblocks.5.ln_1.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_2.weight', 'module.text_encoder.transformer.resblocks.5.ln_2.bias', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_1.weight', 'module.text_encoder.transformer.resblocks.6.ln_1.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_2.weight', 'module.text_encoder.transformer.resblocks.6.ln_2.bias', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_1.weight', 'module.text_encoder.transformer.resblocks.7.ln_1.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_2.weight', 'module.text_encoder.transformer.resblocks.7.ln_2.bias', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_1.weight', 'module.text_encoder.transformer.resblocks.8.ln_1.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_2.weight', 'module.text_encoder.transformer.resblocks.8.ln_2.bias', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_1.weight', 'module.text_encoder.transformer.resblocks.9.ln_1.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_2.weight', 'module.text_encoder.transformer.resblocks.9.ln_2.bias', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_1.weight', 'module.text_encoder.transformer.resblocks.10.ln_1.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_2.weight', 'module.text_encoder.transformer.resblocks.10.ln_2.bias', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_1.weight', 'module.text_encoder.transformer.resblocks.11.ln_1.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_2.weight', 'module.text_encoder.transformer.resblocks.11.ln_2.bias', 'module.text_encoder.ln_final.weight', 'module.text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:36:36 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][0/11317]	eta 16:32:19 lr 0.000022000	time 5.2611 (5.2611)	dist_loss 0.3983 (0.3983)	image_text_loss 3.9411 (3.9411)	pose_text_loss 2.3231 (2.3231)	tot_loss 10.2473 (10.2473)	mem 12001MB
[2024-12-24 21:36:53 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][50/11317]	eta 1:22:57 lr 0.000021999	time 0.3475 (0.4418)	dist_loss 0.0018 (0.1192)	image_text_loss 3.8977 (3.8713)	pose_text_loss 3.8711 (3.6868)	tot_loss 7.7868 (8.7498)	mem 12001MB
[2024-12-24 21:37:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][100/11317]	eta 1:14:25 lr 0.000021996	time 0.3565 (0.3981)	dist_loss 0.0149 (0.0669)	image_text_loss 3.7945 (3.8690)	pose_text_loss 3.5651 (3.7044)	tot_loss 7.5085 (8.2421)	mem 12001MB
[2024-12-24 21:38:19 ViT-B/16] (CL_main_v2.py 442): INFO working dir: ./workdirs/TEST_P2_SKIViFiCLIP_zs_48_25Dec24/
[2024-12-24 21:38:33 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 261): INFO Loading CLIP (backbone: ViT-B/16)
[2024-12-24 21:38:37 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 265): INFO Building Model
[2024-12-24 21:38:37 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 282): INFO Turning on gradients for COMPLETE SKI_VLM model
[2024-12-24 21:38:37 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 315): INFO Parameters to be updated: {'hyperformer_model.l6.tcn1.branches.1.1.weight', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'hyperformer_model.l3.vit1.pe_proj.weight', 'clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.l1.vit1.attn.alpha', 'image_encoder.transformer.resblocks.4.ln_2.weight', 'hyperformer_model.l6.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l8.vit1.pe_proj.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'hyperformer_model.l10.tcn1.branches.1.1.bias', 'hyperformer_model.l8.tcn1.branches.1.0.weight', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'hyperformer_model.l2.vit1.attn.q.weight', 'hyperformer_model.l2.tcn1.branches.3.0.weight', 'hyperformer_model.l1.residual.bn.weight', 'hyperformer_model.l5.tcn1.branches.2.4.bias', 'text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l2.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l2.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l6.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'text_encoder.transformer.resblocks.11.ln_1.weight', 'image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'hyperformer_model.l8.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l4.tcn1.branches.0.1.weight', 'hyperformer_model.l8.residual.conv.weight', 'image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l10.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l5.vit1.norm1.bias', 'hyperformer_model.l3.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l8.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.3.ln_2.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l4.tcn1.branches.0.0.bias', 'hyperformer_model.l9.vit1.pe_proj.weight', 'hyperformer_model.l10.tcn1.branches.1.3.conv.bias', 'image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'hyperformer_model.l10.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l1.tcn1.branches.1.3.conv.weight', 'clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'hyperformer_model.l2.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'hyperformer_model.l6.tcn1.branches.1.3.conv.bias', 'image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'hyperformer_model.l8.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l2.vit1.attn.proj.bias', 'text_encoder.transformer.resblocks.8.ln_2.weight', 'hyperformer_model.l4.tcn1.branches.3.0.bias', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l2.tcn1.branches.0.0.weight', 'hyperformer_model.l2.tcn1.branches.2.1.bias', 'hyperformer_model.l10.tcn1.branches.2.4.weight', 'hyperformer_model.l3.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'image_encoder.transformer.resblocks.4.ln_1.weight', 'text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'hyperformer_model.l6.vit1.norm1.weight', 'hyperformer_model.l7.tcn1.branches.1.1.weight', 'hyperformer_model.l7.tcn1.branches.2.1.weight', 'hyperformer_model.l8.tcn1.branches.1.1.weight', 'hyperformer_model.l6.vit1.attn.alpha', 'image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'hyperformer_model.l1.tcn1.branches.0.3.bn.bias', 'image_encoder.transformer.resblocks.3.ln_2.bias', 'text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'image_encoder.transformer.resblocks.6.ln_1.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.ln_post.weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'hyperformer_model.l5.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l10.tcn1.branches.3.1.weight', 'hyperformer_model.l2.tcn1.branches.2.4.weight', 'hyperformer_model.l9.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.10.ln_2.weight', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'hyperformer_model.l9.vit1.attn.alpha', 'hyperformer_model.l10.vit1.attn.alpha', 'image_encoder.transformer.resblocks.3.ln_2.weight', 'text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'hyperformer_model.l7.tcn1.branches.2.1.bias', 'hyperformer_model.l10.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'hyperformer_model.l2.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'image_encoder.transformer.resblocks.10.ln_2.bias', 'text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'hyperformer_model.l8.vit1.attn.rpe', 'image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'image_encoder.positional_embedding', 'hyperformer_model.l9.vit1.norm1.weight', 'hyperformer_model.l5.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l8.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'hyperformer_model.l2.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'hyperformer_model.l10.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.9.ln_2.weight', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'hyperformer_model.l3.tcn1.branches.0.0.weight', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l5.vit1.attn.w1', 'hyperformer_model.l7.tcn1.branches.2.0.weight', 'hyperformer_model.l8.tcn1.branches.2.0.bias', 'hyperformer_model.l8.tcn1.branches.1.1.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.9.ln_1.bias', 'hyperformer_model.l1.vit1.attn.q.weight', 'hyperformer_model.l2.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'hyperformer_model.l7.vit1.attn.proj.weight', 'hyperformer_model.l4.tcn1.branches.1.0.bias', 'hyperformer_model.l7.tcn1.branches.2.4.weight', 'hyperformer_model.l8.tcn1.branches.3.0.bias', 'hyperformer_model.l10.tcn1.branches.0.3.conv.bias', 'text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'hyperformer_model.l9.tcn1.branches.0.0.weight', 'hyperformer_model.l4.tcn1.branches.2.0.bias', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'hyperformer_model.l3.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.2.1.bias', 'text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'hyperformer_model.l1.tcn1.branches.3.0.weight', 'hyperformer_model.l3.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'hyperformer_model.l1.vit1.attn.rpe', 'hyperformer_model.l4.tcn1.branches.2.4.weight', 'hyperformer_model.l1.residual.conv.bias', 'hyperformer_model.l6.vit1.pe_proj.weight', 'hyperformer_model.l8.vit1.attn.w1', 'clip_text_encoder.ln_final.bias', 'text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'hyperformer_model.l9.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l10.vit1.attn.rpe', 'hyperformer_model.l3.vit1.norm1.weight', 'hyperformer_model.l3.vit1.attn.outer', 'text_encoder.transformer.resblocks.8.ln_1.weight', 'hyperformer_model.l8.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l5.residual.conv.weight', 'hyperformer_model.l3.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l4.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'hyperformer_model.l4.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l6.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'hyperformer_model.l6.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'hyperformer_model.l5.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l10.tcn1.branches.2.1.weight', 'clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l5.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'hyperformer_model.l3.tcn1.branches.2.4.weight', 'clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'hyperformer_model.l10.tcn1.branches.2.0.weight', 'hyperformer_model.l6.tcn1.branches.1.1.bias', 'hyperformer_model.l7.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.2.ln_1.weight', 'hyperformer_model.l6.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l1.tcn1.branches.2.4.weight', 'hyperformer_model.l10.vit1.attn.w1', 'hyperformer_model.l2.tcn1.branches.3.0.bias', 'hyperformer_model.l1.tcn1.branches.2.1.weight', 'hyperformer_model.l9.tcn1.branches.1.1.weight', 'image_encoder.class_embedding', 'hyperformer_model.l1.tcn1.branches.1.1.bias', 'hyperformer_model.l1.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'image_encoder.transformer.resblocks.2.ln_1.weight', 'hyperformer_model.l9.tcn1.branches.2.4.bias', 'text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'text_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l3.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l9.tcn1.branches.2.0.weight', 'hyperformer_model.l6.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l4.tcn1.branches.2.4.bias', 'clip_text_encoder.text_projection', 'hyperformer_model.l7.tcn1.branches.0.1.bias', 'hyperformer_model.l9.tcn1.branches.0.0.bias', 'hyperformer_model.l9.vit1.norm1.bias', 'hyperformer_model.l7.vit1.pe_proj.weight', 'hyperformer_model.l9.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l4.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l9.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l10.vit1.attn.outer', 'text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.11.ln_1.weight', 'hyperformer_model.l7.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l7.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l4.vit1.norm1.bias', 'hyperformer_model.l1.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l6.tcn1.branches.0.1.bias', 'hyperformer_model.l6.vit1.attn.outer', 'hyperformer_model.l9.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'hyperformer_model.l5.tcn1.branches.2.0.weight', 'hyperformer_model.l2.tcn1.branches.1.1.bias', 'hyperformer_model.l10.vit1.norm1.bias', 'text_encoder.ln_final.bias', 'image_encoder.ln_post.bias', 'text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'image_encoder.transformer.resblocks.7.ln_2.weight', 'text_encoder.transformer.resblocks.7.ln_2.bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'hyperformer_model.l3.vit1.attn.alpha', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'hyperformer_model.l6.tcn1.branches.2.0.bias', 'text_encoder.transformer.resblocks.10.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.3.1.weight', 'hyperformer_model.l8.residual.bn.weight', 'hyperformer_model.l1.vit1.skip_proj.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'hyperformer_model.l8.residual.conv.bias', 'hyperformer_model.l6.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'hyperformer_model.l4.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'image_encoder.transformer.resblocks.11.ln_2.bias', 'hyperformer_model.l5.tcn1.branches.3.0.bias', 'hyperformer_model.l6.tcn1.branches.2.4.weight', 'hyperformer_model.l9.vit1.attn.kv.weight', 'hyperformer_model.l10.tcn1.branches.2.4.bias', 'hyperformer_model.l9.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'image_encoder.transformer.resblocks.2.ln_2.bias', 'hyperformer_model.l3.tcn1.branches.3.0.weight', 'hyperformer_model.l7.tcn1.branches.2.0.bias', 'image_encoder.transformer.resblocks.10.ln_1.bias', 'clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'image_encoder.transformer.resblocks.10.ln_1.weight', 'clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'hyperformer_model.l3.tcn1.branches.1.0.weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.2.ln_2.bias', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'hyperformer_model.l2.tcn1.branches.2.0.bias', 'text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'hyperformer_model.l4.tcn1.branches.2.1.bias', 'hyperformer_model.l9.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'hyperformer_model.l7.vit1.attn.alpha', 'hyperformer_model.l10.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.1.ln_1.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l7.tcn1.branches.2.4.bias', 'text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l2.vit1.norm1.weight', 'text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.0.ln_1.bias', 'image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.5.ln_1.weight', 'image_encoder.transformer.resblocks.1.ln_2.weight', 'text_encoder.transformer.resblocks.5.ln_1.bias', 'text_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l1.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l1.tcn1.branches.2.0.weight', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'hyperformer_model.l2.tcn1.branches.2.4.bias', 'hyperformer_model.l9.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l1.tcn1.branches.2.1.bias', 'hyperformer_model.l5.tcn1.branches.3.1.bias', 'hyperformer_model.l8.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.3.ln_1.weight', 'hyperformer_model.l9.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.8.ln_2.weight', 'text_encoder.transformer.resblocks.2.ln_2.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'hyperformer_model.l10.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'hyperformer_model.l1.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l4.vit1.attn.proj.weight', 'text_encoder.transformer.resblocks.4.ln_2.bias', 'hyperformer_model.l4.vit1.pe_proj.weight', 'image_encoder.transformer.resblocks.9.ln_2.bias', 'image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'hyperformer_model.l10.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.6.ln_1.bias', 'hyperformer_model.l7.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l5.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.3.ln_1.weight', 'text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'hyperformer_model.l5.tcn1.branches.1.1.bias', 'hyperformer_model.l7.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'hyperformer_model.l2.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l7.tcn1.branches.3.0.weight', 'image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'image_encoder.transformer.resblocks.1.ln_1.weight', 'hyperformer_model.l10.tcn1.branches.0.0.weight', 'hyperformer_model.l2.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l3.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l7.vit1.norm1.weight', 'hyperformer_model.l3.tcn1.branches.0.1.weight', 'hyperformer_model.l7.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'hyperformer_model.l5.vit1.attn.outer', 'text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l6.vit1.attn.proj.bias', 'hyperformer_model.l6.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l1.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l10.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'text_encoder.transformer.resblocks.10.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.2.1.bias', 'hyperformer_model.l5.tcn1.branches.2.1.weight', 'hyperformer_model.l2.vit1.attn.w1', 'text_encoder.transformer.resblocks.6.ln_1.bias', 'image_encoder.transformer.resblocks.0.ln_2.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'image_encoder.transformer.resblocks.3.ln_1.bias', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'hyperformer_model.l1.residual.bn.bias', 'hyperformer_model.l9.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l8.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.5.ln_2.weight', 'image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'hyperformer_model.l4.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.2.ln_1.bias', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'hyperformer_model.l4.vit1.attn.outer', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'hyperformer_model.l1.vit1.attn.w1', 'text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l9.tcn1.branches.3.1.bias', 'hyperformer_model.l3.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'hyperformer_model.l5.vit1.attn.rpe', 'hyperformer_model.l6.tcn1.branches.3.0.weight', 'hyperformer_model.l10.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l10.vit1.norm1.weight', 'hyperformer_model.l10.tcn1.branches.0.0.bias', 'hyperformer_model.l1.residual.conv.weight', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'image_encoder.conv1.weight', 'text_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l10.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.7.ln_1.weight', 'hyperformer_model.l4.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'text_encoder.transformer.resblocks.9.ln_2.bias', 'hyperformer_model.l9.tcn1.branches.1.0.weight', 'hyperformer_model.l10.tcn1.branches.0.1.weight', 'hyperformer_model.l2.tcn1.branches.3.1.bias', 'hyperformer_model.l4.vit1.attn.q.weight', 'hyperformer_model.l9.vit1.attn.outer', 'image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'hyperformer_model.l4.tcn1.branches.0.3.conv.bias', 'text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'hyperformer_model.l7.tcn1.branches.0.0.weight', 'hyperformer_model.l9.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'hyperformer_model.l2.tcn1.branches.1.1.weight', 'hyperformer_model.l3.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l6.vit1.attn.kv.weight', 'hyperformer_model.l8.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l1.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l3.vit1.attn.proj.weight', 'hyperformer_model.l8.tcn1.branches.3.1.weight', 'hyperformer_model.data_bn.weight', 'hyperformer_model.l3.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l8.vit1.attn.outer', 'text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'hyperformer_model.l3.tcn1.branches.1.0.bias', 'hyperformer_model.l2.vit1.pe_proj.weight', 'hyperformer_model.l10.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'image_encoder.transformer.resblocks.7.ln_1.bias', 'image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'hyperformer_model.l2.tcn1.branches.2.0.weight', 'hyperformer_model.fc2.bias', 'clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'hyperformer_model.l8.vit1.norm1.bias', 'image_encoder.proj', 'text_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l7.vit1.attn.proj.bias', 'hyperformer_model.l8.vit1.attn.proj.bias', 'text_encoder.transformer.resblocks.5.ln_1.weight', 'text_encoder.transformer.resblocks.9.ln_1.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'text_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l9.vit1.attn.q.weight', 'text_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l4.tcn1.branches.3.0.weight', 'hyperformer_model.l8.vit1.attn.q.weight', 'hyperformer_model.l7.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.1.1.weight', 'hyperformer_model.l6.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'image_encoder.transformer.resblocks.8.ln_1.weight', 'text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'hyperformer_model.l5.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l1.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.6.ln_2.bias', 'image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l2.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'image_encoder.ln_pre.bias', 'image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'hyperformer_model.l1.tcn1.branches.1.1.weight', 'clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'hyperformer_model.l1.vit1.attn.outer', 'clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'hyperformer_model.l1.tcn1.branches.2.0.bias', 'clip_text_encoder.positional_embedding', 'hyperformer_model.l1.tcn1.branches.3.0.bias', 'hyperformer_model.l5.tcn1.branches.1.3.bn.weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.5.ln_1.bias', 'clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'image_encoder.transformer.resblocks.9.ln_1.weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.0.1.weight', 'hyperformer_model.l6.tcn1.branches.2.0.weight', 'hyperformer_model.l7.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'hyperformer_model.l5.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l3.tcn1.branches.0.3.conv.weight', 'image_encoder.transformer.resblocks.8.ln_2.bias', 'text_encoder.transformer.resblocks.0.ln_1.bias', 'clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'text_encoder.transformer.resblocks.0.ln_2.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'hyperformer_model.l3.vit1.attn.kv.weight', 'hyperformer_model.l2.vit1.attn.rpe', 'hyperformer_model.l5.vit1.norm1.weight', 'image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'hyperformer_model.l4.vit1.norm1.weight', 'image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'hyperformer_model.l6.vit1.attn.rpe', 'image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'hyperformer_model.l5.vit1.attn.proj.bias', 'text_encoder.transformer.resblocks.4.ln_2.weight', 'text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'hyperformer_model.l7.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'hyperformer_model.l9.vit1.attn.rpe', 'hyperformer_model.l9.tcn1.branches.2.0.bias', 'hyperformer_model.l2.tcn1.branches.0.1.weight', 'hyperformer_model.l4.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l8.vit1.attn.proj.weight', 'hyperformer_model.l10.tcn1.branches.2.0.bias', 'hyperformer_model.l6.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'hyperformer_model.l8.tcn1.branches.0.0.weight', 'hyperformer_model.l4.tcn1.branches.1.3.conv.weight', 'clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'hyperformer_model.l6.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l7.vit1.attn.w1', 'hyperformer_model.l4.tcn1.branches.3.1.bias', 'clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l5.vit1.attn.alpha', 'hyperformer_model.l2.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l9.vit1.attn.proj.weight', 'hyperformer_model.l6.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.3.ln_2.bias', 'hyperformer_model.l9.tcn1.branches.3.0.bias', 'hyperformer_model.l10.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l8.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l5.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.11.ln_2.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'hyperformer_model.l6.tcn1.branches.0.0.bias', 'hyperformer_model.l8.residual.bn.bias', 'hyperformer_model.l5.tcn1.branches.3.0.weight', 'image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'hyperformer_model.l7.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l6.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'image_encoder.transformer.resblocks.6.ln_2.weight', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l7.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.1.0.weight', 'hyperformer_model.l8.tcn1.branches.2.0.weight', 'hyperformer_model.l1.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.1.ln_2.weight', 'hyperformer_model.l3.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l10.vit1.attn.proj.weight', 'hyperformer_model.l5.vit1.attn.proj.weight', 'clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'hyperformer_model.l1.tcn1.branches.1.0.weight', 'hyperformer_model.l2.vit1.attn.outer', 'hyperformer_model.l3.tcn1.branches.2.0.weight', 'hyperformer_model.l7.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.5.ln_2.bias', 'text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.2.ln_2.weight', 'clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'image_encoder.transformer.resblocks.10.ln_2.weight', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'hyperformer_model.l4.vit1.attn.alpha', 'image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'hyperformer_model.l8.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l10.vit1.pe_proj.weight', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.l3.tcn1.branches.3.0.bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'hyperformer_model.l7.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'hyperformer_model.l10.tcn1.branches.1.0.weight', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'hyperformer_model.l1.tcn1.branches.2.4.bias', 'hyperformer_model.l4.tcn1.branches.1.1.weight', 'hyperformer_model.l3.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'hyperformer_model.l2.vit1.attn.proj.weight', 'hyperformer_model.l8.tcn1.branches.1.0.bias', 'image_encoder.ln_pre.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'hyperformer_model.l7.tcn1.branches.0.3.conv.bias', 'clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'hyperformer_model.l3.tcn1.branches.0.1.bias', 'hyperformer_model.l9.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'hyperformer_model.l8.tcn1.branches.0.1.weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'hyperformer_model.l5.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'hyperformer_model.l5.tcn1.branches.3.1.weight', 'hyperformer_model.l6.vit1.norm1.bias', 'image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l2.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l3.tcn1.branches.3.1.bias', 'hyperformer_model.l9.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l3.tcn1.branches.2.0.bias', 'hyperformer_model.l7.vit1.attn.kv.weight', 'hyperformer_model.data_bn.bias', 'text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'hyperformer_model.l1.vit1.attn.proj.bias', 'hyperformer_model.l3.tcn1.branches.1.1.bias', 'hyperformer_model.l9.vit1.attn.w1', 'image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'hyperformer_model.l8.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l2.tcn1.branches.1.0.weight', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'text_encoder.text_projection', 'image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.5.ln_2.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.1.ln_1.bias', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'hyperformer_model.l1.tcn1.branches.0.1.bias', 'hyperformer_model.l5.residual.bn.bias', 'clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'hyperformer_model.l6.tcn1.branches.2.4.bias', 'text_encoder.positional_embedding', 'clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l4.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.1.ln_2.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'hyperformer_model.l5.tcn1.branches.0.3.bn.weight', 'image_encoder.transformer.resblocks.4.ln_2.bias', 'image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'hyperformer_model.l2.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l3.tcn1.branches.2.4.bias', 'hyperformer_model.l5.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l5.tcn1.branches.0.0.bias', 'hyperformer_model.l4.tcn1.branches.2.1.weight', 'hyperformer_model.l2.vit1.norm1.bias', 'hyperformer_model.l5.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'hyperformer_model.l4.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l5.residual.bn.weight', 'image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'hyperformer_model.l8.vit1.norm1.weight', 'text_encoder.transformer.resblocks.9.ln_2.weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'image_encoder.transformer.resblocks.0.ln_1.weight', 'image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.4.ln_1.bias', 'text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'text_encoder.transformer.resblocks.4.ln_1.bias', 'hyperformer_model.l3.tcn1.branches.2.1.weight', 'hyperformer_model.l5.tcn1.branches.2.0.bias', 'hyperformer_model.l6.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l1.tcn1.branches.1.3.bn.bias', 'clip_text_encoder.ln_final.weight', 'text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.6.ln_2.weight', 'image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.6.ln_2.bias', 'image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'hyperformer_model.l7.tcn1.branches.1.3.bn.weight', 'hyperformer_model.fc2.weight', 'hyperformer_model.l3.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l10.tcn1.branches.1.3.bn.weight', 'text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'hyperformer_model.l4.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'hyperformer_model.l8.vit1.attn.kv.weight', 'hyperformer_model.l5.vit1.attn.q.weight', 'hyperformer_model.l10.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.l2.vit1.attn.alpha', 'text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l7.vit1.attn.outer', 'image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l4.vit1.attn.kv.weight', 'hyperformer_model.l7.tcn1.branches.3.1.bias', 'hyperformer_model.l5.tcn1.branches.1.0.bias', 'hyperformer_model.l3.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'hyperformer_model.l4.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l9.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'image_encoder.transformer.resblocks.11.ln_2.weight', 'clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'hyperformer_model.l4.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l1.vit1.attn.proj.weight', 'hyperformer_model.l4.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'hyperformer_model.l6.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l7.vit1.attn.rpe', 'hyperformer_model.l8.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'hyperformer_model.l9.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l1.vit1.norm1.bias', 'hyperformer_model.l6.tcn1.branches.0.1.weight', 'image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'hyperformer_model.l2.tcn1.branches.3.1.weight', 'clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.0.0.bias', 'image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'text_encoder.ln_final.weight', 'image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.7.ln_1.weight', 'text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l1.vit1.pe_proj.weight', 'hyperformer_model.l8.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'image_encoder.transformer.resblocks.7.ln_2.bias', 'text_encoder.transformer.resblocks.4.ln_1.weight', 'text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'hyperformer_model.l3.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'hyperformer_model.l1.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'hyperformer_model.l8.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'text_encoder.transformer.resblocks.7.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.2.4.weight', 'hyperformer_model.l7.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.9.ln_1.bias', 'text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'hyperformer_model.l3.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'hyperformer_model.l1.tcn1.branches.0.1.weight', 'hyperformer_model.l2.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'hyperformer_model.l8.vit1.attn.alpha', 'hyperformer_model.l8.tcn1.branches.3.0.weight', 'hyperformer_model.l6.vit1.attn.proj.weight', 'hyperformer_model.l5.vit1.pe_proj.weight', 'hyperformer_model.l5.residual.conv.bias', 'clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'text_encoder.transformer.resblocks.11.attn.out_proj.weight'}
[2024-12-24 21:38:37 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 316): INFO Total learnable items: 835
[2024-12-24 21:40:13 ViT-B/16] (tools.py 147): INFO ==============> Resuming from ./workdirs/TEST_P1_SKeletonCLIP_alltrn_HFinit_zs_48_17Dec24/ckpt_epoch_0.pth....................
[2024-12-24 21:40:14 ViT-B/16] (tools.py 172): INFO resume VIFICLIP model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.clip_text_encoder.positional_embedding', 'module.clip_text_encoder.text_projection', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'module.clip_text_encoder.ln_final.weight', 'module.clip_text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:40:14 ViT-B/16] (tools.py 176): INFO ==============> Resuming from /data/users/asinha13/projects/CLIP4ADL/model_chkpnts/ntu_CS_P1_HF_pretrain_frzn_txt_zs_48_AS_16Jan24/ckpt_epoch_99.pth....................
[2024-12-24 21:40:14 ViT-B/16] (tools.py 218): INFO resume Hyperformer model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.text_encoder.positional_embedding', 'module.text_encoder.text_projection', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_1.weight', 'module.text_encoder.transformer.resblocks.0.ln_1.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_2.weight', 'module.text_encoder.transformer.resblocks.0.ln_2.bias', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_1.weight', 'module.text_encoder.transformer.resblocks.1.ln_1.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_2.weight', 'module.text_encoder.transformer.resblocks.1.ln_2.bias', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_1.weight', 'module.text_encoder.transformer.resblocks.2.ln_1.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_2.weight', 'module.text_encoder.transformer.resblocks.2.ln_2.bias', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_1.weight', 'module.text_encoder.transformer.resblocks.3.ln_1.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_2.weight', 'module.text_encoder.transformer.resblocks.3.ln_2.bias', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_1.weight', 'module.text_encoder.transformer.resblocks.4.ln_1.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_2.weight', 'module.text_encoder.transformer.resblocks.4.ln_2.bias', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_1.weight', 'module.text_encoder.transformer.resblocks.5.ln_1.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_2.weight', 'module.text_encoder.transformer.resblocks.5.ln_2.bias', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_1.weight', 'module.text_encoder.transformer.resblocks.6.ln_1.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_2.weight', 'module.text_encoder.transformer.resblocks.6.ln_2.bias', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_1.weight', 'module.text_encoder.transformer.resblocks.7.ln_1.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_2.weight', 'module.text_encoder.transformer.resblocks.7.ln_2.bias', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_1.weight', 'module.text_encoder.transformer.resblocks.8.ln_1.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_2.weight', 'module.text_encoder.transformer.resblocks.8.ln_2.bias', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_1.weight', 'module.text_encoder.transformer.resblocks.9.ln_1.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_2.weight', 'module.text_encoder.transformer.resblocks.9.ln_2.bias', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_1.weight', 'module.text_encoder.transformer.resblocks.10.ln_1.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_2.weight', 'module.text_encoder.transformer.resblocks.10.ln_2.bias', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_1.weight', 'module.text_encoder.transformer.resblocks.11.ln_1.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_2.weight', 'module.text_encoder.transformer.resblocks.11.ln_2.bias', 'module.text_encoder.ln_final.weight', 'module.text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:40:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][0/11317]	eta 17:06:19 lr 0.000022000	time 5.4414 (5.4414)	dist_loss 0.3983 (0.3983)	image_text_loss 3.9411 (3.9411)	pose_text_loss 2.3231 (2.3231)	tot_loss 10.2473 (10.2473)	mem 12001MB
[2024-12-24 21:40:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][50/11317]	eta 1:26:15 lr 0.000021999	time 0.3698 (0.4594)	dist_loss 0.0018 (0.1192)	image_text_loss 3.8987 (3.8714)	pose_text_loss 3.8709 (3.6875)	tot_loss 7.7880 (8.7513)	mem 12001MB
[2024-12-24 21:40:56 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][100/11317]	eta 1:17:38 lr 0.000021996	time 0.3811 (0.4153)	dist_loss 0.0143 (0.0670)	image_text_loss 3.7969 (3.8691)	pose_text_loss 3.5595 (3.7056)	tot_loss 7.4991 (8.2451)	mem 12001MB
[2024-12-24 21:41:14 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][150/11317]	eta 1:14:15 lr 0.000021991	time 0.3719 (0.3990)	dist_loss 0.0146 (0.0500)	image_text_loss 3.8438 (3.8745)	pose_text_loss 3.4774 (3.6943)	tot_loss 7.4674 (8.0683)	mem 12001MB
[2024-12-24 21:41:32 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][200/11317]	eta 1:12:19 lr 0.000021983	time 0.3548 (0.3903)	dist_loss 0.0259 (0.0414)	image_text_loss 3.8955 (3.8722)	pose_text_loss 3.5952 (3.6801)	tot_loss 7.7497 (7.9663)	mem 12001MB
[2024-12-24 21:41:50 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][250/11317]	eta 1:10:41 lr 0.000021974	time 0.3619 (0.3833)	dist_loss 0.0159 (0.0364)	image_text_loss 3.9459 (3.8744)	pose_text_loss 3.7455 (3.6646)	tot_loss 7.8503 (7.9026)	mem 12001MB
[2024-12-24 21:42:08 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][300/11317]	eta 1:09:32 lr 0.000021962	time 0.3583 (0.3787)	dist_loss 0.0119 (0.0339)	image_text_loss 3.7326 (3.8735)	pose_text_loss 3.4559 (3.6484)	tot_loss 7.3072 (7.8606)	mem 12001MB
[2024-12-24 21:42:26 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][350/11317]	eta 1:08:41 lr 0.000021949	time 0.3647 (0.3758)	dist_loss 0.0156 (0.0317)	image_text_loss 3.9574 (3.8751)	pose_text_loss 3.8310 (3.6355)	tot_loss 7.9448 (7.8274)	mem 12001MB
[2024-12-24 21:42:44 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][400/11317]	eta 1:08:00 lr 0.000021933	time 0.3385 (0.3738)	dist_loss 0.0169 (0.0300)	image_text_loss 3.8299 (3.8760)	pose_text_loss 3.4721 (3.6243)	tot_loss 7.4706 (7.8000)	mem 12001MB
[2024-12-24 21:43:01 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][450/11317]	eta 1:07:15 lr 0.000021915	time 0.3400 (0.3713)	dist_loss 0.0233 (0.0287)	image_text_loss 3.9123 (3.8765)	pose_text_loss 3.2720 (3.6171)	tot_loss 7.4177 (7.7809)	mem 12001MB
[2024-12-24 21:43:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][500/11317]	eta 1:06:42 lr 0.000021895	time 0.3495 (0.3700)	dist_loss 0.0119 (0.0279)	image_text_loss 3.9405 (3.8768)	pose_text_loss 3.6992 (3.6067)	tot_loss 7.7590 (7.7623)	mem 12001MB
[2024-12-24 21:43:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][550/11317]	eta 1:06:02 lr 0.000021873	time 0.3489 (0.3680)	dist_loss 0.0135 (0.0274)	image_text_loss 3.8269 (3.8767)	pose_text_loss 3.4453 (3.5929)	tot_loss 7.4075 (7.7433)	mem 12001MB
[2024-12-24 21:43:54 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][600/11317]	eta 1:05:27 lr 0.000021849	time 0.3483 (0.3664)	dist_loss 0.0175 (0.0268)	image_text_loss 3.8809 (3.8769)	pose_text_loss 3.4628 (3.5862)	tot_loss 7.5186 (7.7315)	mem 12001MB
[2024-12-24 21:44:12 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][650/11317]	eta 1:05:02 lr 0.000021823	time 0.3657 (0.3659)	dist_loss 0.0156 (0.0265)	image_text_loss 3.8520 (3.8770)	pose_text_loss 3.6586 (3.5783)	tot_loss 7.6668 (7.7204)	mem 12001MB
[2024-12-24 21:44:30 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][700/11317]	eta 1:04:34 lr 0.000021795	time 0.3720 (0.3650)	dist_loss 0.0183 (0.0263)	image_text_loss 3.8740 (3.8767)	pose_text_loss 3.5535 (3.5650)	tot_loss 7.6103 (7.7048)	mem 12001MB
[2024-12-24 21:44:47 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][750/11317]	eta 1:04:06 lr 0.000021765	time 0.3450 (0.3640)	dist_loss 0.0264 (0.0261)	image_text_loss 3.8237 (3.8765)	pose_text_loss 3.3745 (3.5562)	tot_loss 7.4624 (7.6935)	mem 12001MB
[2024-12-24 21:45:05 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][800/11317]	eta 1:03:45 lr 0.000021733	time 0.3515 (0.3638)	dist_loss 0.0174 (0.0261)	image_text_loss 3.8396 (3.8758)	pose_text_loss 3.3902 (3.5443)	tot_loss 7.4038 (7.6808)	mem 12001MB
[2024-12-24 21:45:23 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][850/11317]	eta 1:03:22 lr 0.000021698	time 0.3476 (0.3633)	dist_loss 0.0188 (0.0259)	image_text_loss 3.8669 (3.8761)	pose_text_loss 3.5196 (3.5386)	tot_loss 7.5747 (7.6740)	mem 12001MB
[2024-12-24 21:45:41 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][900/11317]	eta 1:02:58 lr 0.000021662	time 0.3542 (0.3627)	dist_loss 0.0334 (0.0260)	image_text_loss 3.8592 (3.8757)	pose_text_loss 3.1548 (3.5276)	tot_loss 7.3482 (7.6632)	mem 12001MB
[2024-12-24 21:45:58 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][950/11317]	eta 1:02:36 lr 0.000021624	time 0.3407 (0.3624)	dist_loss 0.0284 (0.0259)	image_text_loss 3.8852 (3.8756)	pose_text_loss 3.0623 (3.5188)	tot_loss 7.2318 (7.6539)	mem 12001MB
[2024-12-24 21:46:16 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1000/11317]	eta 1:02:14 lr 0.000021583	time 0.3498 (0.3620)	dist_loss 0.0268 (0.0259)	image_text_loss 3.8645 (3.8754)	pose_text_loss 3.5738 (3.5106)	tot_loss 7.7066 (7.6452)	mem 12001MB
[2024-12-24 21:46:34 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1050/11317]	eta 1:01:51 lr 0.000021541	time 0.4323 (0.3615)	dist_loss 0.0117 (0.0259)	image_text_loss 3.8418 (3.8754)	pose_text_loss 3.5990 (3.5060)	tot_loss 7.5583 (7.6400)	mem 12001MB
[2024-12-24 21:46:52 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1100/11317]	eta 1:01:32 lr 0.000021496	time 0.3592 (0.3614)	dist_loss 0.0460 (0.0258)	image_text_loss 3.8098 (3.8757)	pose_text_loss 2.8691 (3.5022)	tot_loss 7.1388 (7.6363)	mem 12001MB
[2024-12-24 21:47:10 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1150/11317]	eta 1:01:12 lr 0.000021450	time 0.3518 (0.3612)	dist_loss 0.0217 (0.0258)	image_text_loss 3.9590 (3.8754)	pose_text_loss 3.5643 (3.4980)	tot_loss 7.7401 (7.6314)	mem 12001MB
[2024-12-24 21:47:27 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1200/11317]	eta 1:00:52 lr 0.000021401	time 0.3530 (0.3610)	dist_loss 0.0267 (0.0260)	image_text_loss 3.8659 (3.8751)	pose_text_loss 3.3396 (3.4894)	tot_loss 7.4725 (7.6241)	mem 12001MB
[2024-12-24 21:47:45 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1250/11317]	eta 1:00:32 lr 0.000021351	time 0.3480 (0.3608)	dist_loss 0.0599 (0.0261)	image_text_loss 3.8182 (3.8751)	pose_text_loss 2.4540 (3.4796)	tot_loss 6.8710 (7.6158)	mem 12001MB
[2024-12-24 21:48:03 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1300/11317]	eta 1:00:10 lr 0.000021299	time 0.3447 (0.3605)	dist_loss 0.0225 (0.0261)	image_text_loss 3.7924 (3.8750)	pose_text_loss 3.3544 (3.4728)	tot_loss 7.3718 (7.6092)	mem 12001MB
[2024-12-24 21:48:21 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1350/11317]	eta 0:59:52 lr 0.000021244	time 0.3538 (0.3604)	dist_loss 0.0283 (0.0263)	image_text_loss 3.8681 (3.8747)	pose_text_loss 3.3692 (3.4647)	tot_loss 7.5201 (7.6027)	mem 12001MB
[2024-12-24 21:48:39 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1400/11317]	eta 0:59:33 lr 0.000021188	time 0.3467 (0.3603)	dist_loss 0.0268 (0.0265)	image_text_loss 3.8537 (3.8749)	pose_text_loss 3.4036 (3.4563)	tot_loss 7.5258 (7.5962)	mem 12001MB
[2024-12-24 21:48:56 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1450/11317]	eta 0:59:12 lr 0.000021130	time 0.3409 (0.3600)	dist_loss 0.0194 (0.0266)	image_text_loss 3.8577 (3.8747)	pose_text_loss 3.6379 (3.4506)	tot_loss 7.6899 (7.5913)	mem 12001MB
[2024-12-24 21:49:14 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1500/11317]	eta 0:58:51 lr 0.000021069	time 0.4204 (0.3598)	dist_loss 0.0261 (0.0269)	image_text_loss 3.8759 (3.8745)	pose_text_loss 3.1760 (3.4405)	tot_loss 7.3125 (7.5838)	mem 12001MB
[2024-12-24 21:49:31 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1550/11317]	eta 0:58:31 lr 0.000021007	time 0.3583 (0.3596)	dist_loss 0.0392 (0.0272)	image_text_loss 3.8561 (3.8747)	pose_text_loss 3.3340 (3.4305)	tot_loss 7.5816 (7.5769)	mem 12001MB
[2024-12-24 21:49:49 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1600/11317]	eta 0:58:12 lr 0.000020943	time 0.3658 (0.3594)	dist_loss 0.0129 (0.0275)	image_text_loss 3.8228 (3.8741)	pose_text_loss 3.5845 (3.4209)	tot_loss 7.5359 (7.5696)	mem 12001MB
[2024-12-24 21:50:07 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1650/11317]	eta 0:57:54 lr 0.000020877	time 0.4357 (0.3594)	dist_loss 0.0325 (0.0276)	image_text_loss 3.8251 (3.8734)	pose_text_loss 2.9692 (3.4128)	tot_loss 7.1189 (7.5627)	mem 12001MB
[2024-12-24 21:50:25 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1700/11317]	eta 0:57:35 lr 0.000020810	time 0.3498 (0.3593)	dist_loss 0.0441 (0.0278)	image_text_loss 3.8666 (3.8736)	pose_text_loss 2.8056 (3.4078)	tot_loss 7.1131 (7.5590)	mem 12001MB
[2024-12-24 21:50:43 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1750/11317]	eta 0:57:15 lr 0.000020740	time 0.3451 (0.3591)	dist_loss 0.0373 (0.0280)	image_text_loss 3.9267 (3.8736)	pose_text_loss 3.0560 (3.3991)	tot_loss 7.3555 (7.5528)	mem 12001MB
[2024-12-24 21:51:00 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1800/11317]	eta 0:56:57 lr 0.000020669	time 0.4482 (0.3591)	dist_loss 0.0239 (0.0282)	image_text_loss 3.8644 (3.8737)	pose_text_loss 3.4259 (3.3934)	tot_loss 7.5295 (7.5487)	mem 12001MB
[2024-12-24 21:51:18 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1850/11317]	eta 0:56:37 lr 0.000020595	time 0.3638 (0.3589)	dist_loss 0.0357 (0.0282)	image_text_loss 3.8702 (3.8737)	pose_text_loss 3.1079 (3.3911)	tot_loss 7.3349 (7.5469)	mem 12001MB
[2024-12-24 21:51:36 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1900/11317]	eta 0:56:18 lr 0.000020520	time 0.3628 (0.3588)	dist_loss 0.0216 (0.0285)	image_text_loss 3.8695 (3.8737)	pose_text_loss 3.5932 (3.3827)	tot_loss 7.6791 (7.5413)	mem 12001MB
[2024-12-24 21:51:54 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][1950/11317]	eta 0:56:00 lr 0.000020443	time 0.3581 (0.3588)	dist_loss 0.0576 (0.0287)	image_text_loss 3.8742 (3.8737)	pose_text_loss 2.5099 (3.3753)	tot_loss 6.9602 (7.5363)	mem 12001MB
[2024-12-24 21:52:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2000/11317]	eta 0:55:41 lr 0.000020364	time 0.3557 (0.3586)	dist_loss 0.0516 (0.0290)	image_text_loss 3.9610 (3.8735)	pose_text_loss 2.7870 (3.3673)	tot_loss 7.2639 (7.5311)	mem 12001MB
[2024-12-24 21:52:29 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2050/11317]	eta 0:55:22 lr 0.000020284	time 0.3572 (0.3585)	dist_loss 0.0372 (0.0294)	image_text_loss 3.8681 (3.8735)	pose_text_loss 3.0920 (3.3571)	tot_loss 7.3318 (7.5243)	mem 12001MB
[2024-12-24 21:52:47 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2100/11317]	eta 0:55:03 lr 0.000020201	time 0.3506 (0.3584)	dist_loss 0.0216 (0.0295)	image_text_loss 3.8790 (3.8735)	pose_text_loss 3.7062 (3.3520)	tot_loss 7.8009 (7.5207)	mem 12001MB
[2024-12-24 21:53:05 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2150/11317]	eta 0:54:44 lr 0.000020117	time 0.3590 (0.3583)	dist_loss 0.0570 (0.0297)	image_text_loss 3.8745 (3.8734)	pose_text_loss 2.5301 (3.3450)	tot_loss 6.9743 (7.5158)	mem 12001MB
[2024-12-24 21:53:22 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2200/11317]	eta 0:54:26 lr 0.000020031	time 0.3761 (0.3583)	dist_loss 0.0736 (0.0300)	image_text_loss 3.8861 (3.8733)	pose_text_loss 2.3629 (3.3375)	tot_loss 6.9848 (7.5107)	mem 12001MB
[2024-12-24 21:53:40 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2250/11317]	eta 0:54:07 lr 0.000019944	time 0.3579 (0.3581)	dist_loss 0.0553 (0.0302)	image_text_loss 3.8395 (3.8733)	pose_text_loss 2.6781 (3.3309)	tot_loss 7.0710 (7.5060)	mem 12001MB
[2024-12-24 21:53:58 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2300/11317]	eta 0:53:48 lr 0.000019855	time 0.3495 (0.3581)	dist_loss 0.0262 (0.0304)	image_text_loss 3.8759 (3.8732)	pose_text_loss 3.1311 (3.3239)	tot_loss 7.2686 (7.5007)	mem 12001MB
[2024-12-24 21:54:15 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2350/11317]	eta 0:53:29 lr 0.000019764	time 0.3505 (0.3579)	dist_loss 0.0600 (0.0306)	image_text_loss 3.8999 (3.8726)	pose_text_loss 2.5231 (3.3168)	tot_loss 7.0228 (7.4950)	mem 12001MB
[2024-12-24 21:54:33 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2400/11317]	eta 0:53:11 lr 0.000019671	time 0.3529 (0.3579)	dist_loss 0.0204 (0.0308)	image_text_loss 3.8779 (3.8725)	pose_text_loss 3.4116 (3.3093)	tot_loss 7.4938 (7.4902)	mem 12001MB
[2024-12-24 21:54:51 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2450/11317]	eta 0:52:52 lr 0.000019577	time 0.3544 (0.3578)	dist_loss 0.0558 (0.0310)	image_text_loss 3.8902 (3.8724)	pose_text_loss 2.5685 (3.3026)	tot_loss 7.0164 (7.4854)	mem 12001MB
[2024-12-24 21:55:08 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2500/11317]	eta 0:52:33 lr 0.000019481	time 0.3393 (0.3577)	dist_loss 0.0394 (0.0312)	image_text_loss 3.8700 (3.8725)	pose_text_loss 3.4881 (3.2989)	tot_loss 7.7519 (7.4830)	mem 12001MB
[2024-12-24 21:55:26 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2550/11317]	eta 0:52:15 lr 0.000019384	time 0.3487 (0.3576)	dist_loss 0.0277 (0.0314)	image_text_loss 3.8680 (3.8725)	pose_text_loss 3.5719 (3.2918)	tot_loss 7.7174 (7.4782)	mem 12001MB
[2024-12-24 21:55:44 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2600/11317]	eta 0:51:57 lr 0.000019285	time 0.3420 (0.3576)	dist_loss 0.0335 (0.0315)	image_text_loss 3.8638 (3.8725)	pose_text_loss 3.1549 (3.2890)	tot_loss 7.3539 (7.4763)	mem 12001MB
[2024-12-24 21:56:01 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2650/11317]	eta 0:51:37 lr 0.000019184	time 0.3373 (0.3574)	dist_loss 0.0505 (0.0317)	image_text_loss 3.8715 (3.8725)	pose_text_loss 2.7188 (3.2828)	tot_loss 7.0956 (7.4724)	mem 12001MB
[2024-12-24 21:56:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2700/11317]	eta 0:51:20 lr 0.000019082	time 0.3330 (0.3575)	dist_loss 0.0523 (0.0319)	image_text_loss 3.8817 (3.8724)	pose_text_loss 2.6492 (3.2778)	tot_loss 7.0537 (7.4689)	mem 12001MB
[2024-12-24 21:56:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2750/11317]	eta 0:51:02 lr 0.000018978	time 0.3657 (0.3574)	dist_loss 0.0376 (0.0319)	image_text_loss 3.8672 (3.8724)	pose_text_loss 3.1024 (3.2753)	tot_loss 7.3457 (7.4668)	mem 12001MB
[2024-12-24 21:56:55 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2800/11317]	eta 0:50:43 lr 0.000018873	time 0.3695 (0.3574)	dist_loss 0.0194 (0.0320)	image_text_loss 3.8794 (3.8724)	pose_text_loss 3.7734 (3.2709)	tot_loss 7.8473 (7.4637)	mem 12001MB
[2024-12-24 21:57:13 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2850/11317]	eta 0:50:26 lr 0.000018766	time 0.3535 (0.3574)	dist_loss 0.0249 (0.0322)	image_text_loss 3.8813 (3.8725)	pose_text_loss 3.6455 (3.2664)	tot_loss 7.7758 (7.4609)	mem 12001MB
[2024-12-24 21:57:31 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2900/11317]	eta 0:50:08 lr 0.000018658	time 0.3529 (0.3574)	dist_loss 0.0357 (0.0323)	image_text_loss 3.8735 (3.8724)	pose_text_loss 2.8817 (3.2616)	tot_loss 7.1126 (7.4573)	mem 12001MB
[2024-12-24 21:57:48 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][2950/11317]	eta 0:49:50 lr 0.000018548	time 0.3560 (0.3574)	dist_loss 0.0633 (0.0325)	image_text_loss 3.8704 (3.8725)	pose_text_loss 2.4215 (3.2561)	tot_loss 6.9247 (7.4537)	mem 12001MB
[2024-12-24 21:58:06 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3000/11317]	eta 0:49:32 lr 0.000018437	time 0.3659 (0.3574)	dist_loss 0.0506 (0.0327)	image_text_loss 3.9301 (3.8725)	pose_text_loss 2.7099 (3.2521)	tot_loss 7.1463 (7.4513)	mem 12001MB
[2024-12-24 21:58:24 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3050/11317]	eta 0:49:14 lr 0.000018324	time 0.3558 (0.3574)	dist_loss 0.0522 (0.0328)	image_text_loss 3.8718 (3.8724)	pose_text_loss 3.0258 (3.2485)	tot_loss 7.4195 (7.4491)	mem 12001MB
[2024-12-24 21:58:42 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3100/11317]	eta 0:48:56 lr 0.000018210	time 0.3542 (0.3573)	dist_loss 0.0690 (0.0330)	image_text_loss 3.8706 (3.8724)	pose_text_loss 2.3916 (3.2438)	tot_loss 6.9526 (7.4459)	mem 12001MB
[2024-12-24 21:59:00 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3150/11317]	eta 0:48:38 lr 0.000018095	time 0.3621 (0.3573)	dist_loss 0.0619 (0.0332)	image_text_loss 3.8685 (3.8724)	pose_text_loss 2.4813 (3.2386)	tot_loss 6.9689 (7.4426)	mem 12001MB
[2024-12-24 21:59:18 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3200/11317]	eta 0:48:20 lr 0.000017979	time 0.3618 (0.3573)	dist_loss 0.0333 (0.0334)	image_text_loss 3.8707 (3.8724)	pose_text_loss 3.2078 (3.2328)	tot_loss 7.4113 (7.4390)	mem 12001MB
[2024-12-24 21:59:35 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3250/11317]	eta 0:48:01 lr 0.000017861	time 0.3639 (0.3572)	dist_loss 0.0385 (0.0335)	image_text_loss 3.8673 (3.8724)	pose_text_loss 2.7668 (3.2285)	tot_loss 7.0194 (7.4359)	mem 12001MB
[2024-12-24 21:59:53 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3300/11317]	eta 0:47:43 lr 0.000017741	time 0.3531 (0.3572)	dist_loss 0.0241 (0.0336)	image_text_loss 3.8742 (3.8724)	pose_text_loss 3.4454 (3.2250)	tot_loss 7.5605 (7.4334)	mem 12001MB
[2024-12-24 22:00:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3350/11317]	eta 0:47:25 lr 0.000017621	time 0.3498 (0.3572)	dist_loss 0.0301 (0.0337)	image_text_loss 3.8727 (3.8723)	pose_text_loss 3.2048 (3.2213)	tot_loss 7.3783 (7.4308)	mem 12001MB
[2024-12-24 22:00:28 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3400/11317]	eta 0:47:07 lr 0.000017499	time 0.3530 (0.3571)	dist_loss 0.0295 (0.0339)	image_text_loss 3.8711 (3.8723)	pose_text_loss 3.3175 (3.2171)	tot_loss 7.4840 (7.4280)	mem 12001MB
[2024-12-24 22:00:46 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3450/11317]	eta 0:46:49 lr 0.000017376	time 0.3564 (0.3572)	dist_loss 0.0415 (0.0339)	image_text_loss 3.8704 (3.8723)	pose_text_loss 2.9684 (3.2156)	tot_loss 7.2535 (7.4267)	mem 12001MB
[2024-12-24 22:01:04 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3500/11317]	eta 0:46:31 lr 0.000017252	time 0.3571 (0.3571)	dist_loss 0.0293 (0.0340)	image_text_loss 3.8717 (3.8723)	pose_text_loss 3.5515 (3.2127)	tot_loss 7.7159 (7.4246)	mem 12001MB
[2024-12-24 22:01:22 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3550/11317]	eta 0:46:13 lr 0.000017126	time 0.3493 (0.3571)	dist_loss 0.0496 (0.0341)	image_text_loss 3.8711 (3.8723)	pose_text_loss 2.7837 (3.2085)	tot_loss 7.1504 (7.4217)	mem 12001MB
[2024-12-24 22:01:40 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3600/11317]	eta 0:45:55 lr 0.000017000	time 0.3478 (0.3571)	dist_loss 0.0459 (0.0342)	image_text_loss 3.8524 (3.8722)	pose_text_loss 2.6839 (3.2054)	tot_loss 6.9958 (7.4195)	mem 12001MB
[2024-12-24 22:01:58 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3650/11317]	eta 0:45:37 lr 0.000016872	time 0.3524 (0.3571)	dist_loss 0.0201 (0.0344)	image_text_loss 3.8588 (3.8722)	pose_text_loss 3.5126 (3.2004)	tot_loss 7.5721 (7.4161)	mem 12001MB
[2024-12-24 22:02:15 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3700/11317]	eta 0:45:19 lr 0.000016743	time 0.3498 (0.3570)	dist_loss 0.0387 (0.0345)	image_text_loss 3.8683 (3.8722)	pose_text_loss 2.8864 (3.1971)	tot_loss 7.1412 (7.4140)	mem 12001MB
[2024-12-24 22:02:33 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3750/11317]	eta 0:45:01 lr 0.000016613	time 0.3491 (0.3571)	dist_loss 0.0344 (0.0346)	image_text_loss 3.8716 (3.8722)	pose_text_loss 2.9429 (3.1946)	tot_loss 7.1582 (7.4124)	mem 12001MB
[2024-12-24 22:02:51 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3800/11317]	eta 0:44:43 lr 0.000016482	time 0.3552 (0.3570)	dist_loss 0.0281 (0.0347)	image_text_loss 3.8717 (3.8722)	pose_text_loss 3.1993 (3.1911)	tot_loss 7.3525 (7.4101)	mem 12001MB
[2024-12-24 22:03:09 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3850/11317]	eta 0:44:25 lr 0.000016350	time 0.3535 (0.3570)	dist_loss 0.0255 (0.0347)	image_text_loss 3.8697 (3.8722)	pose_text_loss 3.3434 (3.1890)	tot_loss 7.4680 (7.4087)	mem 12001MB
[2024-12-24 22:03:27 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3900/11317]	eta 0:44:08 lr 0.000016217	time 0.3474 (0.3571)	dist_loss 0.0333 (0.0348)	image_text_loss 3.8735 (3.8722)	pose_text_loss 2.8947 (3.1861)	tot_loss 7.1012 (7.4066)	mem 12001MB
[2024-12-24 22:03:45 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][3950/11317]	eta 0:43:50 lr 0.000016083	time 0.3440 (0.3571)	dist_loss 0.0358 (0.0349)	image_text_loss 3.8724 (3.8722)	pose_text_loss 3.0537 (3.1838)	tot_loss 7.2842 (7.4050)	mem 12001MB
[2024-12-24 22:04:02 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4000/11317]	eta 0:43:32 lr 0.000015948	time 0.3533 (0.3570)	dist_loss 0.0374 (0.0350)	image_text_loss 3.8397 (3.8721)	pose_text_loss 2.8291 (3.1805)	tot_loss 7.0425 (7.4027)	mem 12001MB
[2024-12-24 22:04:20 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4050/11317]	eta 0:43:14 lr 0.000015813	time 0.3438 (0.3570)	dist_loss 0.0630 (0.0351)	image_text_loss 3.8676 (3.8721)	pose_text_loss 2.5187 (3.1777)	tot_loss 7.0161 (7.4007)	mem 12001MB
[2024-12-24 22:04:38 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4100/11317]	eta 0:42:56 lr 0.000015676	time 0.3469 (0.3570)	dist_loss 0.0388 (0.0352)	image_text_loss 3.8722 (3.8721)	pose_text_loss 2.8911 (3.1742)	tot_loss 7.1510 (7.3983)	mem 12001MB
[2024-12-24 22:04:56 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4150/11317]	eta 0:42:38 lr 0.000015538	time 0.3515 (0.3570)	dist_loss 0.0256 (0.0353)	image_text_loss 3.8693 (3.8720)	pose_text_loss 3.5510 (3.1708)	tot_loss 7.6759 (7.3962)	mem 12001MB
[2024-12-24 22:05:13 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4200/11317]	eta 0:42:20 lr 0.000015400	time 0.3459 (0.3569)	dist_loss 0.0548 (0.0355)	image_text_loss 3.8721 (3.8720)	pose_text_loss 2.5728 (3.1668)	tot_loss 6.9931 (7.3934)	mem 12001MB
[2024-12-24 22:05:31 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4250/11317]	eta 0:42:02 lr 0.000015260	time 0.3453 (0.3569)	dist_loss 0.0159 (0.0356)	image_text_loss 3.8582 (3.8720)	pose_text_loss 3.2665 (3.1633)	tot_loss 7.2840 (7.3912)	mem 12001MB
[2024-12-24 22:05:49 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4300/11317]	eta 0:41:44 lr 0.000015120	time 0.3541 (0.3569)	dist_loss 0.0450 (0.0357)	image_text_loss 3.8749 (3.8720)	pose_text_loss 2.7298 (3.1601)	tot_loss 7.0548 (7.3891)	mem 12001MB
[2024-12-24 22:06:07 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4350/11317]	eta 0:41:26 lr 0.000014979	time 0.3674 (0.3569)	dist_loss 0.0176 (0.0357)	image_text_loss 3.8749 (3.8720)	pose_text_loss 3.5838 (3.1587)	tot_loss 7.6343 (7.3881)	mem 12001MB
[2024-12-24 22:06:25 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4400/11317]	eta 0:41:08 lr 0.000014838	time 0.3493 (0.3569)	dist_loss 0.0520 (0.0358)	image_text_loss 3.8889 (3.8720)	pose_text_loss 2.6344 (3.1566)	tot_loss 7.0435 (7.3867)	mem 12001MB
[2024-12-24 22:06:42 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4450/11317]	eta 0:40:50 lr 0.000014695	time 0.3525 (0.3569)	dist_loss 0.0374 (0.0359)	image_text_loss 3.8767 (3.8720)	pose_text_loss 2.9198 (3.1542)	tot_loss 7.1707 (7.3849)	mem 12001MB
[2024-12-24 22:07:00 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4500/11317]	eta 0:40:33 lr 0.000014552	time 0.3465 (0.3569)	dist_loss 0.0569 (0.0360)	image_text_loss 3.8783 (3.8720)	pose_text_loss 2.4999 (3.1499)	tot_loss 6.9474 (7.3822)	mem 12001MB
[2024-12-24 22:07:18 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4550/11317]	eta 0:40:15 lr 0.000014408	time 0.3657 (0.3569)	dist_loss 0.0377 (0.0361)	image_text_loss 3.8658 (3.8720)	pose_text_loss 2.9961 (3.1476)	tot_loss 7.2392 (7.3806)	mem 12001MB
[2024-12-24 22:07:36 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4600/11317]	eta 0:39:56 lr 0.000014264	time 0.3702 (0.3568)	dist_loss 0.0324 (0.0362)	image_text_loss 3.8749 (3.8719)	pose_text_loss 3.2857 (3.1445)	tot_loss 7.4850 (7.3785)	mem 12001MB
[2024-12-24 22:07:54 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4650/11317]	eta 0:39:39 lr 0.000014119	time 0.4377 (0.3569)	dist_loss 0.0564 (0.0363)	image_text_loss 3.8728 (3.8719)	pose_text_loss 2.5964 (3.1414)	tot_loss 7.0330 (7.3764)	mem 12001MB
[2024-12-24 22:08:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4700/11317]	eta 0:39:21 lr 0.000013974	time 0.3546 (0.3568)	dist_loss 0.0797 (0.0364)	image_text_loss 3.8030 (3.8719)	pose_text_loss 2.1886 (3.1386)	tot_loss 6.7889 (7.3745)	mem 12001MB
[2024-12-24 22:08:29 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4750/11317]	eta 0:39:03 lr 0.000013827	time 0.3555 (0.3568)	dist_loss 0.0710 (0.0365)	image_text_loss 3.8778 (3.8718)	pose_text_loss 2.3932 (3.1346)	tot_loss 6.9813 (7.3717)	mem 12001MB
[2024-12-24 22:08:47 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4800/11317]	eta 0:38:45 lr 0.000013681	time 0.3559 (0.3569)	dist_loss 0.0150 (0.0366)	image_text_loss 3.9026 (3.8718)	pose_text_loss 3.5952 (3.1319)	tot_loss 7.6475 (7.3701)	mem 12001MB
[2024-12-24 22:09:05 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4850/11317]	eta 0:38:27 lr 0.000013534	time 0.3540 (0.3568)	dist_loss 0.0418 (0.0368)	image_text_loss 3.8766 (3.8718)	pose_text_loss 2.7967 (3.1289)	tot_loss 7.0910 (7.3683)	mem 12001MB
[2024-12-24 22:09:22 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4900/11317]	eta 0:38:09 lr 0.000013386	time 0.3532 (0.3568)	dist_loss 0.0579 (0.0368)	image_text_loss 3.8680 (3.8719)	pose_text_loss 2.4969 (3.1267)	tot_loss 6.9442 (7.3669)	mem 12001MB
[2024-12-24 22:09:40 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][4950/11317]	eta 0:37:51 lr 0.000013238	time 0.3540 (0.3568)	dist_loss 0.0584 (0.0369)	image_text_loss 3.7920 (3.8718)	pose_text_loss 2.5469 (3.1235)	tot_loss 6.9225 (7.3647)	mem 12001MB
[2024-12-24 22:09:58 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5000/11317]	eta 0:37:33 lr 0.000013090	time 0.3694 (0.3568)	dist_loss 0.0502 (0.0370)	image_text_loss 3.9092 (3.8717)	pose_text_loss 2.7735 (3.1209)	tot_loss 7.1844 (7.3628)	mem 12001MB
[2024-12-24 22:10:16 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5050/11317]	eta 0:37:16 lr 0.000012941	time 0.3582 (0.3568)	dist_loss 0.0344 (0.0371)	image_text_loss 3.8726 (3.8717)	pose_text_loss 2.9620 (3.1186)	tot_loss 7.1784 (7.3613)	mem 12001MB
[2024-12-24 22:10:34 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5100/11317]	eta 0:36:58 lr 0.000012792	time 0.3495 (0.3568)	dist_loss 0.0394 (0.0372)	image_text_loss 3.8382 (3.8717)	pose_text_loss 2.7471 (3.1160)	tot_loss 6.9794 (7.3598)	mem 12001MB
[2024-12-24 22:10:52 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5150/11317]	eta 0:36:40 lr 0.000012642	time 0.3609 (0.3568)	dist_loss 0.0214 (0.0372)	image_text_loss 3.8705 (3.8718)	pose_text_loss 3.2500 (3.1149)	tot_loss 7.3349 (7.3590)	mem 12001MB
[2024-12-24 22:11:10 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5200/11317]	eta 0:36:22 lr 0.000012492	time 0.3574 (0.3568)	dist_loss 0.0604 (0.0372)	image_text_loss 3.8699 (3.8718)	pose_text_loss 2.4864 (3.1139)	tot_loss 6.9604 (7.3581)	mem 12001MB
[2024-12-24 22:11:28 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5250/11317]	eta 0:36:05 lr 0.000012342	time 0.3574 (0.3569)	dist_loss 0.0788 (0.0373)	image_text_loss 3.8713 (3.8718)	pose_text_loss 2.3553 (3.1120)	tot_loss 7.0143 (7.3568)	mem 12001MB
[2024-12-24 22:11:46 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5300/11317]	eta 0:35:47 lr 0.000012192	time 0.3519 (0.3569)	dist_loss 0.0341 (0.0374)	image_text_loss 3.8707 (3.8718)	pose_text_loss 2.9237 (3.1098)	tot_loss 7.1356 (7.3555)	mem 12001MB
[2024-12-24 22:12:03 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5350/11317]	eta 0:35:29 lr 0.000012041	time 0.3654 (0.3569)	dist_loss 0.0458 (0.0374)	image_text_loss 3.8815 (3.8718)	pose_text_loss 2.8033 (3.1083)	tot_loss 7.1423 (7.3545)	mem 12001MB
[2024-12-24 22:12:22 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5400/11317]	eta 0:35:11 lr 0.000011891	time 0.3547 (0.3569)	dist_loss 0.0498 (0.0376)	image_text_loss 3.8732 (3.8718)	pose_text_loss 2.7107 (3.1052)	tot_loss 7.0819 (7.3525)	mem 12001MB
[2024-12-24 22:12:39 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5450/11317]	eta 0:34:53 lr 0.000011740	time 0.3560 (0.3569)	dist_loss 0.0463 (0.0376)	image_text_loss 3.8638 (3.8717)	pose_text_loss 2.6689 (3.1032)	tot_loss 6.9960 (7.3512)	mem 12001MB
[2024-12-24 22:12:57 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5500/11317]	eta 0:34:35 lr 0.000011589	time 0.3598 (0.3569)	dist_loss 0.0291 (0.0377)	image_text_loss 3.8860 (3.8717)	pose_text_loss 3.1994 (3.1008)	tot_loss 7.3765 (7.3494)	mem 12001MB
[2024-12-24 22:13:15 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5550/11317]	eta 0:34:18 lr 0.000011438	time 0.3443 (0.3569)	dist_loss 0.0824 (0.0378)	image_text_loss 3.8757 (3.8717)	pose_text_loss 2.2381 (3.0985)	tot_loss 6.9379 (7.3479)	mem 12001MB
[2024-12-24 22:13:33 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5600/11317]	eta 0:34:00 lr 0.000011287	time 0.3572 (0.3569)	dist_loss 0.0500 (0.0379)	image_text_loss 3.8476 (3.8717)	pose_text_loss 2.6391 (3.0959)	tot_loss 6.9872 (7.3461)	mem 12001MB
[2024-12-24 22:13:51 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5650/11317]	eta 0:33:42 lr 0.000011136	time 0.3473 (0.3569)	dist_loss 0.0585 (0.0379)	image_text_loss 3.8730 (3.8716)	pose_text_loss 2.5451 (3.0932)	tot_loss 7.0033 (7.3443)	mem 12001MB
[2024-12-24 22:14:09 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5700/11317]	eta 0:33:24 lr 0.000010985	time 0.3493 (0.3569)	dist_loss 0.0646 (0.0380)	image_text_loss 3.8828 (3.8717)	pose_text_loss 2.4655 (3.0911)	tot_loss 6.9947 (7.3430)	mem 12001MB
[2024-12-24 22:14:26 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5750/11317]	eta 0:33:06 lr 0.000010833	time 0.3566 (0.3569)	dist_loss 0.0144 (0.0381)	image_text_loss 3.8687 (3.8716)	pose_text_loss 3.5998 (3.0891)	tot_loss 7.6125 (7.3415)	mem 12001MB
[2024-12-24 22:14:44 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5800/11317]	eta 0:32:49 lr 0.000010682	time 0.3513 (0.3569)	dist_loss 0.0291 (0.0381)	image_text_loss 3.8738 (3.8716)	pose_text_loss 3.1256 (3.0872)	tot_loss 7.2904 (7.3401)	mem 12001MB
[2024-12-24 22:15:02 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5850/11317]	eta 0:32:31 lr 0.000010531	time 0.3642 (0.3569)	dist_loss 0.0716 (0.0382)	image_text_loss 3.8705 (3.8716)	pose_text_loss 2.3379 (3.0847)	tot_loss 6.9241 (7.3386)	mem 12001MB
[2024-12-24 22:15:20 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5900/11317]	eta 0:32:13 lr 0.000010380	time 0.3608 (0.3569)	dist_loss 0.0615 (0.0383)	image_text_loss 3.8806 (3.8716)	pose_text_loss 2.6023 (3.0836)	tot_loss 7.0980 (7.3378)	mem 12001MB
[2024-12-24 22:15:38 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][5950/11317]	eta 0:31:55 lr 0.000010230	time 0.3598 (0.3569)	dist_loss 0.0306 (0.0383)	image_text_loss 3.8763 (3.8716)	pose_text_loss 3.1641 (3.0817)	tot_loss 7.3467 (7.3367)	mem 12001MB
[2024-12-24 22:15:56 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6000/11317]	eta 0:31:37 lr 0.000010079	time 0.3509 (0.3569)	dist_loss 0.0647 (0.0384)	image_text_loss 3.8723 (3.8716)	pose_text_loss 2.5671 (3.0800)	tot_loss 7.0865 (7.3354)	mem 12001MB
[2024-12-24 22:16:14 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6050/11317]	eta 0:31:19 lr 0.000009929	time 0.3602 (0.3569)	dist_loss 0.0537 (0.0384)	image_text_loss 3.8612 (3.8716)	pose_text_loss 2.5747 (3.0789)	tot_loss 6.9726 (7.3347)	mem 12001MB
[2024-12-24 22:16:31 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6100/11317]	eta 0:31:01 lr 0.000009779	time 0.3548 (0.3569)	dist_loss 0.0280 (0.0385)	image_text_loss 3.8733 (3.8716)	pose_text_loss 3.4757 (3.0777)	tot_loss 7.6294 (7.3338)	mem 12001MB
[2024-12-24 22:16:49 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6150/11317]	eta 0:30:44 lr 0.000009629	time 0.3519 (0.3569)	dist_loss 0.0659 (0.0385)	image_text_loss 3.8725 (3.8716)	pose_text_loss 2.4009 (3.0755)	tot_loss 6.9322 (7.3324)	mem 12001MB
[2024-12-24 22:17:07 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6200/11317]	eta 0:30:26 lr 0.000009479	time 0.3561 (0.3569)	dist_loss 0.0444 (0.0386)	image_text_loss 3.8683 (3.8716)	pose_text_loss 2.7290 (3.0736)	tot_loss 7.0413 (7.3310)	mem 12001MB
[2024-12-24 22:17:25 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6250/11317]	eta 0:30:08 lr 0.000009330	time 0.3766 (0.3569)	dist_loss 0.0181 (0.0387)	image_text_loss 3.8605 (3.8716)	pose_text_loss 3.6327 (3.0717)	tot_loss 7.6738 (7.3299)	mem 12001MB
[2024-12-24 22:17:43 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6300/11317]	eta 0:29:50 lr 0.000009181	time 0.3523 (0.3570)	dist_loss 0.0189 (0.0387)	image_text_loss 3.8504 (3.8716)	pose_text_loss 3.2473 (3.0706)	tot_loss 7.2867 (7.3291)	mem 12001MB
[2024-12-24 22:18:01 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6350/11317]	eta 0:29:32 lr 0.000009032	time 0.3573 (0.3569)	dist_loss 0.0607 (0.0387)	image_text_loss 3.8628 (3.8716)	pose_text_loss 2.4821 (3.0692)	tot_loss 6.9517 (7.3281)	mem 12001MB
[2024-12-24 22:18:18 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6400/11317]	eta 0:29:15 lr 0.000008884	time 0.3514 (0.3569)	dist_loss 0.0481 (0.0388)	image_text_loss 3.8648 (3.8716)	pose_text_loss 2.6256 (3.0674)	tot_loss 6.9710 (7.3270)	mem 12001MB
[2024-12-24 22:18:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6450/11317]	eta 0:28:57 lr 0.000008736	time 0.3559 (0.3570)	dist_loss 0.0375 (0.0389)	image_text_loss 3.8732 (3.8716)	pose_text_loss 2.9217 (3.0648)	tot_loss 7.1701 (7.3254)	mem 12001MB
[2024-12-24 22:18:54 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6500/11317]	eta 0:28:39 lr 0.000008589	time 0.3658 (0.3570)	dist_loss 0.0249 (0.0390)	image_text_loss 3.8725 (3.8716)	pose_text_loss 3.2375 (3.0629)	tot_loss 7.3592 (7.3240)	mem 12001MB
[2024-12-24 22:19:12 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6550/11317]	eta 0:28:21 lr 0.000008442	time 0.3594 (0.3569)	dist_loss 0.0413 (0.0390)	image_text_loss 3.8879 (3.8715)	pose_text_loss 2.7663 (3.0610)	tot_loss 7.0668 (7.3228)	mem 12001MB
[2024-12-24 22:19:30 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6600/11317]	eta 0:28:03 lr 0.000008296	time 0.3548 (0.3570)	dist_loss 0.0196 (0.0391)	image_text_loss 3.8743 (3.8715)	pose_text_loss 3.5029 (3.0593)	tot_loss 7.5727 (7.3216)	mem 12001MB
[2024-12-24 22:19:48 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6650/11317]	eta 0:27:45 lr 0.000008150	time 0.3533 (0.3570)	dist_loss 0.0398 (0.0391)	image_text_loss 3.8844 (3.8715)	pose_text_loss 2.8275 (3.0580)	tot_loss 7.1097 (7.3207)	mem 12001MB
[2024-12-24 22:20:06 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6700/11317]	eta 0:27:27 lr 0.000008005	time 0.3522 (0.3569)	dist_loss 0.0510 (0.0392)	image_text_loss 3.8843 (3.8715)	pose_text_loss 2.6253 (3.0558)	tot_loss 7.0193 (7.3193)	mem 12001MB
[2024-12-24 22:20:23 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6750/11317]	eta 0:27:10 lr 0.000007861	time 0.3462 (0.3569)	dist_loss 0.0665 (0.0393)	image_text_loss 3.8718 (3.8715)	pose_text_loss 2.4462 (3.0534)	tot_loss 6.9832 (7.3178)	mem 12001MB
[2024-12-24 22:20:41 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6800/11317]	eta 0:26:52 lr 0.000007717	time 0.3553 (0.3569)	dist_loss 0.0310 (0.0393)	image_text_loss 3.8677 (3.8715)	pose_text_loss 3.1647 (3.0520)	tot_loss 7.3421 (7.3170)	mem 12001MB
[2024-12-24 22:20:59 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6850/11317]	eta 0:26:34 lr 0.000007573	time 0.3618 (0.3569)	dist_loss 0.0665 (0.0394)	image_text_loss 3.8738 (3.8715)	pose_text_loss 2.4345 (3.0492)	tot_loss 6.9734 (7.3152)	mem 12001MB
[2024-12-24 22:21:17 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6900/11317]	eta 0:26:16 lr 0.000007431	time 0.3481 (0.3569)	dist_loss 0.0504 (0.0395)	image_text_loss 3.8801 (3.8715)	pose_text_loss 2.6717 (3.0477)	tot_loss 7.0559 (7.3143)	mem 12001MB
[2024-12-24 22:21:35 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][6950/11317]	eta 0:25:58 lr 0.000007289	time 0.3506 (0.3569)	dist_loss 0.0658 (0.0395)	image_text_loss 3.8561 (3.8715)	pose_text_loss 2.4109 (3.0464)	tot_loss 6.9249 (7.3133)	mem 12001MB
[2024-12-24 22:21:52 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7000/11317]	eta 0:25:40 lr 0.000007148	time 0.3640 (0.3569)	dist_loss 0.0312 (0.0396)	image_text_loss 3.8730 (3.8715)	pose_text_loss 3.3272 (3.0449)	tot_loss 7.5122 (7.3122)	mem 12001MB
[2024-12-24 22:22:10 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7050/11317]	eta 0:25:22 lr 0.000007007	time 0.3466 (0.3568)	dist_loss 0.0202 (0.0396)	image_text_loss 3.8734 (3.8715)	pose_text_loss 3.3969 (3.0434)	tot_loss 7.4719 (7.3112)	mem 12001MB
[2024-12-24 22:22:27 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7100/11317]	eta 0:25:04 lr 0.000006868	time 0.3544 (0.3568)	dist_loss 0.0504 (0.0397)	image_text_loss 3.8697 (3.8715)	pose_text_loss 2.6324 (3.0417)	tot_loss 7.0059 (7.3102)	mem 12001MB
[2024-12-24 22:22:45 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7150/11317]	eta 0:24:46 lr 0.000006729	time 0.3528 (0.3568)	dist_loss 0.0774 (0.0398)	image_text_loss 3.8699 (3.8715)	pose_text_loss 2.2580 (3.0391)	tot_loss 6.9022 (7.3085)	mem 12001MB
[2024-12-24 22:23:03 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7200/11317]	eta 0:24:28 lr 0.000006591	time 0.3560 (0.3568)	dist_loss 0.0285 (0.0399)	image_text_loss 3.8716 (3.8715)	pose_text_loss 3.2640 (3.0371)	tot_loss 7.4208 (7.3071)	mem 12001MB
[2024-12-24 22:23:21 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7250/11317]	eta 0:24:10 lr 0.000006454	time 0.3491 (0.3568)	dist_loss 0.0120 (0.0399)	image_text_loss 3.8829 (3.8715)	pose_text_loss 3.7999 (3.0350)	tot_loss 7.8033 (7.3058)	mem 12001MB
[2024-12-24 22:23:38 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7300/11317]	eta 0:23:53 lr 0.000006318	time 0.3629 (0.3568)	dist_loss 0.0591 (0.0400)	image_text_loss 3.8682 (3.8715)	pose_text_loss 2.4917 (3.0332)	tot_loss 6.9510 (7.3046)	mem 12001MB
[2024-12-24 22:23:57 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7350/11317]	eta 0:23:35 lr 0.000006182	time 0.3540 (0.3568)	dist_loss 0.0317 (0.0400)	image_text_loss 3.8714 (3.8715)	pose_text_loss 3.0930 (3.0318)	tot_loss 7.2810 (7.3035)	mem 12001MB
[2024-12-24 22:24:15 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7400/11317]	eta 0:23:17 lr 0.000006048	time 0.3566 (0.3568)	dist_loss 0.0419 (0.0401)	image_text_loss 3.8661 (3.8714)	pose_text_loss 2.7536 (3.0305)	tot_loss 7.0384 (7.3027)	mem 12001MB
[2024-12-24 22:24:32 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7450/11317]	eta 0:22:59 lr 0.000005915	time 0.3544 (0.3568)	dist_loss 0.0695 (0.0401)	image_text_loss 3.8708 (3.8714)	pose_text_loss 2.3509 (3.0293)	tot_loss 6.9165 (7.3019)	mem 12001MB
[2024-12-24 22:24:51 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7500/11317]	eta 0:22:42 lr 0.000005782	time 0.3570 (0.3569)	dist_loss 0.0547 (0.0402)	image_text_loss 3.8724 (3.8714)	pose_text_loss 2.6500 (3.0272)	tot_loss 7.0693 (7.3006)	mem 12001MB
[2024-12-24 22:25:08 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7550/11317]	eta 0:22:24 lr 0.000005651	time 0.3585 (0.3569)	dist_loss 0.0231 (0.0402)	image_text_loss 3.8621 (3.8714)	pose_text_loss 3.1172 (3.0259)	tot_loss 7.2100 (7.2996)	mem 12001MB
[2024-12-24 22:25:26 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7600/11317]	eta 0:22:06 lr 0.000005521	time 0.3545 (0.3568)	dist_loss 0.0556 (0.0403)	image_text_loss 3.8331 (3.8713)	pose_text_loss 2.5321 (3.0246)	tot_loss 6.9208 (7.2987)	mem 12001MB
[2024-12-24 22:25:44 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7650/11317]	eta 0:21:48 lr 0.000005392	time 0.3556 (0.3569)	dist_loss 0.0283 (0.0403)	image_text_loss 3.8708 (3.8713)	pose_text_loss 3.0455 (3.0232)	tot_loss 7.1994 (7.2978)	mem 12001MB
[2024-12-24 22:26:02 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7700/11317]	eta 0:21:30 lr 0.000005264	time 0.3582 (0.3569)	dist_loss 0.0661 (0.0404)	image_text_loss 3.8712 (3.8713)	pose_text_loss 2.3942 (3.0216)	tot_loss 6.9269 (7.2968)	mem 12001MB
[2024-12-24 22:26:20 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7750/11317]	eta 0:21:12 lr 0.000005137	time 0.3561 (0.3568)	dist_loss 0.0459 (0.0404)	image_text_loss 3.8751 (3.8713)	pose_text_loss 2.7071 (3.0204)	tot_loss 7.0414 (7.2959)	mem 12001MB
[2024-12-24 22:26:38 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7800/11317]	eta 0:20:55 lr 0.000005011	time 0.3494 (0.3569)	dist_loss 0.0357 (0.0405)	image_text_loss 3.8534 (3.8713)	pose_text_loss 2.8713 (3.0190)	tot_loss 7.0817 (7.2949)	mem 12001MB
[2024-12-24 22:26:55 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7850/11317]	eta 0:20:37 lr 0.000004886	time 0.3448 (0.3569)	dist_loss 0.0612 (0.0405)	image_text_loss 3.8700 (3.8713)	pose_text_loss 2.4285 (3.0180)	tot_loss 6.9110 (7.2943)	mem 12001MB
[2024-12-24 22:27:13 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7900/11317]	eta 0:20:19 lr 0.000004763	time 0.3488 (0.3568)	dist_loss 0.0424 (0.0406)	image_text_loss 3.8734 (3.8713)	pose_text_loss 3.2192 (3.0165)	tot_loss 7.5168 (7.2934)	mem 12001MB
[2024-12-24 22:27:31 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][7950/11317]	eta 0:20:01 lr 0.000004640	time 0.3505 (0.3569)	dist_loss 0.0143 (0.0406)	image_text_loss 3.8710 (3.8713)	pose_text_loss 3.6610 (3.0162)	tot_loss 7.6750 (7.2930)	mem 12001MB
[2024-12-24 22:27:49 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8000/11317]	eta 0:19:43 lr 0.000004520	time 0.3594 (0.3569)	dist_loss 0.0215 (0.0406)	image_text_loss 3.8813 (3.8713)	pose_text_loss 3.4888 (3.0149)	tot_loss 7.5854 (7.2922)	mem 12001MB
[2024-12-24 22:28:07 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8050/11317]	eta 0:19:25 lr 0.000004400	time 0.3519 (0.3569)	dist_loss 0.0818 (0.0407)	image_text_loss 3.8891 (3.8713)	pose_text_loss 2.2263 (3.0131)	tot_loss 6.9335 (7.2910)	mem 12001MB
[2024-12-24 22:28:25 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8100/11317]	eta 0:19:08 lr 0.000004281	time 0.3448 (0.3569)	dist_loss 0.0251 (0.0407)	image_text_loss 3.8742 (3.8713)	pose_text_loss 3.7646 (3.0119)	tot_loss 7.8895 (7.2901)	mem 12001MB
[2024-12-24 22:28:43 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8150/11317]	eta 0:18:50 lr 0.000004164	time 0.3756 (0.3569)	dist_loss 0.0232 (0.0407)	image_text_loss 3.8856 (3.8713)	pose_text_loss 3.6335 (3.0111)	tot_loss 7.7509 (7.2895)	mem 12001MB
[2024-12-24 22:29:01 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8200/11317]	eta 0:18:32 lr 0.000004049	time 0.3522 (0.3569)	dist_loss 0.0260 (0.0407)	image_text_loss 3.8665 (3.8713)	pose_text_loss 3.5084 (3.0102)	tot_loss 7.6354 (7.2888)	mem 12001MB
[2024-12-24 22:29:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8250/11317]	eta 0:18:14 lr 0.000003934	time 0.3556 (0.3569)	dist_loss 0.0192 (0.0408)	image_text_loss 3.8764 (3.8713)	pose_text_loss 3.4746 (3.0081)	tot_loss 7.5432 (7.2876)	mem 12001MB
[2024-12-24 22:29:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8300/11317]	eta 0:17:56 lr 0.000003821	time 0.3488 (0.3569)	dist_loss 0.0553 (0.0408)	image_text_loss 3.8800 (3.8713)	pose_text_loss 2.5386 (3.0076)	tot_loss 6.9717 (7.2871)	mem 12001MB
[2024-12-24 22:29:54 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8350/11317]	eta 0:17:38 lr 0.000003710	time 0.3486 (0.3569)	dist_loss 0.0289 (0.0409)	image_text_loss 3.8710 (3.8713)	pose_text_loss 3.5759 (3.0064)	tot_loss 7.7360 (7.2863)	mem 12001MB
[2024-12-24 22:30:12 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8400/11317]	eta 0:17:21 lr 0.000003599	time 0.3511 (0.3569)	dist_loss 0.0238 (0.0409)	image_text_loss 3.8714 (3.8713)	pose_text_loss 3.5853 (3.0053)	tot_loss 7.6950 (7.2856)	mem 12001MB
[2024-12-24 22:30:30 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8450/11317]	eta 0:17:03 lr 0.000003491	time 0.3523 (0.3569)	dist_loss 0.0348 (0.0409)	image_text_loss 3.8871 (3.8712)	pose_text_loss 3.4931 (3.0041)	tot_loss 7.7280 (7.2847)	mem 12001MB
[2024-12-24 22:30:48 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8500/11317]	eta 0:16:45 lr 0.000003383	time 0.3582 (0.3569)	dist_loss 0.0439 (0.0410)	image_text_loss 3.8715 (3.8712)	pose_text_loss 2.8821 (3.0032)	tot_loss 7.1928 (7.2840)	mem 12001MB
[2024-12-24 22:31:06 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8550/11317]	eta 0:16:27 lr 0.000003278	time 0.3553 (0.3570)	dist_loss 0.0324 (0.0410)	image_text_loss 3.8686 (3.8712)	pose_text_loss 3.1409 (3.0024)	tot_loss 7.3334 (7.2835)	mem 12001MB
[2024-12-24 22:31:24 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8600/11317]	eta 0:16:09 lr 0.000003173	time 0.3593 (0.3569)	dist_loss 0.0269 (0.0410)	image_text_loss 3.9002 (3.8712)	pose_text_loss 3.1931 (3.0020)	tot_loss 7.3627 (7.2832)	mem 12001MB
[2024-12-24 22:31:42 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8650/11317]	eta 0:15:51 lr 0.000003071	time 0.3518 (0.3569)	dist_loss 0.0681 (0.0410)	image_text_loss 3.8855 (3.8712)	pose_text_loss 2.3818 (3.0013)	tot_loss 6.9488 (7.2827)	mem 12001MB
[2024-12-24 22:32:00 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8700/11317]	eta 0:15:34 lr 0.000002970	time 0.3592 (0.3570)	dist_loss 0.0723 (0.0411)	image_text_loss 3.8829 (3.8712)	pose_text_loss 2.3221 (2.9991)	tot_loss 6.9276 (7.2812)	mem 12001MB
[2024-12-24 22:32:17 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8750/11317]	eta 0:15:16 lr 0.000002870	time 0.3651 (0.3569)	dist_loss 0.0320 (0.0411)	image_text_loss 3.8664 (3.8712)	pose_text_loss 3.0120 (2.9984)	tot_loss 7.1980 (7.2808)	mem 12001MB
[2024-12-24 22:32:35 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8800/11317]	eta 0:14:58 lr 0.000002772	time 0.3500 (0.3569)	dist_loss 0.0321 (0.0411)	image_text_loss 3.8576 (3.8712)	pose_text_loss 3.2383 (2.9973)	tot_loss 7.4168 (7.2799)	mem 12001MB
[2024-12-24 22:32:53 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8850/11317]	eta 0:14:40 lr 0.000002675	time 0.3525 (0.3569)	dist_loss 0.0395 (0.0412)	image_text_loss 3.8709 (3.8712)	pose_text_loss 2.8133 (2.9965)	tot_loss 7.0792 (7.2793)	mem 12001MB
[2024-12-24 22:33:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8900/11317]	eta 0:14:22 lr 0.000002581	time 0.3522 (0.3569)	dist_loss 0.0565 (0.0412)	image_text_loss 3.8705 (3.8712)	pose_text_loss 2.5157 (2.9952)	tot_loss 6.9516 (7.2784)	mem 12001MB
[2024-12-24 22:33:29 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][8950/11317]	eta 0:14:04 lr 0.000002488	time 0.3495 (0.3569)	dist_loss 0.0510 (0.0412)	image_text_loss 3.8698 (3.8712)	pose_text_loss 2.6200 (2.9943)	tot_loss 6.9998 (7.2777)	mem 12001MB
[2024-12-24 22:33:47 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9000/11317]	eta 0:13:47 lr 0.000002396	time 0.3543 (0.3569)	dist_loss 0.0812 (0.0413)	image_text_loss 3.8828 (3.8712)	pose_text_loss 2.2179 (2.9935)	tot_loss 6.9131 (7.2772)	mem 12001MB
[2024-12-24 22:34:04 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9050/11317]	eta 0:13:29 lr 0.000002306	time 0.3526 (0.3569)	dist_loss 0.0631 (0.0413)	image_text_loss 3.8763 (3.8712)	pose_text_loss 2.4359 (2.9928)	tot_loss 6.9430 (7.2767)	mem 12001MB
[2024-12-24 22:34:22 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9100/11317]	eta 0:13:11 lr 0.000002218	time 0.3507 (0.3569)	dist_loss 0.0440 (0.0413)	image_text_loss 3.8689 (3.8711)	pose_text_loss 2.7857 (2.9916)	tot_loss 7.0943 (7.2759)	mem 12001MB
[2024-12-24 22:34:40 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9150/11317]	eta 0:12:53 lr 0.000002132	time 0.3524 (0.3569)	dist_loss 0.0679 (0.0414)	image_text_loss 3.8703 (3.8711)	pose_text_loss 2.3588 (2.9900)	tot_loss 6.9079 (7.2749)	mem 12001MB
[2024-12-24 22:34:58 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9200/11317]	eta 0:12:35 lr 0.000002047	time 0.3542 (0.3569)	dist_loss 0.0744 (0.0414)	image_text_loss 3.8789 (3.8711)	pose_text_loss 2.3152 (2.9892)	tot_loss 6.9380 (7.2743)	mem 12001MB
[2024-12-24 22:35:16 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9250/11317]	eta 0:12:17 lr 0.000001964	time 0.3433 (0.3569)	dist_loss 0.0564 (0.0414)	image_text_loss 3.8712 (3.8711)	pose_text_loss 2.5223 (2.9882)	tot_loss 6.9570 (7.2736)	mem 12001MB
[2024-12-24 22:35:33 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9300/11317]	eta 0:11:59 lr 0.000001883	time 0.3417 (0.3569)	dist_loss 0.0230 (0.0415)	image_text_loss 3.8582 (3.8711)	pose_text_loss 3.0360 (2.9872)	tot_loss 7.1237 (7.2730)	mem 12001MB
[2024-12-24 22:35:51 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9350/11317]	eta 0:11:41 lr 0.000001804	time 0.3480 (0.3569)	dist_loss 0.0312 (0.0415)	image_text_loss 3.8691 (3.8711)	pose_text_loss 3.1565 (2.9862)	tot_loss 7.3373 (7.2723)	mem 12001MB
[2024-12-24 22:36:09 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9400/11317]	eta 0:11:24 lr 0.000001726	time 0.3530 (0.3569)	dist_loss 0.0334 (0.0415)	image_text_loss 3.8709 (3.8711)	pose_text_loss 3.0938 (2.9852)	tot_loss 7.2991 (7.2716)	mem 12001MB
[2024-12-24 22:36:27 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9450/11317]	eta 0:11:06 lr 0.000001650	time 0.3537 (0.3569)	dist_loss 0.0234 (0.0416)	image_text_loss 3.8671 (3.8711)	pose_text_loss 3.3561 (2.9842)	tot_loss 7.4575 (7.2710)	mem 12001MB
[2024-12-24 22:36:44 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9500/11317]	eta 0:10:48 lr 0.000001576	time 0.3520 (0.3569)	dist_loss 0.0315 (0.0416)	image_text_loss 3.8890 (3.8711)	pose_text_loss 3.0883 (2.9832)	tot_loss 7.2922 (7.2704)	mem 12001MB
[2024-12-24 22:37:02 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9550/11317]	eta 0:10:30 lr 0.000001504	time 0.3619 (0.3569)	dist_loss 0.0377 (0.0417)	image_text_loss 3.8744 (3.8711)	pose_text_loss 2.8672 (2.9818)	tot_loss 7.1189 (7.2695)	mem 12001MB
[2024-12-24 22:37:20 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9600/11317]	eta 0:10:12 lr 0.000001434	time 0.3720 (0.3569)	dist_loss 0.0485 (0.0417)	image_text_loss 3.8729 (3.8711)	pose_text_loss 2.7026 (2.9809)	tot_loss 7.0610 (7.2689)	mem 12001MB
[2024-12-24 22:37:38 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9650/11317]	eta 0:09:54 lr 0.000001365	time 0.3523 (0.3569)	dist_loss 0.0850 (0.0417)	image_text_loss 3.8715 (3.8711)	pose_text_loss 2.2100 (2.9803)	tot_loss 6.9317 (7.2684)	mem 12001MB
[2024-12-24 22:37:56 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9700/11317]	eta 0:09:37 lr 0.000001299	time 0.3518 (0.3568)	dist_loss 0.0253 (0.0417)	image_text_loss 3.8718 (3.8711)	pose_text_loss 3.5478 (2.9798)	tot_loss 7.6731 (7.2682)	mem 12001MB
[2024-12-24 22:38:14 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9750/11317]	eta 0:09:19 lr 0.000001234	time 0.3518 (0.3569)	dist_loss 0.0490 (0.0418)	image_text_loss 3.8665 (3.8711)	pose_text_loss 2.6605 (2.9785)	tot_loss 7.0168 (7.2673)	mem 12001MB
[2024-12-24 22:38:31 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9800/11317]	eta 0:09:01 lr 0.000001171	time 0.3586 (0.3568)	dist_loss 0.0593 (0.0418)	image_text_loss 3.9024 (3.8711)	pose_text_loss 2.4960 (2.9776)	tot_loss 6.9915 (7.2666)	mem 12001MB
[2024-12-24 22:38:49 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9850/11317]	eta 0:08:43 lr 0.000001111	time 0.3483 (0.3568)	dist_loss 0.0528 (0.0418)	image_text_loss 3.8635 (3.8711)	pose_text_loss 2.6166 (2.9766)	tot_loss 7.0082 (7.2659)	mem 12001MB
[2024-12-24 22:39:07 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9900/11317]	eta 0:08:25 lr 0.000001052	time 0.3704 (0.3569)	dist_loss 0.0266 (0.0418)	image_text_loss 3.8717 (3.8711)	pose_text_loss 3.4626 (2.9761)	tot_loss 7.6004 (7.2655)	mem 12001MB
[2024-12-24 22:39:25 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][9950/11317]	eta 0:08:07 lr 0.000000995	time 0.3531 (0.3569)	dist_loss 0.0653 (0.0419)	image_text_loss 3.8613 (3.8711)	pose_text_loss 2.3888 (2.9752)	tot_loss 6.9029 (7.2649)	mem 12001MB
[2024-12-24 22:39:43 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10000/11317]	eta 0:07:49 lr 0.000000940	time 0.3543 (0.3569)	dist_loss 0.0518 (0.0419)	image_text_loss 3.8693 (3.8711)	pose_text_loss 2.6168 (2.9741)	tot_loss 7.0039 (7.2642)	mem 12001MB
[2024-12-24 22:40:01 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10050/11317]	eta 0:07:32 lr 0.000000887	time 0.3517 (0.3569)	dist_loss 0.0312 (0.0419)	image_text_loss 3.8704 (3.8711)	pose_text_loss 3.1267 (2.9730)	tot_loss 7.3094 (7.2635)	mem 12001MB
[2024-12-24 22:40:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10100/11317]	eta 0:07:14 lr 0.000000836	time 0.3472 (0.3569)	dist_loss 0.0491 (0.0420)	image_text_loss 3.8704 (3.8711)	pose_text_loss 2.6152 (2.9720)	tot_loss 6.9768 (7.2629)	mem 12001MB
[2024-12-24 22:40:36 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10150/11317]	eta 0:06:56 lr 0.000000786	time 0.3557 (0.3569)	dist_loss 0.0542 (0.0420)	image_text_loss 3.8588 (3.8711)	pose_text_loss 2.6477 (2.9715)	tot_loss 7.0488 (7.2625)	mem 12001MB
[2024-12-24 22:40:54 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10200/11317]	eta 0:06:38 lr 0.000000739	time 0.3644 (0.3569)	dist_loss 0.0608 (0.0420)	image_text_loss 3.8664 (3.8711)	pose_text_loss 2.4722 (2.9706)	tot_loss 6.9464 (7.2621)	mem 12001MB
[2024-12-24 22:41:12 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10250/11317]	eta 0:06:20 lr 0.000000694	time 0.3660 (0.3569)	dist_loss 0.0513 (0.0421)	image_text_loss 3.8569 (3.8711)	pose_text_loss 2.5868 (2.9691)	tot_loss 6.9565 (7.2611)	mem 12001MB
[2024-12-24 22:41:30 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10300/11317]	eta 0:06:02 lr 0.000000651	time 0.3712 (0.3568)	dist_loss 0.0400 (0.0421)	image_text_loss 3.8736 (3.8711)	pose_text_loss 2.8862 (2.9684)	tot_loss 7.1598 (7.2606)	mem 12001MB
[2024-12-24 22:41:48 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10350/11317]	eta 0:05:45 lr 0.000000610	time 0.3552 (0.3569)	dist_loss 0.0177 (0.0421)	image_text_loss 3.8656 (3.8711)	pose_text_loss 3.4863 (2.9680)	tot_loss 7.5287 (7.2602)	mem 12001MB
[2024-12-24 22:42:05 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10400/11317]	eta 0:05:27 lr 0.000000571	time 0.3673 (0.3569)	dist_loss 0.0554 (0.0421)	image_text_loss 3.8697 (3.8711)	pose_text_loss 2.5131 (2.9671)	tot_loss 6.9367 (7.2595)	mem 12001MB
[2024-12-24 22:42:23 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10450/11317]	eta 0:05:09 lr 0.000000534	time 0.3615 (0.3568)	dist_loss 0.0128 (0.0422)	image_text_loss 3.8706 (3.8711)	pose_text_loss 3.6663 (2.9662)	tot_loss 7.6653 (7.2589)	mem 12001MB
[2024-12-24 22:42:41 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10500/11317]	eta 0:04:51 lr 0.000000499	time 0.3558 (0.3569)	dist_loss 0.0463 (0.0422)	image_text_loss 3.8663 (3.8711)	pose_text_loss 2.7766 (2.9655)	tot_loss 7.1060 (7.2583)	mem 12001MB
[2024-12-24 22:42:59 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10550/11317]	eta 0:04:33 lr 0.000000466	time 0.3662 (0.3569)	dist_loss 0.0227 (0.0422)	image_text_loss 3.8695 (3.8711)	pose_text_loss 3.1672 (2.9645)	tot_loss 7.2635 (7.2577)	mem 12001MB
[2024-12-24 22:43:17 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10600/11317]	eta 0:04:15 lr 0.000000435	time 0.3511 (0.3568)	dist_loss 0.0664 (0.0423)	image_text_loss 3.8724 (3.8711)	pose_text_loss 2.4365 (2.9632)	tot_loss 6.9734 (7.2569)	mem 12001MB
[2024-12-24 22:43:35 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10650/11317]	eta 0:03:58 lr 0.000000406	time 0.3470 (0.3569)	dist_loss 0.0575 (0.0423)	image_text_loss 3.9140 (3.8711)	pose_text_loss 2.5441 (2.9626)	tot_loss 7.0329 (7.2565)	mem 12001MB
[2024-12-24 22:43:53 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10700/11317]	eta 0:03:40 lr 0.000000379	time 0.3651 (0.3569)	dist_loss 0.0595 (0.0423)	image_text_loss 3.8907 (3.8711)	pose_text_loss 2.5135 (2.9617)	tot_loss 6.9989 (7.2558)	mem 12001MB
[2024-12-24 22:44:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10750/11317]	eta 0:03:22 lr 0.000000355	time 0.3592 (0.3569)	dist_loss 0.0249 (0.0423)	image_text_loss 3.8753 (3.8711)	pose_text_loss 3.2632 (2.9608)	tot_loss 7.3878 (7.2552)	mem 12001MB
[2024-12-24 22:44:29 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10800/11317]	eta 0:03:04 lr 0.000000332	time 0.3509 (0.3569)	dist_loss 0.0825 (0.0423)	image_text_loss 3.8658 (3.8711)	pose_text_loss 2.1982 (2.9601)	tot_loss 6.8886 (7.2547)	mem 12001MB
[2024-12-24 22:44:47 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10850/11317]	eta 0:02:46 lr 0.000000311	time 0.3477 (0.3569)	dist_loss 0.0518 (0.0424)	image_text_loss 3.8703 (3.8711)	pose_text_loss 2.6414 (2.9592)	tot_loss 7.0301 (7.2541)	mem 12001MB
[2024-12-24 22:45:04 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10900/11317]	eta 0:02:28 lr 0.000000293	time 0.3498 (0.3569)	dist_loss 0.0653 (0.0424)	image_text_loss 3.8823 (3.8711)	pose_text_loss 2.4033 (2.9584)	tot_loss 6.9391 (7.2535)	mem 12001MB
[2024-12-24 22:45:22 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][10950/11317]	eta 0:02:10 lr 0.000000276	time 0.3552 (0.3569)	dist_loss 0.0295 (0.0424)	image_text_loss 3.8718 (3.8711)	pose_text_loss 3.1112 (2.9582)	tot_loss 7.2782 (7.2534)	mem 12001MB
[2024-12-24 22:45:40 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11000/11317]	eta 0:01:53 lr 0.000000262	time 0.3518 (0.3569)	dist_loss 0.0304 (0.0425)	image_text_loss 3.8560 (3.8710)	pose_text_loss 2.9604 (2.9571)	tot_loss 7.1199 (7.2527)	mem 12001MB
[2024-12-24 22:45:58 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11050/11317]	eta 0:01:35 lr 0.000000250	time 0.4312 (0.3569)	dist_loss 0.0436 (0.0425)	image_text_loss 3.8595 (3.8710)	pose_text_loss 2.7359 (2.9563)	tot_loss 7.0314 (7.2521)	mem 12001MB
[2024-12-24 22:46:16 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11100/11317]	eta 0:01:17 lr 0.000000240	time 0.3565 (0.3569)	dist_loss 0.0200 (0.0425)	image_text_loss 3.8677 (3.8710)	pose_text_loss 3.3345 (2.9558)	tot_loss 7.4024 (7.2517)	mem 12001MB
[2024-12-24 22:46:34 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11150/11317]	eta 0:00:59 lr 0.000000232	time 0.3612 (0.3569)	dist_loss 0.0603 (0.0425)	image_text_loss 3.8652 (3.8710)	pose_text_loss 2.4808 (2.9552)	tot_loss 6.9485 (7.2512)	mem 12001MB
[2024-12-24 22:46:52 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11200/11317]	eta 0:00:41 lr 0.000000226	time 0.3601 (0.3569)	dist_loss 0.0232 (0.0425)	image_text_loss 3.8729 (3.8710)	pose_text_loss 3.1948 (2.9546)	tot_loss 7.2994 (7.2508)	mem 12001MB
[2024-12-24 22:47:10 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11250/11317]	eta 0:00:23 lr 0.000000222	time 0.3548 (0.3569)	dist_loss 0.0605 (0.0425)	image_text_loss 3.8848 (3.8710)	pose_text_loss 2.4855 (2.9539)	tot_loss 6.9748 (7.2503)	mem 12001MB
[2024-12-24 22:47:28 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][11300/11317]	eta 0:00:06 lr 0.000000220	time 0.3535 (0.3569)	dist_loss 0.0414 (0.0425)	image_text_loss 3.8693 (3.8710)	pose_text_loss 3.2428 (2.9538)	tot_loss 7.5258 (7.2502)	mem 12001MB
[2024-12-24 22:47:33 ViT-B/16] (CL_main_v2.py 290): INFO EPOCH 0 training takes 1:07:19
[2024-12-24 22:47:33 ViT-B/16] (CL_main_v2.py 307): INFO 1 views inference
[2024-12-24 22:47:34 ViT-B/16] (CL_main_v2.py 379): INFO Test: [0/250]	Acc@1 for Image-Text: 0.000	mCA for Image-Text: 0.000	
[2024-12-24 22:47:34 ViT-B/16] (CL_main_v2.py 379): INFO Test: [0/250]	Acc@1 for Text-Pose: 100.000	mCA for Text-Pose: 4.167	
[2024-12-24 22:47:34 ViT-B/16] (CL_main_v2.py 379): INFO Test: [0/250]	Acc@1 for Image-Text-Pose: 100.000	mCA for Image-Text-Pose: 4.167	
[2024-12-24 22:47:42 ViT-B/16] (CL_main_v2.py 379): INFO Test: [50/250]	Acc@1 for Image-Text: 3.922	mCA for Image-Text: 3.125	
[2024-12-24 22:47:42 ViT-B/16] (CL_main_v2.py 379): INFO Test: [50/250]	Acc@1 for Text-Pose: 74.510	mCA for Text-Pose: 64.531	
[2024-12-24 22:47:42 ViT-B/16] (CL_main_v2.py 379): INFO Test: [50/250]	Acc@1 for Image-Text-Pose: 74.510	mCA for Image-Text-Pose: 64.531	
[2024-12-24 22:47:49 ViT-B/16] (CL_main_v2.py 379): INFO Test: [100/250]	Acc@1 for Image-Text: 4.455	mCA for Image-Text: 4.167	
[2024-12-24 22:47:49 ViT-B/16] (CL_main_v2.py 379): INFO Test: [100/250]	Acc@1 for Text-Pose: 71.782	mCA for Text-Pose: 71.152	
[2024-12-24 22:47:49 ViT-B/16] (CL_main_v2.py 379): INFO Test: [100/250]	Acc@1 for Image-Text-Pose: 71.782	mCA for Image-Text-Pose: 71.152	
[2024-12-24 22:47:56 ViT-B/16] (CL_main_v2.py 379): INFO Test: [150/250]	Acc@1 for Image-Text: 5.298	mCA for Image-Text: 4.187	
[2024-12-24 22:47:56 ViT-B/16] (CL_main_v2.py 379): INFO Test: [150/250]	Acc@1 for Text-Pose: 72.517	mCA for Text-Pose: 71.831	
[2024-12-24 22:47:56 ViT-B/16] (CL_main_v2.py 379): INFO Test: [150/250]	Acc@1 for Image-Text-Pose: 72.517	mCA for Image-Text-Pose: 71.831	
[2024-12-24 22:48:03 ViT-B/16] (CL_main_v2.py 379): INFO Test: [200/250]	Acc@1 for Image-Text: 5.224	mCA for Image-Text: 3.778	
[2024-12-24 22:48:03 ViT-B/16] (CL_main_v2.py 379): INFO Test: [200/250]	Acc@1 for Text-Pose: 72.637	mCA for Text-Pose: 70.398	
[2024-12-24 22:48:03 ViT-B/16] (CL_main_v2.py 379): INFO Test: [200/250]	Acc@1 for Image-Text-Pose: 72.637	mCA for Image-Text-Pose: 70.398	
[2024-12-24 22:48:10 ViT-B/16] (CL_main_v2.py 406): INFO  * Acc@1 for Image-Text: 3.150 Acc@5 for Image-Text: 12.600 mCA for Image-Text: 2.885
[2024-12-24 22:48:10 ViT-B/16] (CL_main_v2.py 406): INFO  * Acc@1 for Text-Pose: 70.550 Acc@5 for Text-Pose: 86.350 mCA for Text-Pose: 71.699
[2024-12-24 22:48:10 ViT-B/16] (CL_main_v2.py 406): INFO  * Acc@1 for Image-Text-Pose: 70.550 Acc@5 for Image-Text-Pose: 86.400 mCA for Image-Text-Pose: 71.696
[2024-12-24 22:48:10 ViT-B/16] (CL_main_v2.py 157): INFO Accuracy of the network on the 2004 test videos on Image-Text: 3.1%. mCA: 2.9
[2024-12-24 22:48:10 ViT-B/16] (CL_main_v2.py 165): INFO Max accuracy: 3.15%
