[2024-12-24 21:35:50 ViT-B/16] (CL_main_v2.py 442): INFO working dir: ./workdirs/TEST_P2_SKIViFiCLIP_zs_48_25Dec24/
[2024-12-24 21:35:50 ViT-B/16] (CL_main_v2.py 446): INFO AUG:
  COLOR_JITTER: 0.8
  CUTMIX: 1.0
  GRAY_SCALE: 0.2
  LABEL_SMOOTH: 0.1
  MIXUP: 0.8
  MIXUP_SWITCH_PROB: 0.5
BASE: ['']
DATA:
  ASYNC_LOADING: False
  DATASET: ntu60
  INPUT_SIZE: 224
  LABEL_LIST: /data/users/asinha13/ntu/ntu60_cs_zero_shot_AS_2Nov23/zsl_48-12_base_class_labels.csv
  NUM_CLASSES: 48
  NUM_FRAMES: 16
  ROOT: /data/ntu/NTU60_224x224/rgb
  SKELETON_DATA: /data/vidlab_datasets/ntu/Hyperformer_processed_data/NTU60_CS.npz
  TRAIN_FILE: /data/users/asinha13/ntu/ntu60_cs_zero_shot_AS_2Nov23/zsl_48-12_ntu60_base_train_data_v2.csv
  VAL_FILE: /data/users/asinha13/ntu/ntu60_cs_zero_shot_AS_2Nov23/zsl_48-12_ntu60_base_val_data_v2.csv
LOCAL_RANK: 0
MODEL:
  ARCH: ViT-B/16
  DROP_PATH_RATE: 0.0
  FIX_TEXT: True
  GRAPH: graph.ntu_rgb_d.Graph
  JOINT_LABEL: [0, 4, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 3, 3, 3, 2, 3, 3, 3, 1, 0, 1, 0, 1]
  LABELING_MODE: spatial
  POSE_MODEL: trainers.Hyperformer.Hyperformer_Model
  PRETRAINED: None
  RESUME: ./workdirs/TEST_P1_SKeletonCLIP_alltrn_HFinit_zs_48_17Dec24/ckpt_epoch_0.pth
  RESUME_POSE: /data/users/asinha13/projects/CLIP4ADL/model_chkpnts/ntu_CS_P1_HF_pretrain_frzn_txt_zs_48_AS_16Jan24/ckpt_epoch_99.pth
OUTPUT: ./workdirs/TEST_P2_SKIViFiCLIP_zs_48_25Dec24/
PRINT_FREQ: 50
SAVE_FREQ: 25
SEED: 1024
TEST:
  MULTI_VIEW_INFERENCE: False
  NUM_CLIP: 1
  NUM_CROP: 1
  ONLY_TEST: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: False
  BATCH_SIZE: 1
  CLIP_GRAD: 1.0
  EPOCHS: 1
  LOSS_SCALE: 10.0
  LR: 2.2e-05
  LR_SCHEDULER: cosine
  OPTIMIZER: adamw
  OPT_LEVEL: O1
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 0
  WEIGHT_DECAY: 0.001
TRAINER:
  SKI_VLM:
    CTX_INIT: a photo of a
    N_CTX_TEXT: 0
    N_CTX_VISION: 0
    PROMPT_DEPTH_TEXT: 1
    PROMPT_DEPTH_VISION: 0
    PROMPT_MODEL: False
    USE: both
    ZS_EVAL: False
[2024-12-24 21:36:05 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 261): INFO Loading CLIP (backbone: ViT-B/16)
[2024-12-24 21:36:09 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 265): INFO Building Model
[2024-12-24 21:36:09 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 282): INFO Turning on gradients for COMPLETE SKI_VLM model
[2024-12-24 21:36:09 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 315): INFO Parameters to be updated: {'hyperformer_model.l5.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.9.ln_2.weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'text_encoder.transformer.resblocks.10.ln_2.bias', 'image_encoder.transformer.resblocks.7.ln_2.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l3.vit1.attn.proj.weight', 'image_encoder.class_embedding', 'hyperformer_model.l5.residual.bn.weight', 'clip_text_encoder.text_projection', 'hyperformer_model.l10.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l7.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l3.vit1.attn.rpe', 'hyperformer_model.l1.residual.bn.bias', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'hyperformer_model.l7.tcn1.branches.1.1.bias', 'hyperformer_model.l3.tcn1.branches.1.1.bias', 'hyperformer_model.l9.tcn1.branches.1.0.bias', 'image_encoder.proj', 'image_encoder.transformer.resblocks.6.ln_2.weight', 'clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l6.vit1.attn.outer', 'hyperformer_model.l5.residual.conv.weight', 'hyperformer_model.l8.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l9.vit1.attn.w1', 'hyperformer_model.l1.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l7.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l7.tcn1.branches.0.3.conv.bias', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'hyperformer_model.l2.tcn1.branches.3.1.weight', 'hyperformer_model.l1.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'image_encoder.positional_embedding', 'hyperformer_model.l5.tcn1.branches.2.0.bias', 'hyperformer_model.l6.tcn1.branches.1.1.weight', 'hyperformer_model.l3.tcn1.branches.1.1.weight', 'hyperformer_model.l4.vit1.attn.proj.weight', 'hyperformer_model.l6.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.4.ln_2.weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'hyperformer_model.l6.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'hyperformer_model.l3.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'hyperformer_model.l9.tcn1.branches.0.0.weight', 'hyperformer_model.l4.vit1.pe_proj.weight', 'hyperformer_model.l9.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'hyperformer_model.l4.vit1.norm1.weight', 'image_encoder.ln_pre.weight', 'image_encoder.transformer.resblocks.6.ln_2.bias', 'hyperformer_model.l10.tcn1.branches.1.0.weight', 'hyperformer_model.l1.residual.conv.weight', 'hyperformer_model.l10.vit1.attn.outer', 'clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'hyperformer_model.l5.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'text_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l1.tcn1.branches.1.1.bias', 'text_encoder.ln_final.weight', 'hyperformer_model.l6.tcn1.branches.0.0.weight', 'hyperformer_model.l9.vit1.pe_proj.weight', 'hyperformer_model.l2.vit1.attn.w1', 'hyperformer_model.l5.vit1.norm1.bias', 'hyperformer_model.l7.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'hyperformer_model.l8.vit1.attn.rpe', 'image_encoder.transformer.resblocks.3.ln_1.weight', 'image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.9.ln_1.weight', 'text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.9.ln_1.bias', 'image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'hyperformer_model.l3.tcn1.branches.3.1.weight', 'hyperformer_model.l7.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l1.vit1.skip_proj.weight', 'hyperformer_model.l1.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l1.vit1.attn.proj.bias', 'hyperformer_model.l7.vit1.norm1.bias', 'hyperformer_model.l8.tcn1.branches.3.0.bias', 'clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.3.0.weight', 'image_encoder.transformer.resblocks.8.ln_1.weight', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'hyperformer_model.l4.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'hyperformer_model.l2.tcn1.branches.2.0.bias', 'hyperformer_model.l8.vit1.attn.outer', 'image_encoder.transformer.resblocks.11.ln_1.weight', 'clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'hyperformer_model.fc2.weight', 'hyperformer_model.l7.vit1.attn.alpha', 'image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.4.ln_1.weight', 'hyperformer_model.l4.tcn1.branches.3.1.bias', 'clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l2.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'hyperformer_model.l6.tcn1.branches.1.3.bn.weight', 'text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'hyperformer_model.l2.vit1.attn.alpha', 'clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'hyperformer_model.l8.tcn1.branches.2.4.weight', 'hyperformer_model.l2.tcn1.branches.1.3.bn.weight', 'clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l3.tcn1.branches.2.0.bias', 'image_encoder.transformer.resblocks.4.ln_2.bias', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'hyperformer_model.l7.tcn1.branches.0.0.bias', 'hyperformer_model.l5.vit1.attn.alpha', 'hyperformer_model.l2.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'hyperformer_model.l10.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l2.vit1.pe_proj.weight', 'image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l1.vit1.norm1.bias', 'text_encoder.transformer.resblocks.7.ln_2.bias', 'hyperformer_model.l1.tcn1.branches.1.0.weight', 'hyperformer_model.l8.vit1.attn.alpha', 'hyperformer_model.l4.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.6.ln_1.bias', 'hyperformer_model.l9.tcn1.branches.0.3.conv.weight', 'image_encoder.transformer.resblocks.3.ln_1.bias', 'image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'text_encoder.transformer.resblocks.5.ln_2.bias', 'hyperformer_model.l9.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l9.vit1.norm1.weight', 'hyperformer_model.l4.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'text_encoder.ln_final.bias', 'hyperformer_model.l3.tcn1.branches.2.0.weight', 'hyperformer_model.data_bn.bias', 'image_encoder.transformer.resblocks.4.ln_1.bias', 'image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'hyperformer_model.l8.tcn1.branches.0.1.weight', 'hyperformer_model.l10.tcn1.branches.1.3.bn.weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'hyperformer_model.l9.tcn1.branches.2.0.bias', 'text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'image_encoder.ln_pre.bias', 'text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.7.ln_1.bias', 'clip_text_encoder.positional_embedding', 'hyperformer_model.l9.tcn1.branches.3.1.bias', 'text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'hyperformer_model.l7.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.2.ln_2.bias', 'text_encoder.transformer.resblocks.8.ln_1.weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'text_encoder.transformer.resblocks.11.ln_2.weight', 'text_encoder.transformer.resblocks.4.ln_1.bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'hyperformer_model.l2.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l5.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l10.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'hyperformer_model.l1.vit1.attn.w1', 'hyperformer_model.l1.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l7.vit1.attn.rpe', 'image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'hyperformer_model.l1.tcn1.branches.3.0.bias', 'hyperformer_model.l8.tcn1.branches.2.0.bias', 'hyperformer_model.l3.tcn1.branches.0.0.weight', 'hyperformer_model.l9.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l8.tcn1.branches.1.3.conv.bias', 'image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l10.tcn1.branches.2.1.weight', 'hyperformer_model.l9.vit1.attn.alpha', 'hyperformer_model.l3.tcn1.branches.0.3.bn.weight', 'text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'hyperformer_model.l4.vit1.attn.proj.bias', 'hyperformer_model.l7.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l4.tcn1.branches.2.0.bias', 'hyperformer_model.l7.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l1.vit1.attn.proj.weight', 'hyperformer_model.l8.tcn1.branches.3.1.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'hyperformer_model.l1.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.11.ln_2.bias', 'hyperformer_model.l4.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l8.tcn1.branches.3.0.weight', 'image_encoder.ln_post.weight', 'hyperformer_model.l5.vit1.attn.w1', 'hyperformer_model.l6.vit1.attn.alpha', 'image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'hyperformer_model.l8.tcn1.branches.1.1.bias', 'hyperformer_model.l2.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'hyperformer_model.l5.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.8.ln_1.bias', 'text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l3.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l5.vit1.attn.outer', 'image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'hyperformer_model.l10.tcn1.branches.0.1.bias', 'hyperformer_model.l2.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l7.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.1.3.bn.weight', 'text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'hyperformer_model.l4.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l3.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l8.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.5.ln_1.weight', 'hyperformer_model.l9.tcn1.branches.3.0.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'hyperformer_model.l6.vit1.norm1.bias', 'text_encoder.transformer.resblocks.0.ln_2.bias', 'hyperformer_model.l4.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'hyperformer_model.l6.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l6.tcn1.branches.3.0.bias', 'hyperformer_model.l8.tcn1.branches.0.1.bias', 'hyperformer_model.l9.tcn1.branches.3.0.weight', 'hyperformer_model.l10.vit1.attn.proj.weight', 'hyperformer_model.l10.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l3.tcn1.branches.2.4.weight', 'hyperformer_model.l3.vit1.attn.w1', 'image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'hyperformer_model.l8.tcn1.branches.1.0.weight', 'hyperformer_model.l10.vit1.attn.proj.bias', 'text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.7.ln_1.weight', 'text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.2.0.bias', 'hyperformer_model.l7.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'hyperformer_model.l2.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l10.tcn1.branches.1.1.bias', 'hyperformer_model.l8.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'image_encoder.transformer.resblocks.0.ln_2.weight', 'image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'hyperformer_model.l10.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'hyperformer_model.l5.tcn1.branches.1.3.conv.bias', 'image_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l6.tcn1.branches.2.1.weight', 'hyperformer_model.l10.tcn1.branches.2.4.bias', 'text_encoder.transformer.resblocks.5.ln_1.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'hyperformer_model.l6.tcn1.branches.0.1.weight', 'hyperformer_model.l9.tcn1.branches.2.1.bias', 'hyperformer_model.l4.vit1.attn.rpe', 'text_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.l4.vit1.attn.outer', 'clip_text_encoder.ln_final.weight', 'hyperformer_model.l6.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'hyperformer_model.l4.tcn1.branches.1.1.weight', 'hyperformer_model.l5.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l4.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.2.ln_2.weight', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l7.tcn1.branches.1.1.weight', 'hyperformer_model.l3.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l3.tcn1.branches.1.0.bias', 'hyperformer_model.l9.vit1.norm1.bias', 'hyperformer_model.l7.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.8.ln_2.bias', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'text_encoder.positional_embedding', 'hyperformer_model.l3.vit1.attn.alpha', 'text_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l2.vit1.attn.rpe', 'image_encoder.transformer.resblocks.10.ln_1.weight', 'hyperformer_model.l4.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'hyperformer_model.l9.tcn1.branches.1.1.bias', 'image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'hyperformer_model.l2.tcn1.branches.0.1.weight', 'image_encoder.transformer.resblocks.5.ln_2.weight', 'text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'hyperformer_model.l7.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'hyperformer_model.l6.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'image_encoder.transformer.resblocks.1.ln_2.weight', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'hyperformer_model.l4.tcn1.branches.2.4.weight', 'hyperformer_model.l9.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'hyperformer_model.l6.vit1.pe_proj.weight', 'hyperformer_model.l10.tcn1.branches.2.0.bias', 'hyperformer_model.l4.vit1.attn.q.weight', 'hyperformer_model.l7.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'hyperformer_model.l2.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l2.vit1.norm1.weight', 'hyperformer_model.l9.tcn1.branches.1.0.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l1.tcn1.branches.1.0.bias', 'hyperformer_model.l1.tcn1.branches.1.1.weight', 'hyperformer_model.l6.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'hyperformer_model.l3.vit1.attn.proj.bias', 'text_encoder.transformer.resblocks.2.ln_1.weight', 'image_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.l9.vit1.attn.q.weight', 'text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l3.vit1.norm1.bias', 'hyperformer_model.l5.tcn1.branches.0.0.bias', 'image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'image_encoder.transformer.resblocks.7.ln_1.bias', 'hyperformer_model.l8.tcn1.branches.1.1.weight', 'hyperformer_model.l8.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'hyperformer_model.l2.tcn1.branches.2.0.weight', 'hyperformer_model.l10.vit1.attn.w1', 'text_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l6.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l7.tcn1.branches.2.4.bias', 'hyperformer_model.l6.vit1.attn.q.weight', 'hyperformer_model.l3.tcn1.branches.2.4.bias', 'text_encoder.transformer.resblocks.8.ln_1.bias', 'clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l8.vit1.attn.proj.weight', 'hyperformer_model.l10.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l2.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l5.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l10.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'hyperformer_model.l9.tcn1.branches.1.1.weight', 'clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'text_encoder.transformer.resblocks.9.ln_2.weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'hyperformer_model.l1.vit1.attn.rpe', 'text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'text_encoder.transformer.resblocks.4.ln_2.bias', 'clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l4.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l8.residual.conv.weight', 'hyperformer_model.l9.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'hyperformer_model.l5.tcn1.branches.0.1.bias', 'hyperformer_model.l8.vit1.attn.w1', 'text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.0.3.bn.bias', 'image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'hyperformer_model.l1.tcn1.branches.3.1.weight', 'hyperformer_model.l5.vit1.attn.proj.weight', 'hyperformer_model.l8.tcn1.branches.1.0.bias', 'hyperformer_model.l2.vit1.norm1.bias', 'image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'hyperformer_model.l5.tcn1.branches.2.1.bias', 'text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.l8.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.10.ln_2.weight', 'hyperformer_model.l5.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l9.tcn1.branches.1.3.conv.bias', 'image_encoder.transformer.resblocks.10.ln_2.bias', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.2.4.bias', 'text_encoder.transformer.resblocks.11.ln_2.bias', 'clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'hyperformer_model.l6.vit1.attn.kv.weight', 'hyperformer_model.l10.vit1.norm1.weight', 'image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'image_encoder.conv1.weight', 'image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'hyperformer_model.l6.tcn1.branches.2.0.weight', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l5.tcn1.branches.0.3.conv.weight', 'image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.4.ln_1.weight', 'hyperformer_model.l3.tcn1.branches.0.3.conv.bias', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'hyperformer_model.l3.vit1.attn.kv.weight', 'hyperformer_model.l3.tcn1.branches.0.1.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l9.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'text_encoder.transformer.resblocks.2.ln_1.bias', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.l2.vit1.attn.proj.bias', 'hyperformer_model.l9.vit1.attn.rpe', 'image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'hyperformer_model.l7.vit1.norm1.weight', 'image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'hyperformer_model.l5.tcn1.branches.2.4.weight', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'hyperformer_model.l3.tcn1.branches.3.0.weight', 'hyperformer_model.l2.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l6.vit1.attn.w1', 'hyperformer_model.l3.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'hyperformer_model.l1.vit1.attn.outer', 'image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l10.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.1.ln_1.weight', 'hyperformer_model.l8.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'text_encoder.transformer.resblocks.1.ln_2.weight', 'text_encoder.transformer.resblocks.6.ln_1.weight', 'clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'text_encoder.transformer.resblocks.2.ln_2.weight', 'hyperformer_model.l8.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'hyperformer_model.l5.residual.conv.bias', 'text_encoder.transformer.resblocks.8.ln_2.weight', 'text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'hyperformer_model.l3.tcn1.branches.2.1.bias', 'hyperformer_model.l3.tcn1.branches.1.3.bn.bias', 'text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.0.0.weight', 'hyperformer_model.l6.vit1.norm1.weight', 'text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'hyperformer_model.l4.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l7.vit1.pe_proj.weight', 'hyperformer_model.l1.tcn1.branches.0.0.bias', 'hyperformer_model.l6.tcn1.branches.0.1.bias', 'hyperformer_model.l10.tcn1.branches.2.1.bias', 'hyperformer_model.l8.tcn1.branches.2.4.bias', 'text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'image_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l10.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l4.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'hyperformer_model.l5.vit1.norm1.weight', 'image_encoder.transformer.resblocks.4.ln_2.weight', 'clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'hyperformer_model.l2.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'hyperformer_model.l2.tcn1.branches.1.1.bias', 'hyperformer_model.l7.tcn1.branches.0.1.weight', 'hyperformer_model.l2.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'hyperformer_model.l10.tcn1.branches.0.0.bias', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'hyperformer_model.l2.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l7.tcn1.branches.2.4.weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'hyperformer_model.l4.vit1.norm1.bias', 'hyperformer_model.l3.tcn1.branches.0.1.weight', 'hyperformer_model.l5.tcn1.branches.1.1.weight', 'hyperformer_model.l6.vit1.attn.rpe', 'hyperformer_model.l3.tcn1.branches.1.0.weight', 'hyperformer_model.l6.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l4.tcn1.branches.1.3.bn.bias', 'image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'hyperformer_model.l2.vit1.attn.proj.weight', 'hyperformer_model.l10.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'text_encoder.transformer.resblocks.9.ln_2.bias', 'image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l7.vit1.attn.outer', 'image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'hyperformer_model.l1.vit1.pe_proj.weight', 'text_encoder.transformer.resblocks.6.ln_2.bias', 'hyperformer_model.l10.tcn1.branches.0.0.weight', 'hyperformer_model.l2.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.0.ln_1.bias', 'image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'hyperformer_model.l9.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.6.ln_1.bias', 'image_encoder.transformer.resblocks.3.ln_2.bias', 'image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.2.1.weight', 'hyperformer_model.l10.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.0.ln_2.bias', 'text_encoder.transformer.resblocks.3.ln_2.weight', 'image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'hyperformer_model.l10.vit1.attn.rpe', 'hyperformer_model.l7.vit1.attn.proj.weight', 'hyperformer_model.l10.tcn1.branches.3.0.bias', 'hyperformer_model.data_bn.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.1.ln_1.bias', 'hyperformer_model.l8.vit1.attn.q.weight', 'text_encoder.transformer.resblocks.2.ln_2.bias', 'image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'hyperformer_model.l3.tcn1.branches.0.0.bias', 'hyperformer_model.l10.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l7.vit1.attn.kv.weight', 'hyperformer_model.l5.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l3.tcn1.branches.2.1.weight', 'hyperformer_model.l8.tcn1.branches.2.0.weight', 'hyperformer_model.l3.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l2.vit1.attn.kv.weight', 'text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'hyperformer_model.l1.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'hyperformer_model.l4.tcn1.branches.0.1.bias', 'hyperformer_model.l4.tcn1.branches.0.0.bias', 'hyperformer_model.l9.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l6.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l5.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'hyperformer_model.l5.tcn1.branches.0.0.weight', 'hyperformer_model.l7.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l8.residual.bn.weight', 'hyperformer_model.l1.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'hyperformer_model.l1.tcn1.branches.0.3.bn.bias', 'image_encoder.transformer.resblocks.1.ln_1.bias', 'hyperformer_model.l7.tcn1.branches.3.0.bias', 'hyperformer_model.l10.tcn1.branches.2.4.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'hyperformer_model.l2.tcn1.branches.0.0.bias', 'hyperformer_model.l2.vit1.attn.q.weight', 'hyperformer_model.l8.residual.bn.bias', 'hyperformer_model.l1.residual.bn.weight', 'text_encoder.transformer.resblocks.1.ln_1.weight', 'hyperformer_model.l5.vit1.attn.kv.weight', 'text_encoder.transformer.resblocks.10.ln_2.weight', 'text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l10.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'image_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.5.ln_1.bias', 'text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l1.vit1.norm1.weight', 'hyperformer_model.l9.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l5.residual.bn.bias', 'hyperformer_model.l9.vit1.attn.proj.weight', 'clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'hyperformer_model.l3.vit1.attn.outer', 'hyperformer_model.l6.vit1.attn.proj.weight', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'hyperformer_model.l5.vit1.pe_proj.weight', 'hyperformer_model.l7.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.2.ln_1.weight', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'hyperformer_model.l3.tcn1.branches.3.1.bias', 'hyperformer_model.l8.vit1.attn.proj.bias', 'hyperformer_model.l8.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l8.tcn1.branches.1.3.bn.weight', 'image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'hyperformer_model.l8.vit1.norm1.weight', 'hyperformer_model.l7.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.0.1.weight', 'hyperformer_model.l3.vit1.pe_proj.weight', 'text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.1.0.weight', 'hyperformer_model.l7.vit1.attn.w1', 'text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'hyperformer_model.l8.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'hyperformer_model.l8.vit1.norm1.bias', 'image_encoder.transformer.resblocks.8.ln_2.weight', 'text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'image_encoder.transformer.resblocks.7.ln_2.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'text_encoder.text_projection', 'hyperformer_model.fc2.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'hyperformer_model.l5.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'hyperformer_model.l2.tcn1.branches.3.1.bias', 'hyperformer_model.l4.tcn1.branches.0.1.weight', 'image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.1.3.bn.bias', 'text_encoder.transformer.resblocks.10.ln_1.weight', 'hyperformer_model.l10.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'hyperformer_model.l1.vit1.attn.alpha', 'image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'hyperformer_model.l2.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l7.tcn1.branches.0.1.bias', 'text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'hyperformer_model.l3.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l5.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l9.vit1.attn.kv.weight', 'text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'hyperformer_model.l4.tcn1.branches.2.0.weight', 'clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'hyperformer_model.l10.tcn1.branches.2.0.weight', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'hyperformer_model.l8.vit1.pe_proj.weight', 'text_encoder.transformer.resblocks.11.ln_1.weight', 'hyperformer_model.l5.vit1.attn.proj.bias', 'hyperformer_model.l10.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l2.vit1.attn.outer', 'hyperformer_model.l1.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'hyperformer_model.l1.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'text_encoder.transformer.resblocks.3.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.2.0.weight', 'hyperformer_model.l4.vit1.attn.alpha', 'image_encoder.transformer.resblocks.5.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l10.vit1.attn.alpha', 'text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'clip_text_encoder.ln_final.bias', 'image_encoder.transformer.resblocks.7.ln_1.weight', 'text_encoder.transformer.resblocks.9.ln_1.weight', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'hyperformer_model.l8.residual.conv.bias', 'hyperformer_model.l1.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'hyperformer_model.l9.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.11.ln_2.weight', 'hyperformer_model.l9.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'hyperformer_model.l8.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l5.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'hyperformer_model.l1.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'hyperformer_model.l4.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'hyperformer_model.l1.tcn1.branches.0.1.weight', 'clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'text_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.l9.tcn1.branches.2.4.bias', 'text_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l1.tcn1.branches.2.0.bias', 'hyperformer_model.l1.residual.conv.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'hyperformer_model.l7.tcn1.branches.3.1.bias', 'hyperformer_model.l4.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l6.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'hyperformer_model.l4.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'hyperformer_model.l1.tcn1.branches.3.1.bias', 'hyperformer_model.l5.tcn1.branches.1.0.bias', 'hyperformer_model.l7.tcn1.branches.2.0.bias', 'hyperformer_model.l2.tcn1.branches.2.1.weight', 'hyperformer_model.l6.tcn1.branches.1.3.bn.bias', 'text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'image_encoder.ln_post.bias', 'hyperformer_model.l2.tcn1.branches.1.1.weight', 'hyperformer_model.l5.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'hyperformer_model.l2.tcn1.branches.2.4.bias', 'hyperformer_model.l3.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.9.ln_2.bias', 'image_encoder.transformer.resblocks.9.ln_1.bias', 'hyperformer_model.l1.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'hyperformer_model.l10.vit1.norm1.bias', 'hyperformer_model.l10.vit1.pe_proj.weight', 'image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.1.0.weight', 'hyperformer_model.l6.tcn1.branches.1.1.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'hyperformer_model.l9.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l9.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l6.tcn1.branches.3.1.bias', 'hyperformer_model.l2.tcn1.branches.2.4.weight', 'clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'text_encoder.transformer.resblocks.0.ln_2.weight', 'text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'hyperformer_model.l4.vit1.attn.w1', 'hyperformer_model.l4.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'hyperformer_model.l5.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'text_encoder.transformer.resblocks.3.ln_2.bias', 'hyperformer_model.l8.tcn1.branches.0.0.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.5.ln_1.weight', 'hyperformer_model.l6.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'hyperformer_model.l7.tcn1.branches.3.0.weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l4.tcn1.branches.0.0.weight', 'hyperformer_model.l9.vit1.attn.outer', 'clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.l4.tcn1.branches.1.3.bn.weight'}
[2024-12-24 21:36:09 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 316): INFO Total learnable items: 835
[2024-12-24 21:36:30 ViT-B/16] (tools.py 147): INFO ==============> Resuming from ./workdirs/TEST_P1_SKeletonCLIP_alltrn_HFinit_zs_48_17Dec24/ckpt_epoch_0.pth....................
[2024-12-24 21:36:31 ViT-B/16] (tools.py 172): INFO resume VIFICLIP model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.clip_text_encoder.positional_embedding', 'module.clip_text_encoder.text_projection', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'module.clip_text_encoder.ln_final.weight', 'module.clip_text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:36:31 ViT-B/16] (tools.py 176): INFO ==============> Resuming from /data/users/asinha13/projects/CLIP4ADL/model_chkpnts/ntu_CS_P1_HF_pretrain_frzn_txt_zs_48_AS_16Jan24/ckpt_epoch_99.pth....................
[2024-12-24 21:36:31 ViT-B/16] (tools.py 218): INFO resume Hyperformer model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.text_encoder.positional_embedding', 'module.text_encoder.text_projection', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_1.weight', 'module.text_encoder.transformer.resblocks.0.ln_1.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_2.weight', 'module.text_encoder.transformer.resblocks.0.ln_2.bias', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_1.weight', 'module.text_encoder.transformer.resblocks.1.ln_1.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_2.weight', 'module.text_encoder.transformer.resblocks.1.ln_2.bias', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_1.weight', 'module.text_encoder.transformer.resblocks.2.ln_1.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_2.weight', 'module.text_encoder.transformer.resblocks.2.ln_2.bias', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_1.weight', 'module.text_encoder.transformer.resblocks.3.ln_1.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_2.weight', 'module.text_encoder.transformer.resblocks.3.ln_2.bias', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_1.weight', 'module.text_encoder.transformer.resblocks.4.ln_1.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_2.weight', 'module.text_encoder.transformer.resblocks.4.ln_2.bias', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_1.weight', 'module.text_encoder.transformer.resblocks.5.ln_1.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_2.weight', 'module.text_encoder.transformer.resblocks.5.ln_2.bias', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_1.weight', 'module.text_encoder.transformer.resblocks.6.ln_1.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_2.weight', 'module.text_encoder.transformer.resblocks.6.ln_2.bias', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_1.weight', 'module.text_encoder.transformer.resblocks.7.ln_1.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_2.weight', 'module.text_encoder.transformer.resblocks.7.ln_2.bias', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_1.weight', 'module.text_encoder.transformer.resblocks.8.ln_1.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_2.weight', 'module.text_encoder.transformer.resblocks.8.ln_2.bias', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_1.weight', 'module.text_encoder.transformer.resblocks.9.ln_1.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_2.weight', 'module.text_encoder.transformer.resblocks.9.ln_2.bias', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_1.weight', 'module.text_encoder.transformer.resblocks.10.ln_1.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_2.weight', 'module.text_encoder.transformer.resblocks.10.ln_2.bias', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_1.weight', 'module.text_encoder.transformer.resblocks.11.ln_1.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_2.weight', 'module.text_encoder.transformer.resblocks.11.ln_2.bias', 'module.text_encoder.ln_final.weight', 'module.text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:36:36 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][0/11317]	eta 16:16:16 lr 0.000022000	time 5.1759 (5.1759)	dist_loss 0.4401 (0.4401)	image_text_loss 3.8434 (3.8434)	pose_text_loss 3.1540 (3.1540)	tot_loss 11.3981 (11.3981)	mem 29650MB
[2024-12-24 21:36:53 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][50/11317]	eta 1:22:39 lr 0.000021999	time 0.3500 (0.4401)	dist_loss 0.0061 (0.1055)	image_text_loss 3.8884 (3.8754)	pose_text_loss 3.8570 (3.7149)	tot_loss 7.8062 (8.6450)	mem 29650MB
[2024-12-24 21:37:11 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][100/11317]	eta 1:14:16 lr 0.000021996	time 0.3599 (0.3973)	dist_loss 0.0150 (0.0609)	image_text_loss 3.7708 (3.8737)	pose_text_loss 3.6946 (3.7335)	tot_loss 7.6154 (8.2166)	mem 29650MB
[2024-12-24 21:38:19 ViT-B/16] (CL_main_v2.py 442): INFO working dir: ./workdirs/TEST_P2_SKIViFiCLIP_zs_48_25Dec24/
[2024-12-24 21:38:19 ViT-B/16] (CL_main_v2.py 446): INFO AUG:
  COLOR_JITTER: 0.8
  CUTMIX: 1.0
  GRAY_SCALE: 0.2
  LABEL_SMOOTH: 0.1
  MIXUP: 0.8
  MIXUP_SWITCH_PROB: 0.5
BASE: ['']
DATA:
  ASYNC_LOADING: False
  DATASET: ntu60
  INPUT_SIZE: 224
  LABEL_LIST: /data/users/asinha13/ntu/ntu60_cs_zero_shot_AS_2Nov23/zsl_48-12_base_class_labels.csv
  NUM_CLASSES: 48
  NUM_FRAMES: 16
  ROOT: /data/ntu/NTU60_224x224/rgb
  SKELETON_DATA: /data/vidlab_datasets/ntu/Hyperformer_processed_data/NTU60_CS.npz
  TRAIN_FILE: /data/users/asinha13/ntu/ntu60_cs_zero_shot_AS_2Nov23/zsl_48-12_ntu60_base_train_data_v2.csv
  VAL_FILE: /data/users/asinha13/ntu/ntu60_cs_zero_shot_AS_2Nov23/zsl_48-12_ntu60_base_val_data_v2.csv
LOCAL_RANK: 0
MODEL:
  ARCH: ViT-B/16
  DROP_PATH_RATE: 0.0
  FIX_TEXT: True
  GRAPH: graph.ntu_rgb_d.Graph
  JOINT_LABEL: [0, 4, 2, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 3, 3, 3, 2, 3, 3, 3, 1, 0, 1, 0, 1]
  LABELING_MODE: spatial
  POSE_MODEL: trainers.Hyperformer.Hyperformer_Model
  PRETRAINED: None
  RESUME: ./workdirs/TEST_P1_SKeletonCLIP_alltrn_HFinit_zs_48_17Dec24/ckpt_epoch_0.pth
  RESUME_POSE: /data/users/asinha13/projects/CLIP4ADL/model_chkpnts/ntu_CS_P1_HF_pretrain_frzn_txt_zs_48_AS_16Jan24/ckpt_epoch_99.pth
OUTPUT: ./workdirs/TEST_P2_SKIViFiCLIP_zs_48_25Dec24/
PRINT_FREQ: 50
SAVE_FREQ: 25
SEED: 1024
TEST:
  MULTI_VIEW_INFERENCE: False
  NUM_CLIP: 1
  NUM_CROP: 1
  ONLY_TEST: False
TRAIN:
  ACCUMULATION_STEPS: 1
  AUTO_RESUME: False
  BATCH_SIZE: 1
  CLIP_GRAD: 1.0
  EPOCHS: 1
  LOSS_SCALE: 10.0
  LR: 2.2e-05
  LR_SCHEDULER: cosine
  OPTIMIZER: adamw
  OPT_LEVEL: O1
  USE_CHECKPOINT: False
  WARMUP_EPOCHS: 0
  WEIGHT_DECAY: 0.001
TRAINER:
  SKI_VLM:
    CTX_INIT: a photo of a
    N_CTX_TEXT: 0
    N_CTX_VISION: 0
    PROMPT_DEPTH_TEXT: 1
    PROMPT_DEPTH_VISION: 0
    PROMPT_MODEL: False
    USE: both
    ZS_EVAL: False
[2024-12-24 21:39:08 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 261): INFO Loading CLIP (backbone: ViT-B/16)
[2024-12-24 21:39:12 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 265): INFO Building Model
[2024-12-24 21:39:12 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 282): INFO Turning on gradients for COMPLETE SKI_VLM model
[2024-12-24 21:39:12 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 315): INFO Parameters to be updated: {'text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'hyperformer_model.l5.vit1.attn.proj.bias', 'hyperformer_model.l3.tcn1.branches.1.0.weight', 'hyperformer_model.l3.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.0.ln_2.bias', 'hyperformer_model.l3.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'hyperformer_model.l8.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'text_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.data_bn.weight', 'text_encoder.transformer.resblocks.5.ln_1.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'hyperformer_model.l3.tcn1.branches.1.0.bias', 'hyperformer_model.l9.tcn1.branches.0.1.weight', 'hyperformer_model.l2.tcn1.branches.2.1.bias', 'text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.l2.tcn1.branches.1.0.bias', 'hyperformer_model.l5.tcn1.branches.1.3.bn.weight', 'image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l2.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l5.residual.conv.weight', 'hyperformer_model.l2.tcn1.branches.1.1.bias', 'image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'image_encoder.transformer.resblocks.6.ln_2.weight', 'clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'hyperformer_model.l10.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l6.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.3.ln_2.bias', 'hyperformer_model.l2.vit1.attn.rpe', 'hyperformer_model.l4.vit1.attn.w1', 'hyperformer_model.l3.vit1.attn.outer', 'text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'text_encoder.transformer.resblocks.8.ln_1.weight', 'image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.11.ln_1.weight', 'text_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l7.tcn1.branches.0.1.bias', 'hyperformer_model.l8.vit1.pe_proj.weight', 'hyperformer_model.l8.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'hyperformer_model.l9.vit1.attn.rpe', 'image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l10.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l10.tcn1.branches.2.1.bias', 'image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'hyperformer_model.l1.residual.bn.bias', 'image_encoder.transformer.resblocks.11.ln_2.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'hyperformer_model.l3.tcn1.branches.2.4.weight', 'hyperformer_model.l7.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.10.ln_1.bias', 'image_encoder.transformer.resblocks.0.ln_1.bias', 'image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'image_encoder.transformer.resblocks.5.ln_2.weight', 'text_encoder.transformer.resblocks.7.ln_2.bias', 'text_encoder.transformer.resblocks.7.ln_1.weight', 'text_encoder.ln_final.bias', 'image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'hyperformer_model.l7.vit1.attn.proj.weight', 'hyperformer_model.l6.vit1.pe_proj.weight', 'image_encoder.class_embedding', 'clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'hyperformer_model.l8.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.1.ln_1.bias', 'text_encoder.transformer.resblocks.9.ln_1.weight', 'image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'image_encoder.transformer.resblocks.4.ln_1.weight', 'clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l2.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'hyperformer_model.l3.vit1.attn.q.weight', 'hyperformer_model.l8.tcn1.branches.0.0.bias', 'hyperformer_model.l8.tcn1.branches.2.1.bias', 'hyperformer_model.l10.tcn1.branches.0.3.bn.bias', 'text_encoder.transformer.resblocks.2.ln_2.weight', 'hyperformer_model.l3.tcn1.branches.2.0.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.2.ln_1.weight', 'image_encoder.transformer.resblocks.5.ln_1.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'hyperformer_model.l8.tcn1.branches.0.3.conv.weight', 'hyperformer_model.fc2.weight', 'text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'hyperformer_model.l9.tcn1.branches.1.3.conv.weight', 'text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.2.ln_1.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'hyperformer_model.l5.vit1.attn.q.weight', 'hyperformer_model.l4.vit1.norm1.bias', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'hyperformer_model.l5.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.1.ln_1.weight', 'hyperformer_model.l6.tcn1.branches.3.0.bias', 'text_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l2.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'hyperformer_model.l8.tcn1.branches.2.4.bias', 'image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.1.ln_2.bias', 'image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'hyperformer_model.l7.tcn1.branches.3.0.weight', 'hyperformer_model.l1.tcn1.branches.2.0.bias', 'image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'hyperformer_model.l2.tcn1.branches.0.1.bias', 'hyperformer_model.l9.tcn1.branches.1.1.weight', 'hyperformer_model.l6.tcn1.branches.1.3.bn.bias', 'text_encoder.transformer.resblocks.4.ln_1.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'hyperformer_model.l2.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l7.vit1.norm1.weight', 'hyperformer_model.l5.tcn1.branches.0.3.conv.bias', 'text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'hyperformer_model.l1.tcn1.branches.0.0.bias', 'hyperformer_model.l3.tcn1.branches.3.1.weight', 'hyperformer_model.l6.vit1.attn.outer', 'image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'hyperformer_model.l1.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l8.residual.conv.weight', 'hyperformer_model.l6.vit1.attn.alpha', 'hyperformer_model.l9.vit1.norm1.bias', 'image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'hyperformer_model.l6.tcn1.branches.0.1.bias', 'hyperformer_model.l7.vit1.attn.proj.bias', 'text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'hyperformer_model.l7.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l8.tcn1.branches.3.1.bias', 'hyperformer_model.l2.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.l10.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.3.ln_1.bias', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'hyperformer_model.l2.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'hyperformer_model.l7.tcn1.branches.3.1.weight', 'hyperformer_model.l9.tcn1.branches.2.4.bias', 'hyperformer_model.l1.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l5.vit1.pe_proj.weight', 'clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'hyperformer_model.l6.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'hyperformer_model.l7.tcn1.branches.0.1.weight', 'hyperformer_model.l10.tcn1.branches.0.0.bias', 'hyperformer_model.l10.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l4.tcn1.branches.3.1.bias', 'image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'hyperformer_model.l10.vit1.norm1.bias', 'hyperformer_model.l10.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l2.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.2.ln_1.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'hyperformer_model.l4.tcn1.branches.2.4.weight', 'hyperformer_model.l9.vit1.pe_proj.weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'hyperformer_model.l2.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l1.tcn1.branches.3.1.bias', 'hyperformer_model.l9.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.1.ln_2.weight', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.1.ln_1.bias', 'hyperformer_model.l7.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'hyperformer_model.l1.vit1.norm1.weight', 'hyperformer_model.l2.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l7.tcn1.branches.3.0.bias', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.4.ln_2.weight', 'clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'hyperformer_model.l7.tcn1.branches.0.0.weight', 'hyperformer_model.l5.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.2.ln_2.weight', 'text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'hyperformer_model.l8.tcn1.branches.1.3.bn.weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'hyperformer_model.l10.tcn1.branches.0.0.weight', 'hyperformer_model.l3.tcn1.branches.0.1.bias', 'text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'hyperformer_model.l3.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l4.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l8.tcn1.branches.0.0.weight', 'text_encoder.transformer.resblocks.3.ln_1.bias', 'text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.8.ln_1.bias', 'hyperformer_model.l2.vit1.attn.outer', 'hyperformer_model.l3.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l9.vit1.attn.proj.weight', 'hyperformer_model.l5.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.11.ln_2.weight', 'image_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l3.tcn1.branches.0.3.bn.weight', 'clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'hyperformer_model.l3.tcn1.branches.0.0.weight', 'hyperformer_model.l5.vit1.norm1.weight', 'hyperformer_model.l9.tcn1.branches.0.3.conv.weight', 'text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'hyperformer_model.l2.vit1.attn.alpha', 'hyperformer_model.l1.tcn1.branches.0.0.weight', 'hyperformer_model.l5.vit1.attn.w1', 'image_encoder.ln_pre.bias', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l4.tcn1.branches.0.1.bias', 'hyperformer_model.l6.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'hyperformer_model.l5.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l8.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'hyperformer_model.l2.tcn1.branches.1.1.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'hyperformer_model.l5.tcn1.branches.2.0.weight', 'hyperformer_model.l4.tcn1.branches.3.0.bias', 'hyperformer_model.l8.vit1.norm1.bias', 'hyperformer_model.l3.vit1.attn.alpha', 'text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'clip_text_encoder.text_projection', 'hyperformer_model.l1.tcn1.branches.3.0.weight', 'hyperformer_model.l8.tcn1.branches.1.1.bias', 'text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'hyperformer_model.l7.vit1.attn.rpe', 'text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'hyperformer_model.l6.tcn1.branches.3.0.weight', 'text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'hyperformer_model.l8.residual.conv.bias', 'hyperformer_model.l1.tcn1.branches.1.1.weight', 'hyperformer_model.l4.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.4.ln_1.weight', 'image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'hyperformer_model.l2.tcn1.branches.1.3.conv.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.10.ln_2.weight', 'text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'hyperformer_model.l5.tcn1.branches.1.0.bias', 'hyperformer_model.l6.tcn1.branches.2.0.weight', 'hyperformer_model.l7.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l8.tcn1.branches.3.1.weight', 'image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'hyperformer_model.l10.vit1.attn.w1', 'text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'hyperformer_model.l10.tcn1.branches.1.1.bias', 'hyperformer_model.l2.tcn1.branches.2.0.bias', 'image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'hyperformer_model.l2.tcn1.branches.3.1.bias', 'hyperformer_model.l9.tcn1.branches.2.0.bias', 'hyperformer_model.l3.tcn1.branches.0.1.weight', 'hyperformer_model.l10.vit1.attn.alpha', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'hyperformer_model.l10.tcn1.branches.2.4.weight', 'hyperformer_model.l8.vit1.attn.proj.bias', 'hyperformer_model.l10.tcn1.branches.3.0.weight', 'hyperformer_model.l4.tcn1.branches.0.0.bias', 'image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'hyperformer_model.l4.tcn1.branches.1.0.weight', 'hyperformer_model.l7.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l3.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l8.vit1.attn.rpe', 'hyperformer_model.l6.tcn1.branches.2.0.bias', 'hyperformer_model.l5.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'hyperformer_model.l8.vit1.attn.w1', 'hyperformer_model.l10.vit1.attn.proj.bias', 'hyperformer_model.l4.vit1.attn.outer', 'text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'hyperformer_model.l10.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'hyperformer_model.l4.vit1.pe_proj.weight', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'hyperformer_model.l2.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l3.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'hyperformer_model.l1.tcn1.branches.1.0.bias', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'text_encoder.text_projection', 'text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'clip_text_encoder.ln_final.weight', 'hyperformer_model.l4.tcn1.branches.1.3.conv.bias', 'image_encoder.transformer.resblocks.4.ln_2.bias', 'hyperformer_model.l10.tcn1.branches.3.1.bias', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'hyperformer_model.l6.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l8.tcn1.branches.3.0.weight', 'image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'hyperformer_model.l1.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l9.tcn1.branches.0.0.bias', 'hyperformer_model.l10.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l1.residual.conv.bias', 'hyperformer_model.l5.residual.bn.bias', 'clip_text_encoder.ln_final.bias', 'text_encoder.transformer.resblocks.11.ln_2.bias', 'text_encoder.ln_final.weight', 'clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l4.vit1.attn.kv.weight', 'hyperformer_model.l7.vit1.pe_proj.weight', 'hyperformer_model.l8.tcn1.branches.0.1.bias', 'text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l5.tcn1.branches.2.1.weight', 'hyperformer_model.l5.vit1.norm1.bias', 'hyperformer_model.l6.vit1.attn.q.weight', 'hyperformer_model.l3.tcn1.branches.2.1.bias', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'text_encoder.transformer.resblocks.7.ln_1.bias', 'text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'hyperformer_model.l6.tcn1.branches.0.0.bias', 'hyperformer_model.l9.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l8.vit1.attn.outer', 'image_encoder.transformer.resblocks.6.ln_2.bias', 'image_encoder.positional_embedding', 'image_encoder.ln_pre.weight', 'clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'hyperformer_model.l2.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'hyperformer_model.l6.vit1.norm1.bias', 'hyperformer_model.data_bn.bias', 'hyperformer_model.l5.tcn1.branches.1.1.bias', 'hyperformer_model.l1.vit1.pe_proj.weight', 'hyperformer_model.l6.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l6.vit1.norm1.weight', 'hyperformer_model.l10.tcn1.branches.0.1.weight', 'clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'hyperformer_model.l5.residual.bn.weight', 'image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.3.1.weight', 'text_encoder.transformer.resblocks.6.ln_1.weight', 'hyperformer_model.l7.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'hyperformer_model.l8.tcn1.branches.0.1.weight', 'hyperformer_model.l5.tcn1.branches.2.4.bias', 'hyperformer_model.l8.vit1.norm1.weight', 'image_encoder.transformer.resblocks.5.ln_2.bias', 'text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'hyperformer_model.l9.vit1.attn.alpha', 'hyperformer_model.l10.vit1.attn.proj.weight', 'clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'hyperformer_model.l6.tcn1.branches.2.1.bias', 'hyperformer_model.l1.tcn1.branches.1.3.conv.weight', 'clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'image_encoder.transformer.resblocks.1.ln_1.weight', 'text_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l8.tcn1.branches.1.0.bias', 'text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'hyperformer_model.l4.tcn1.branches.2.1.bias', 'hyperformer_model.l4.tcn1.branches.0.1.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'hyperformer_model.l4.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l6.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l4.tcn1.branches.2.0.bias', 'text_encoder.transformer.resblocks.4.ln_2.bias', 'image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'hyperformer_model.l10.tcn1.branches.3.0.bias', 'hyperformer_model.l8.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l5.vit1.attn.proj.weight', 'hyperformer_model.l9.tcn1.branches.1.0.bias', 'hyperformer_model.l4.tcn1.branches.1.1.bias', 'hyperformer_model.l4.vit1.attn.q.weight', 'hyperformer_model.l5.residual.conv.bias', 'hyperformer_model.l4.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'hyperformer_model.l3.tcn1.branches.2.4.bias', 'hyperformer_model.l7.tcn1.branches.2.1.bias', 'text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'hyperformer_model.l2.vit1.norm1.bias', 'hyperformer_model.l7.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l1.vit1.skip_proj.weight', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'text_encoder.positional_embedding', 'text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'hyperformer_model.l2.tcn1.branches.3.1.weight', 'hyperformer_model.l10.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l1.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l9.vit1.norm1.weight', 'hyperformer_model.l3.tcn1.branches.0.0.bias', 'image_encoder.transformer.resblocks.3.ln_1.weight', 'image_encoder.transformer.resblocks.3.ln_2.bias', 'text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l7.tcn1.branches.0.3.conv.bias', 'image_encoder.transformer.resblocks.11.ln_1.weight', 'hyperformer_model.l5.tcn1.branches.3.0.weight', 'hyperformer_model.l10.vit1.attn.rpe', 'hyperformer_model.l1.vit1.attn.alpha', 'clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.l3.vit1.norm1.weight', 'hyperformer_model.l2.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.5.ln_1.weight', 'text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'hyperformer_model.l2.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.0.ln_2.weight', 'hyperformer_model.l4.tcn1.branches.3.0.weight', 'hyperformer_model.l8.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.10.ln_1.weight', 'text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.2.4.weight', 'hyperformer_model.l6.tcn1.branches.1.0.bias', 'hyperformer_model.l4.tcn1.branches.0.3.bn.weight', 'image_encoder.transformer.resblocks.1.ln_2.weight', 'hyperformer_model.l7.vit1.attn.alpha', 'text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.7.ln_2.weight', 'hyperformer_model.l10.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'hyperformer_model.l6.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l4.vit1.attn.rpe', 'hyperformer_model.l7.tcn1.branches.2.1.weight', 'image_encoder.transformer.resblocks.0.ln_2.bias', 'clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.11.ln_2.weight', 'image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.3.1.bias', 'clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'hyperformer_model.l1.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l3.tcn1.branches.1.3.conv.bias', 'hyperformer_model.l8.vit1.attn.q.weight', 'text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l4.tcn1.branches.2.4.bias', 'hyperformer_model.l3.tcn1.branches.3.0.bias', 'image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'hyperformer_model.l5.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.7.ln_1.weight', 'image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l10.tcn1.branches.2.1.weight', 'hyperformer_model.l1.tcn1.branches.1.0.weight', 'image_encoder.transformer.resblocks.9.ln_1.weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'hyperformer_model.l10.vit1.attn.kv.weight', 'image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'hyperformer_model.l5.tcn1.branches.2.4.weight', 'hyperformer_model.l10.vit1.norm1.weight', 'text_encoder.transformer.resblocks.6.ln_2.weight', 'hyperformer_model.l4.vit1.attn.proj.bias', 'hyperformer_model.l5.vit1.attn.alpha', 'hyperformer_model.l1.vit1.attn.kv.weight', 'text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l6.vit1.attn.proj.weight', 'hyperformer_model.l8.tcn1.branches.1.3.bn.bias', 'text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'hyperformer_model.l5.vit1.attn.rpe', 'text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'hyperformer_model.l1.tcn1.branches.0.3.conv.weight', 'hyperformer_model.l4.vit1.attn.alpha', 'clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'hyperformer_model.l7.tcn1.branches.1.1.bias', 'hyperformer_model.l8.residual.bn.weight', 'text_encoder.transformer.resblocks.3.ln_1.weight', 'hyperformer_model.l1.tcn1.branches.1.3.conv.bias', 'image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'hyperformer_model.l10.vit1.pe_proj.weight', 'text_encoder.transformer.resblocks.8.ln_2.weight', 'text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'hyperformer_model.l4.tcn1.branches.1.1.weight', 'image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'hyperformer_model.l8.tcn1.branches.2.0.bias', 'hyperformer_model.l4.vit1.attn.proj.weight', 'clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'hyperformer_model.l4.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l3.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'hyperformer_model.l9.vit1.attn.proj.bias', 'hyperformer_model.l7.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.8.ln_1.weight', 'image_encoder.transformer.resblocks.7.ln_1.bias', 'clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'hyperformer_model.l3.vit1.attn.kv.weight', 'hyperformer_model.l5.vit1.attn.outer', 'hyperformer_model.l5.tcn1.branches.2.1.bias', 'hyperformer_model.l3.tcn1.branches.1.1.weight', 'hyperformer_model.l7.tcn1.branches.1.1.weight', 'text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'hyperformer_model.l7.tcn1.branches.1.0.weight', 'hyperformer_model.l5.tcn1.branches.0.1.weight', 'hyperformer_model.l6.tcn1.branches.2.4.bias', 'hyperformer_model.l9.tcn1.branches.1.1.bias', 'hyperformer_model.l2.vit1.attn.kv.weight', 'clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.1.1.bias', 'image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'hyperformer_model.l5.tcn1.branches.0.3.bn.bias', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'hyperformer_model.l8.residual.bn.bias', 'image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.9.ln_1.bias', 'image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.10.ln_1.weight', 'hyperformer_model.l2.vit1.attn.proj.weight', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'hyperformer_model.l6.vit1.attn.kv.weight', 'hyperformer_model.l9.vit1.attn.w1', 'text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'hyperformer_model.l4.tcn1.branches.1.3.bn.weight', 'image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'hyperformer_model.l5.tcn1.branches.2.0.bias', 'hyperformer_model.l1.residual.bn.weight', 'image_encoder.transformer.resblocks.4.ln_2.weight', 'hyperformer_model.l9.tcn1.branches.0.3.conv.bias', 'text_encoder.transformer.resblocks.10.ln_2.bias', 'text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'hyperformer_model.l8.vit1.attn.proj.weight', 'hyperformer_model.l7.vit1.norm1.bias', 'hyperformer_model.l1.residual.conv.weight', 'text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'hyperformer_model.l7.vit1.attn.outer', 'text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'hyperformer_model.l3.tcn1.branches.3.1.bias', 'hyperformer_model.l7.tcn1.branches.1.3.conv.bias', 'text_encoder.transformer.resblocks.6.ln_2.bias', 'hyperformer_model.l1.tcn1.branches.3.1.weight', 'clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'hyperformer_model.l1.tcn1.branches.2.1.bias', 'hyperformer_model.l3.tcn1.branches.1.1.bias', 'hyperformer_model.l4.tcn1.branches.2.0.weight', 'image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'hyperformer_model.l8.tcn1.branches.1.3.conv.bias', 'image_encoder.ln_post.bias', 'hyperformer_model.l2.vit1.pe_proj.weight', 'clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'image_encoder.proj', 'hyperformer_model.l10.vit1.attn.q.weight', 'image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'image_encoder.transformer.resblocks.9.ln_1.bias', 'hyperformer_model.l8.tcn1.branches.1.3.conv.weight', 'clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'hyperformer_model.l5.tcn1.branches.1.0.weight', 'hyperformer_model.l5.tcn1.branches.1.3.conv.bias', 'image_encoder.conv1.weight', 'image_encoder.transformer.resblocks.8.ln_2.weight', 'image_encoder.transformer.resblocks.8.ln_2.bias', 'text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'hyperformer_model.l3.vit1.attn.proj.bias', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'hyperformer_model.l2.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'hyperformer_model.l5.vit1.attn.kv.weight', 'clip_text_encoder.positional_embedding', 'clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'image_encoder.transformer.resblocks.7.ln_2.bias', 'text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'hyperformer_model.l9.tcn1.branches.0.0.weight', 'image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'text_encoder.transformer.resblocks.9.ln_2.bias', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'hyperformer_model.l7.tcn1.branches.2.0.weight', 'hyperformer_model.l1.vit1.attn.rpe', 'hyperformer_model.l9.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'hyperformer_model.l8.vit1.attn.alpha', 'text_encoder.transformer.resblocks.5.ln_2.bias', 'hyperformer_model.l1.vit1.attn.outer', 'hyperformer_model.l2.tcn1.branches.1.3.conv.bias', 'image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'hyperformer_model.l2.tcn1.branches.2.4.bias', 'hyperformer_model.l9.tcn1.branches.2.1.weight', 'hyperformer_model.l5.tcn1.branches.0.0.bias', 'text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'hyperformer_model.l4.vit1.norm1.weight', 'image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'hyperformer_model.l1.tcn1.branches.0.1.bias', 'clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'hyperformer_model.l9.tcn1.branches.2.1.bias', 'hyperformer_model.l1.vit1.norm1.bias', 'text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'hyperformer_model.l2.vit1.norm1.weight', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'image_encoder.ln_post.weight', 'text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'hyperformer_model.fc2.bias', 'hyperformer_model.l9.vit1.attn.q.weight', 'clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'hyperformer_model.l2.tcn1.branches.1.3.bn.bias', 'text_encoder.transformer.resblocks.6.ln_1.bias', 'text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'hyperformer_model.l9.tcn1.branches.1.3.bn.weight', 'hyperformer_model.l7.tcn1.branches.0.3.bn.weight', 'image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'hyperformer_model.l1.vit1.attn.proj.weight', 'hyperformer_model.l10.tcn1.branches.2.0.bias', 'image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'hyperformer_model.l9.tcn1.branches.2.4.weight', 'image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'hyperformer_model.l1.tcn1.branches.2.4.bias', 'hyperformer_model.l3.vit1.pe_proj.weight', 'text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'hyperformer_model.l9.tcn1.branches.3.0.bias', 'hyperformer_model.l10.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l3.vit1.attn.proj.weight', 'hyperformer_model.l8.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l4.tcn1.branches.1.3.conv.weight', 'image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'image_encoder.transformer.resblocks.4.ln_1.bias', 'hyperformer_model.l2.tcn1.branches.2.4.weight', 'clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'hyperformer_model.l5.tcn1.branches.0.3.bn.weight', 'image_encoder.transformer.resblocks.6.ln_1.bias', 'clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'hyperformer_model.l10.tcn1.branches.0.1.bias', 'image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'hyperformer_model.l5.tcn1.branches.3.0.bias', 'hyperformer_model.l7.tcn1.branches.2.0.bias', 'text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l4.tcn1.branches.3.1.weight', 'hyperformer_model.l6.tcn1.branches.1.3.conv.weight', 'hyperformer_model.l4.tcn1.branches.0.3.conv.weight', 'clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'image_encoder.transformer.resblocks.9.ln_2.bias', 'image_encoder.transformer.resblocks.1.ln_2.bias', 'image_encoder.transformer.resblocks.10.ln_2.bias', 'text_encoder.transformer.resblocks.10.ln_2.weight', 'text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'hyperformer_model.l7.tcn1.branches.0.0.bias', 'hyperformer_model.l7.tcn1.branches.2.4.weight', 'hyperformer_model.l2.vit1.attn.proj.bias', 'image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'image_encoder.transformer.resblocks.6.ln_1.weight', 'text_encoder.transformer.resblocks.8.ln_2.bias', 'hyperformer_model.l6.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l3.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'image_encoder.transformer.resblocks.3.ln_2.weight', 'hyperformer_model.l4.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l10.tcn1.branches.1.1.weight', 'image_encoder.transformer.resblocks.2.ln_2.bias', 'image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'hyperformer_model.l6.vit1.attn.w1', 'hyperformer_model.l1.tcn1.branches.2.1.weight', 'text_encoder.transformer.resblocks.2.ln_2.bias', 'image_encoder.transformer.resblocks.5.ln_1.bias', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'hyperformer_model.l8.tcn1.branches.0.3.bn.weight', 'hyperformer_model.l8.tcn1.branches.1.1.weight', 'hyperformer_model.l9.tcn1.branches.1.3.bn.bias', 'hyperformer_model.l3.tcn1.branches.2.1.weight', 'hyperformer_model.l9.tcn1.branches.3.1.weight', 'hyperformer_model.l7.tcn1.branches.1.0.bias', 'image_encoder.transformer.resblocks.9.ln_2.weight', 'clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'hyperformer_model.l1.vit1.attn.proj.bias', 'hyperformer_model.l9.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'hyperformer_model.l3.vit1.norm1.bias', 'hyperformer_model.l6.vit1.attn.rpe', 'clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'hyperformer_model.l10.tcn1.branches.2.4.bias', 'clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'hyperformer_model.l9.tcn1.branches.0.3.bn.bias', 'hyperformer_model.l9.vit1.attn.kv.weight', 'hyperformer_model.l10.vit1.attn.outer', 'clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'hyperformer_model.l1.tcn1.branches.0.1.weight', 'text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'hyperformer_model.l3.tcn1.branches.2.0.bias', 'clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'hyperformer_model.l9.tcn1.branches.2.0.weight', 'clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'hyperformer_model.l7.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'hyperformer_model.l6.tcn1.branches.1.3.conv.bias', 'clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'hyperformer_model.l6.tcn1.branches.1.1.weight', 'clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'text_encoder.transformer.resblocks.9.ln_2.weight', 'text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'hyperformer_model.l5.tcn1.branches.3.1.bias', 'text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'hyperformer_model.l1.tcn1.branches.3.0.bias', 'hyperformer_model.l5.tcn1.branches.1.1.weight', 'clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'hyperformer_model.l6.vit1.attn.proj.bias', 'hyperformer_model.l8.tcn1.branches.1.0.weight', 'text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'hyperformer_model.l6.tcn1.branches.2.4.weight', 'text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'hyperformer_model.l9.tcn1.branches.3.0.weight', 'clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'hyperformer_model.l1.vit1.attn.w1', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'hyperformer_model.l9.vit1.attn.outer', 'image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'text_encoder.transformer.resblocks.0.ln_1.bias', 'hyperformer_model.l2.tcn1.branches.2.0.weight', 'hyperformer_model.l3.tcn1.branches.3.0.weight', 'hyperformer_model.l6.tcn1.branches.0.1.weight', 'hyperformer_model.l10.tcn1.branches.0.3.conv.bias', 'hyperformer_model.l1.tcn1.branches.2.0.weight'}
[2024-12-24 21:39:12 ViT-B/16] (CL_vificlip_pose_text_merged_model_AS_7Feb24.py 316): INFO Total learnable items: 835
[2024-12-24 21:40:13 ViT-B/16] (tools.py 147): INFO ==============> Resuming from ./workdirs/TEST_P1_SKeletonCLIP_alltrn_HFinit_zs_48_17Dec24/ckpt_epoch_0.pth....................
[2024-12-24 21:40:14 ViT-B/16] (tools.py 172): INFO resume VIFICLIP model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.clip_text_encoder.positional_embedding', 'module.clip_text_encoder.text_projection', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.0.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.1.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.2.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.3.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.4.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.5.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.6.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.7.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.8.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.9.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.10.ln_2.bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_1.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.clip_text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.weight', 'module.clip_text_encoder.transformer.resblocks.11.ln_2.bias', 'module.clip_text_encoder.ln_final.weight', 'module.clip_text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:40:14 ViT-B/16] (tools.py 176): INFO ==============> Resuming from /data/users/asinha13/projects/CLIP4ADL/model_chkpnts/ntu_CS_P1_HF_pretrain_frzn_txt_zs_48_AS_16Jan24/ckpt_epoch_99.pth....................
[2024-12-24 21:40:14 ViT-B/16] (tools.py 218): INFO resume Hyperformer model: _IncompatibleKeys(missing_keys=['module.prompt_learner.complete_text_embeddings', 'module.image_encoder.class_embedding', 'module.image_encoder.positional_embedding', 'module.image_encoder.proj', 'module.image_encoder.conv1.weight', 'module.image_encoder.ln_pre.weight', 'module.image_encoder.ln_pre.bias', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_1.weight', 'module.image_encoder.transformer.resblocks.0.ln_1.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.0.ln_2.weight', 'module.image_encoder.transformer.resblocks.0.ln_2.bias', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_1.weight', 'module.image_encoder.transformer.resblocks.1.ln_1.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.1.ln_2.weight', 'module.image_encoder.transformer.resblocks.1.ln_2.bias', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_1.weight', 'module.image_encoder.transformer.resblocks.2.ln_1.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.2.ln_2.weight', 'module.image_encoder.transformer.resblocks.2.ln_2.bias', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_1.weight', 'module.image_encoder.transformer.resblocks.3.ln_1.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.3.ln_2.weight', 'module.image_encoder.transformer.resblocks.3.ln_2.bias', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_1.weight', 'module.image_encoder.transformer.resblocks.4.ln_1.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.4.ln_2.weight', 'module.image_encoder.transformer.resblocks.4.ln_2.bias', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_1.weight', 'module.image_encoder.transformer.resblocks.5.ln_1.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.5.ln_2.weight', 'module.image_encoder.transformer.resblocks.5.ln_2.bias', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_1.weight', 'module.image_encoder.transformer.resblocks.6.ln_1.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.6.ln_2.weight', 'module.image_encoder.transformer.resblocks.6.ln_2.bias', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_1.weight', 'module.image_encoder.transformer.resblocks.7.ln_1.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.7.ln_2.weight', 'module.image_encoder.transformer.resblocks.7.ln_2.bias', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_1.weight', 'module.image_encoder.transformer.resblocks.8.ln_1.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.8.ln_2.weight', 'module.image_encoder.transformer.resblocks.8.ln_2.bias', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_1.weight', 'module.image_encoder.transformer.resblocks.9.ln_1.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.9.ln_2.weight', 'module.image_encoder.transformer.resblocks.9.ln_2.bias', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_1.weight', 'module.image_encoder.transformer.resblocks.10.ln_1.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.10.ln_2.weight', 'module.image_encoder.transformer.resblocks.10.ln_2.bias', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.image_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.image_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_1.weight', 'module.image_encoder.transformer.resblocks.11.ln_1.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.image_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.image_encoder.transformer.resblocks.11.ln_2.weight', 'module.image_encoder.transformer.resblocks.11.ln_2.bias', 'module.image_encoder.ln_post.weight', 'module.image_encoder.ln_post.bias', 'module.text_encoder.positional_embedding', 'module.text_encoder.text_projection', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.0.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.0.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_1.weight', 'module.text_encoder.transformer.resblocks.0.ln_1.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.0.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.0.ln_2.weight', 'module.text_encoder.transformer.resblocks.0.ln_2.bias', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.1.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.1.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_1.weight', 'module.text_encoder.transformer.resblocks.1.ln_1.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.1.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.1.ln_2.weight', 'module.text_encoder.transformer.resblocks.1.ln_2.bias', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.2.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.2.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_1.weight', 'module.text_encoder.transformer.resblocks.2.ln_1.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.2.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.2.ln_2.weight', 'module.text_encoder.transformer.resblocks.2.ln_2.bias', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.3.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.3.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_1.weight', 'module.text_encoder.transformer.resblocks.3.ln_1.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.3.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.3.ln_2.weight', 'module.text_encoder.transformer.resblocks.3.ln_2.bias', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.4.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.4.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_1.weight', 'module.text_encoder.transformer.resblocks.4.ln_1.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.4.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.4.ln_2.weight', 'module.text_encoder.transformer.resblocks.4.ln_2.bias', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.5.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.5.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_1.weight', 'module.text_encoder.transformer.resblocks.5.ln_1.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.5.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.5.ln_2.weight', 'module.text_encoder.transformer.resblocks.5.ln_2.bias', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.6.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.6.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_1.weight', 'module.text_encoder.transformer.resblocks.6.ln_1.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.6.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.6.ln_2.weight', 'module.text_encoder.transformer.resblocks.6.ln_2.bias', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.7.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.7.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_1.weight', 'module.text_encoder.transformer.resblocks.7.ln_1.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.7.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.7.ln_2.weight', 'module.text_encoder.transformer.resblocks.7.ln_2.bias', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.8.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.8.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_1.weight', 'module.text_encoder.transformer.resblocks.8.ln_1.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.8.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.8.ln_2.weight', 'module.text_encoder.transformer.resblocks.8.ln_2.bias', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.9.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.9.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_1.weight', 'module.text_encoder.transformer.resblocks.9.ln_1.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.9.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.9.ln_2.weight', 'module.text_encoder.transformer.resblocks.9.ln_2.bias', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.10.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.10.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_1.weight', 'module.text_encoder.transformer.resblocks.10.ln_1.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.10.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.10.ln_2.weight', 'module.text_encoder.transformer.resblocks.10.ln_2.bias', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_weight', 'module.text_encoder.transformer.resblocks.11.attn.in_proj_bias', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.weight', 'module.text_encoder.transformer.resblocks.11.attn.out_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_1.weight', 'module.text_encoder.transformer.resblocks.11.ln_1.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_fc.bias', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.weight', 'module.text_encoder.transformer.resblocks.11.mlp.c_proj.bias', 'module.text_encoder.transformer.resblocks.11.ln_2.weight', 'module.text_encoder.transformer.resblocks.11.ln_2.bias', 'module.text_encoder.ln_final.weight', 'module.text_encoder.ln_final.bias'], unexpected_keys=[])
[2024-12-24 21:40:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][0/11317]	eta 17:09:07 lr 0.000022000	time 5.4561 (5.4561)	dist_loss 0.4401 (0.4401)	image_text_loss 3.8434 (3.8434)	pose_text_loss 3.1541 (3.1541)	tot_loss 11.3984 (11.3984)	mem 29650MB
[2024-12-24 21:40:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][50/11317]	eta 1:26:18 lr 0.000021999	time 0.3768 (0.4596)	dist_loss 0.0053 (0.1055)	image_text_loss 3.8882 (3.8754)	pose_text_loss 3.8573 (3.7157)	tot_loss 7.7982 (8.6464)	mem 29650MB
[2024-12-24 21:40:56 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][100/11317]	eta 1:17:40 lr 0.000021996	time 0.3824 (0.4155)	dist_loss 0.0143 (0.0609)	image_text_loss 3.7726 (3.8737)	pose_text_loss 3.6999 (3.7342)	tot_loss 7.6156 (8.2166)	mem 29650MB
[2024-12-24 21:41:14 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][150/11317]	eta 1:14:18 lr 0.000021991	time 0.3792 (0.3993)	dist_loss 0.0122 (0.0462)	image_text_loss 3.8051 (3.8723)	pose_text_loss 3.5601 (3.7174)	tot_loss 7.4877 (8.0516)	mem 29650MB
[2024-12-24 21:41:32 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][200/11317]	eta 1:12:19 lr 0.000021983	time 0.3610 (0.3904)	dist_loss 0.0345 (0.0390)	image_text_loss 3.9625 (3.8702)	pose_text_loss 3.6389 (3.6997)	tot_loss 7.9466 (7.9597)	mem 29650MB
[2024-12-24 21:41:50 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][250/11317]	eta 1:10:41 lr 0.000021974	time 0.3544 (0.3833)	dist_loss 0.0167 (0.0349)	image_text_loss 4.0164 (3.8741)	pose_text_loss 3.9266 (3.6764)	tot_loss 8.1099 (7.8989)	mem 29650MB
[2024-12-24 21:42:08 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][300/11317]	eta 1:09:33 lr 0.000021962	time 0.3605 (0.3788)	dist_loss 0.0308 (0.0323)	image_text_loss 3.7233 (3.8729)	pose_text_loss 3.4428 (3.6625)	tot_loss 7.4741 (7.8583)	mem 29650MB
[2024-12-24 21:42:26 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][350/11317]	eta 1:08:42 lr 0.000021949	time 0.3673 (0.3759)	dist_loss 0.0105 (0.0305)	image_text_loss 3.7644 (3.8723)	pose_text_loss 3.5073 (3.6457)	tot_loss 7.3763 (7.8225)	mem 29650MB
[2024-12-24 21:42:44 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][400/11317]	eta 1:08:00 lr 0.000021933	time 0.3453 (0.3738)	dist_loss 0.0199 (0.0291)	image_text_loss 3.8856 (3.8741)	pose_text_loss 3.3833 (3.6302)	tot_loss 7.4678 (7.7953)	mem 29650MB
[2024-12-24 21:43:01 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][450/11317]	eta 1:07:15 lr 0.000021915	time 0.3520 (0.3714)	dist_loss 0.0153 (0.0282)	image_text_loss 3.8973 (3.8740)	pose_text_loss 3.7502 (3.6162)	tot_loss 7.8002 (7.7725)	mem 29650MB
[2024-12-24 21:43:19 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][500/11317]	eta 1:06:42 lr 0.000021895	time 0.3503 (0.3700)	dist_loss 0.0151 (0.0275)	image_text_loss 3.8225 (3.8750)	pose_text_loss 3.5668 (3.6073)	tot_loss 7.5406 (7.7570)	mem 29650MB
[2024-12-24 21:43:37 ViT-B/16] (CL_main_v2.py 273): INFO Train: [0/1][550/11317]	eta 1:06:02 lr 0.000021873	time 0.3510 (0.3680)	dist_loss 0.0088 (0.0268)	image_text_loss 3.7921 (3.8757)	pose_text_loss 3.5432 (3.6002)	tot_loss 7.4230 (7.7438)	mem 29650MB
